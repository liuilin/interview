[TOC]

阳哥、JavaGuide、中华石杉、肖池、马士兵、左神

学东西要先抓脉络，不要先扣细节。体会知识成体系的感觉

[尚硅谷Java大厂面试题第二季(Java面试必学，周阳主讲)_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV18b411M7xz)

[尚硅谷2021逆袭版Java面试题第三季（Java大厂面试题，周阳主讲）_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1Hy4y1B78T?p=70&spm_id_from=pageDriver)

### Java基础

> 第四题开始

1. **面向对象的特征**

   封装、继承、多态

   > 多态：父类引用指向子类对象（接口的多种不同实现方式）。前提 1. 类的继承 2. 方法的重写
   >
   > ```java
   > List<String> list = new ArrayList<>();
   > List<String> linkedList = new LinkedList<>();
   > ```
   >
   > 多态就是同一个接口，使用不同的实例而执行不同操作，如图所示：
   >
   > <img src="https://www.runoob.com/wp-content/uploads/2013/12/java-polymorphism-111.png" alt="java-polymorphism-111.png (701×561)" style="zoom: 50%;" />

2. **重载和重写的区别**

   重载：发生在同一个类中，方法名必须相同，而参数类型、个数、顺序不同，方法返回值和访问修饰符也可以不同

   重写：发生在子父类中，方法名、参数列表必须相同，返回值和抛出异常的范围要小于等于父类，访问修饰符范围要大于等于父类；如果父类方法访问修饰符为 private 则子类就不能重写该方法

3. **接口和抽象类有什么区别？**

   接口是对行为的抽象，是抽象方法的集合，利用接口可以达到 API 定义与实现分离的目的。接口，不能实例化，也不能包含任何非常量成员，所以任何 field 都是隐含着 public static final 的含义；同时，没有非静态方法实现，也就是说要么是抽象方法，要么是静态方法。在标准类库中，如 Java.util.List

   抽象类是不能实例化的类，用 abstract 关键字修饰 class ，其目的主要是代码重用。除了不能实例化，形式上和一般的 Java 类并没有太大区别，它可以有一个或多个抽象方法，也可以没有。抽象类大多用于抽取相关 Java 类的共用方法实现或者是共同成员变量，然后通过继承的方式达到代码复用的目的。在标准库中，比如 Collection 框架，很多通用部分就被抽取成为抽象类，例如 Java.util.AbstractList

   > - 在抽象类中可以写非抽象的方法，从而避免在子类中重复书写他们，这样可以提高代码的复用性，这是抽象类的优势；接口中只能有抽象的方法。
   > - 一个类只能继承一个直接父类，这个父类可以是具体的类也可是抽象类；但是一个类可以实现多个接口。
   >
   > Java 类实现 interface 使用 implements 关键词，继承 abstract class 则是使用 extends 关键词，我们可以参考 Java 标准库中的 ArrayList.
   >
   > ```java
   > public class ArrayList<E> extends AbstractList<E>
   >   implements List<E>， RandomAccess， Cloneable， Java.io.Serializable
   > {}
   > ```
   >
   > ...Servlet extends HttpServlet extends GenericServlet implement Servlet
   >
   > 实现接口就需要复写所有方法；而继承接口就只需要复写 abstract 方法

4. **String 和 StringBuffer、StringBuilder 的区别是什么？String 为什么是不可变的**

   String 类中是使用 final 关键字的字符数组来保存字符串的（`private final char value []`） ，所以 String 对象是不可变的，每次对 String 类改变的时候相当于生成了一个新的 String 对象然后将指针指向它，所以内容经常改变的字符串最好不要用 String，因为每次生成对象都会对系统性能产生影响，特别是当内存中无引用对象多了以后，JVM 的 GC 就会开始工作，那时速度就会很慢

   StringBuffer 和 StringBuilder 类就不一样了，每次结果都是对对象本身进行操作，而不是生成新的对象。然而 StringBuffer 是对方法加了锁是线程安全的。而 StringBuilder 是非线程安全的

   > 加锁了效率会受到一定影响

   总结：

   1. 操作少量数据时用 String
   2. 单线程下操作大量数据用 StringBuilder
   3. 多线程下操作大量数据用 StringBuffer 

5. **Java 容器有哪些？哪些是同步容器？哪些是并发容器？（Java 集合之间的区别 | 介绍一下集合框架）**

   ![Java 集合容器](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/Java%20%E9%9B%86%E5%90%88%E5%AE%B9%E5%99%A8.jpg)

   Java 容器主要分两大类，一类是 Collection，一类是 Map，它们有共同父接口 Iterator

   - Collection
     - List 与 Set

       List 特点是数据对象有序且可以重复

       Set 特点是数据对象无序且不可以重复

     - ArrayList 和 LinkedList

       ArrayList 是个数组的数据，查询快、增删慢（因为要移动数据）

       > 数组删除慢，删了之后要把后面的数据往前移动

       LinkedList 是个双向链表 ，查询慢、增删快（因为只用移动指针）

       > 链表查询慢，因为要一个一个的遍历，增删比较快，主需要改变 index 指向的指针
     >
       > LinkedList 见 LRU 算法应用

     - ArrayList 和 Vector

       Vector 加了锁是线程安全的，数据一致性保证了，但是性能急剧下级
     
       ArrayList 不是同步的，所以在不需要保证线程安全时建议使用 ArrayList，多线程情况下呢可以使用 CopyOnWrite 写时复制
     
     - HashSet
     
       HashSet 底层就是 HashMap
     
       ```java
       public HashSet() {
           map = new HashMap<>();
       }
       ```
       
     
   - Map

     - HashMap ：

       - JDK8 之前，HashMap 由数组 + 链表组成的，数组是 HashMap 的主体，链表则是主要为了解决哈希冲突而存在的（“拉链法” 解决冲突）。
     - JDK8 以后，在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8 ）时，将链表转化为红黑树，以减少搜索时间。
     
   - HashMap 和 HashTable
     
       HashMap 是非线程安全的、键和值都允许有 null 存在、效率高。而 HashTable 则都相反
     
     - HashMap 与 TreeMap
     
       HashMap 通过 hashcode 对其内容进行快速查找，而 TreeMap 中所有的元素都保持着某种固定的顺序在 Map 中插入、删除和定位元素。HashMap 是最好的选择但如果您要按自然顺序或自定义顺序遍历键，那么 TreeMap 会更好使用 HashMap 要求添加的键明确定义了 hashCode () 和 equals () 的实现。这个 TreeMap 没有调优选项，因为该树总处于平衡状态

6. **HashMap 的源码，实现原理，JDK8 中对 HashMap 做了怎样的优化**

   不管是数组还是链表，如果我们想要寻找一个特定的数值，时间复杂度都为 O (n)。那有什么办法用最快的速度来找到一个特定的元素呢，工业界中常用的数据结构 “哈希表”，在哈希表中，不管是寻找、删除、增加一个新元素，时间复杂度都是 O (1)

   JDK1.7（头插）：

   底层数据结构是数组 + 链表

   哈希函数（ Hash function）

   哈希函数能快速将一个数值转换成哈希值（整数）。所以哈希表必须保持哈希值的计算一致，如果两个哈希值是不相同的，那么这两个哈希值的原始输入也是不相同的

   那如果两个不同的输入得到相同的哈希值呢？这也就是所谓的 **哈希值冲突**，这也是为什么我们结合数组和链表来实现哈希表，如果一个关键字对应的数组下标已经有其他元素了，只需要在其对应的链表后创建一个新的节点即可

   简单来说，我们输入关键字 x，使用哈希函数 f (x) 计算出哈希值 y，然后使用哈希值 y 来找特定的数组下标，并在对应位置插入新数据。在之后的实现中，我们会使用 Java 来实现哈希表，而 JVM 自动生成哈希值，我们只需要再将其哈希值和我们的哈希表数组长度取模（mod）就能拿到其对应下标

   > X => f (X) = Y => Y % Array.length = Array position of X

   底层数据结构：JDK1.8 以后的 HashMap 在解决哈希冲突时的处理是当链表长度大于阈值（默认为 8）时，将链表转化为红黑树，以减少搜索时间。Hashtable 没有这样的机制

7. **ConcurrentHashMap 实现原理**

   ConcurrentHashMap 是一个 Segment 数组，Segment 通过继承 ReentrantLock 来进行分段加锁，所以每次需要加锁的操作锁住的是一个 Segment，这样只要保证每个 Segment 是线程安全的，也就实现了全局的线程安全。

   > 分段锁一个个数组
   >
   > 读写锁：读的时候允许它写

8. **HaspMap 扩容是怎样扩容的 **

   当数组存放元素大于它的阈值（0.75）时，就扩容成原来的两倍。本来应该是拿着这个节点 key 的 hash 去 & 上新长度 - 1，计算出应该落到新数组的哪个节点上边。但是它不需要这么做了，而是只需要去 & 上老长度。因为老长度的最高位对应上去的 hash 值恰好是新数组是否需要移动的关键点，如果对应上去的 hash 值为 1，那就需要移动且移动的大小为老数组的长度，为 0 就不需要移动（当然这是 jdk1.8）

9. **HashMap、HashTable、ConcurrentHashMap 的区别 **

   https://zhuanlan.zhihu.com/p/50675786

   > 一般问题：
   >
   > 谈谈你理解的 HashMap，讲讲其中的 get put 过程。
   >
   > 1.8 做了什么优化？
   >
   > 是线程安全的嘛？
   >
   > 不安全会导致哪些问题？
   >
   > 如何解决？有没有线程安全的并发容器？
   >
   > ConcurrentHashMap 是如何实现的？ 1.7、1.8 实现有何不同？为什么这么做？

   [HashMap 与 ConcurrentHashMap 的区别_XF 的专栏 - CSDN 博客_hashmap 和 concurrenthashmap 的区别](https://blog.csdn.net/xuefeng0707/article/details/40834595)

   - 线程是否安全：HashMap 是非线程安全的所以效率高，HashTable 是线程安全的；HashTable 内部的方法基本都经过 Synchronized 修饰。（如果你要保证线程安全的话就使用 ConcurrentHashMap 吧！）
   - 对 Null key 和 Null value 的支持：HashMap 中，null 可以作为键，这样的键只有一个，键所对应的值可以有多个 null。但是在 HashTable 中 put 进的键值只要有一个 null，直接抛出 NullPointerException
   - 初始容量大小和每次扩充容量大小的不同 ：①创建时如果不指定容量初始值，Hashtable 默认的初始大小为 11，之后每次扩充，容量变为原来的 2n+1。HashMap 默认的初始化大小为 16。之后每次扩充，容量变为原来的 2 倍。②创建时如果给定了容量初始值，那么 Hashtable 会直接使用你给定的大小，而 HashMap 会将其扩充为 2 的幂次方大小（HashMap 中的 tableSizeFor () 方法保证，下面给出了源代码）。也就是说 HashMap 总是使用 2 的幂作为哈希表的大小，后面会介绍到为什么是 2 的幂次方
   - 底层数据结构：JDK1.8 以后的 HashMap 在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）时，将链表转化为红黑树，以减少搜索时间。Hashtable 没有这样的机制。
   - Hashmap 虽然好用，但是还是有缺点，它线程不安全，而且 1.7 会发生闭环链表问题，concurrentHashMap1.7 前怎么用桶锁的，1.8 怎么用 CAS 和 Synchronized 解决的
   - 见下

   > 人很聪明，真的很聪明。既然不能全锁（HashTable）又不能不锁（HashMap），所以就搞个部分锁，只锁部分，用到哪部分就锁哪部分。一个大仓库，里面有若干个隔间，每个隔间都有锁，同时只允许一个人进隔间存取东西。但是，在存取东西之前，需要有一个全局索引，告诉你要操作的资源在哪个隔间里，然后当你看到隔间空闲时，就可以进去存取，如果隔间正在占用，那你就得等着。聪明
   >
   > sc = n - (n>>> 2)；
   >
   > “>>>” 无符号右移，hashmap 里面的算法太 low，位运算是效率最高的

10. **极高并发下 HashTable 和 ConcurrentHashMap 哪个性能更好，为什么，如何实现的**

    HashTable 使用一把锁处理并发问题，当有多个线程访问时，需要竞争一把锁导致阻塞

    ConcurrentHashMap 则使用分段，相当于把一个 HashMap 分成多个，然后每个部分分配一把锁，这样就可以支持多线程访问

11. **HashMap 在高并发下如果没有处理线程安全会有怎样的安全隐患，具体表现是什么**

15. **传值和传引用的区别，Java是怎么样的，有没有传值引用**

    值传递：传递的是真实内容的一个副本，对副本的操作不影响原内容，也就是形参怎么变化，不会影响实参对应的内容

    引用传递：传递变量的引用地址，若地址指向的变量改变，指向同一内存空间的变量同步改变

13. **一个ArrayList在循环过程中删除，会不会出问题，为什么**

    有问题遍历的时候应该使用 Iterator 或 倒序遍历 List

    - 使用 Iterator ，顺序向下，如果找到元素，则使用 remove 方法进行移除。
    - 倒序遍历 List ，如果找到元素，则使用 remove 方法进行移除。

17. **Hash冲突问题（为什么会有hash冲突算法）**

    为什么会有hash冲突算法(n-1)&key.hashCode()呢：我们想要让它均匀的落在每个节点上，避免链表过长

    hash的操作：首先是根据我们的key进行一个哈希。然后右移16位取到它的高16位，再与他的本身也就是低16位进行异或^操作。取异或的原因是因为想要0、1均衡，尽量让每一位都参与到运算中来，避免出现一种极端情况全是0或1，那就没意思了

    数组的操作：数组长度必须是2的n次幂，因为二的n次幂是一个偶数，偶数减1是一个奇数。是个基数，在进行计算的时候，二进制最低位一定是一个1，这时和hash值进行一个与&运算时，计算出来key落在数组的索引值是奇数还是偶数是依赖的数组长度二进制最高位对应的hash值是0还是1。如果数组长度是一个奇数，减1得到一个偶数后，无论你的hash值是多少，计算出来索引的永远只能是一个偶数，这就意味了奇数位就用不了

    ```
    010101000001111110 hashCode
    			 01111 在老数组16中key落在节点上的索引
    			011111 在新数组32中key落在节点上的索引
    ```

18. **Object类中的方法**

    clone

    finalize()：虚拟机的垃圾回收，每个对象都可以调用这个方法来判断对象是否可以被销毁

    hashCode()、equals()：hashMap
    

getClass()：获取当前类，再 .getClassLoader() 可以获取类加载器等等
    
    toString()：架构开发（自己定义类，看里面的信息）
    
    wait()、notify()、notifyAll()：多线程相关，操作线程的等待和唤醒

16. ==**你重写过 hashcode 和 equals 么，为什么重写 equals 时必须重写 hashCode 方法？（hashCode 与 equals）**==

    hashCode ()：作用是获取哈希码，也称为散列码；它实际上是返回一个 int 整数。这个哈希码的作用是确定该对象在哈希表中的索引位置。hashCode () 定义在 JDK 的 Object.Java 中，这就意味着 Java 中的任何类都包含有 hashCode () 函数。

    散列表存储的是键值对 (key-value)，它的特点是：能根据 “键” 快速的检索出对应的 “值”。这其中就利用到了散列码！（可以快速找到所需要的对象）
    为什么要有 hashCode

    > 我们以 “HashSet 如何检查重复” 为例子来说明为什么要有 hashCode：
    >
    > 当你把对象加入 HashSet 时，HashSet 会先计算对象的 hashcode 值来判断对象加入的位置，同时也会与其他已经加入的对象的 hashcode 值作比较，如果没有相符的 hashcode，HashSet 会假设对象没有重复出现。但是如果发现有相同 hashcode 值的对象，这时会调用 equals（）方法来检查 hashcode 相等的对象是否真的相同。如果两者相同，HashSet 就不会让其加入操作成功。如果不同的话，就会重新散列到其他位置。（摘自我的 Java 启蒙书《Head first Java》第二版）。这样我们就大大减少了 equals 的次数，相应就大大提高了执行速度。
    >
    > hashCode（）与 equals（）的相关规定，如果两个对象相等，则 hashcode 一定也是相同的

    两个对象相等，对两个对象分别调用 equals 方法都返回 true
    两个对象有相同的 hashcode 值，它们也不一定是相等的
    因此，equals 方法被覆盖过，则 hashCode 方法也必须被覆盖
    hashCode () 的默认行为是对堆上的对象产生独特值。如果没有重写 hashCode ()，则该 class 的两个对象无论如何都不会相等（即使这两个对象指向相同的数据）

17. **<span id='newObject'>一个对象占用多少个字节？</span>对象的创建过程？**

    使用 OpenJDK 的 JOL（Java Object Layout） 工具来查看对象的布局，Object 对象默认是 8 个字节

    > klass point 默认（压缩）是 4 个字节，不压缩的话是 8 个字节

    ```java
    public class HelloJOL {
        public static void main(String[] args) {
            Object o = new Object();
            System.out.println(ClassLayout.parseInstance(o).toPrintable());
        }
        // ================================ print out ================================
        // java.lang.Object object internals:
        //  OFFSET  SIZE   TYPE DESCRIPTION                               VALUE
        //       0     4        (object header)                           01 00 00 00 (00000001 00000000 00000000 00000000) (1)
        //       4     4        (object header)                           00 00 00 00 (00000000 00000000 00000000 00000000) (0)
        //       8     4        (object header)                           e5 01 00 f8 (11100101 00000001 00000000 11111000) (-134217243)
        //      12     4        (loss due to the next object alignment)
        // Instance size: 16 bytes
        // Space losses: 0 bytes internal + 4 bytes external = 4 bytes total
    }
    ```

    前两个 `(object header)` 是 markword，第三个 `(object header)` 是 klass pointer，`e5 01 00 f8` 值是 `Object.class` 。第四行是 padding 补齐

    ![Java 对象头信息](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/Java%20%E5%AF%B9%E8%B1%A1%E5%A4%B4%E4%BF%A1%E6%81%AF.jpg)

    一个对象包含哪些内容

    - mark word：作用是记录了锁状态信息、 GC 标记信息、hashCode 信息
    - klass pointer：指向当前对象
    - instance data：

###  数据结构和算法

左神算法笔记：https://juejin.im/post/5c6b9c696fb9a049ed316ef9#heading-24

https://juejin.im/post/5c6b9d0a6fb9a04a05403cbc

https://www.jianshu.com/nb/5320868

1. **树**

   https://xeh1430.github.io/text/dataStructure8

   <img src="https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/tree.png" alt="img" style="zoom:50%;" />

2. **==快速排序，堆排序，归并排序==，插入排序（堆和排序准备模板，比如对数器模板）**

   可视化算法：https://visualgo.net/en

   想要绕开原本数据状况方式：1. 随机选一个数 2. hash

   - 冒泡排序（时间复杂度 O(N^2^)， 额外空间复杂度 O(1)  ，工程组已经少见）

     如果前一个比后一个大就交换，直到排好最后一位，重复操作。从 N...N-1...1，结果是个等差数列，类似于 aN^2^+bN+1，不要低阶项 bN+1，不要高阶项系数a，结果就是 O(N^2^)

     ```java
     private static void bubbleSort(int[] arr) {
         if (arr == null || arr.length < 2) {
             return；
         }
     
         for (int end = arr.length - 1； end > 0； end--) {
             for (int i = 0； i < end； i++) {
                 if (arr[i] > arr[i + 1]) {
                     swap(arr， i， i + 1)；
                 }
             }
         }
     }
     
     private static void swap(int[] arr， int i， int j) {
         int temp = arr[i]；
         arr[i] = arr[j]；
         arr[j] = temp；
     }
     ```

   - 选择排序（时间复杂度O(N^2^)， 额外空间复杂度O(1)  ）

   - 插入排序（时间复杂度O(N^2^)， 额外空间复杂度O(1)  ）

     选定第一个位置为最小值，遍历后面的值比第一个位置小就交换。然后从第二个开始循环

   - 归并排序（时间复杂度O(N*log^N^)，额外空间复杂度O(1) )

     先左侧排序，然后右侧排序。准备一个辅助数组，然后用外排序的方式小的填，依次动到末尾。另外一部分把没动到末尾的部分copy进辅助数组，再整体的copy回原数组

     ```java
     public static void sortProcess(int[] arr, int L, int R) {
         if (L == R) {
             return;
         }
         int mid = L + ((R - L) >> 1);//L和R中点位置，防止溢出，除以2等于右移一位，等同于（L+R)/2
         sortProcess(arr, L, mid);//T(N/2)
         sortProcess(arr, mid + 1, R);//T(N/2)
         merge(arr, L, mid, R);//big O(N)
         //T(N)=2T(N/2)+O(N)，用mater公式【T(N)=2T(N/2)+O(N)】、log(b,a) = d -> 复杂度为O(N^d * logN)
         //求解时间复杂度为：O(N*logN)，额外空间为借用的数组为：O(N)
     }
     private static void merge(int[] arr, int L, int mid, int R) {
         int[] auxiliary = new int[R - L + 1];
         int i = 0;
         int p1 = L;
         int p2 = mid + 1;
         while (p1 <= mid && p2 <= R) {
             auxiliary[i++] = arr[p1] < arr[p2] ? arr[p1++] : arr[p2++];
         }
         //两个必有且只有一个越界
         while (p1 <= mid) {
             auxiliary[i++] = arr[p1++];
         }
         while (p2 <= R) {
             auxiliary[i++] = arr[p2++];
         }
         for (i = 0; i < auxiliary.length; i++) {
             arr[L + i] = auxiliary[i];//[L+i]表示可能在坐边P1位置，可能在右边P2（mid+1）位置
         }
     }
     ```

     > 引出来分治的思想非常重要
     >
     > 小和问题：
     >
     > ```java
     > 只改变了这两处内容
     > return sortProcess(arr, L, mid)+sortProcess(arr, mid+1, R)+merge(arr,L,mid,R);
     > 
     > while (p1 <= mid && p2 <= R) {
     >  //ture:R-p2+1是递归后右边的个数 * 比p1小的值
     >  res += arr[p1] < arr[p2] ? (R - p2 + 1) * arr[p1] : 0;
     >  auxiliary[i++] = arr[p1] < arr[p2] ? arr[p1++] : arr[p2++];
     > }
     > ```

   - ==随机快排：==【时间复杂度O(N*log^N^)，额外空间复杂度O(log^N^)就是数组需要2分多少次且每次都在中间位置，最差情况O(N)】

     [快排](https://www.bilibili.com/video/BV1qb411g7fK?from=search&seid=15785115392021315340)：长期期望的复杂度是O(N*log^N^)，如果是顺序的数组则每次只排好一位数，时间复杂度为O(N^2^)

     优势：代码简洁，可以说明常数项很低；各种算法时间复杂度一样时，开始拼常数项；归并排序输在需要准备数组和拷贝数组过程，而且会遍历两边，快排只用while一遍

     随机快排：数组中随机选一个数和末尾交换，然后进行快排。好处是变成了一个概率事件

     实现：选最后一个数x，根据Netherlands荷兰国旗问题，选定最后一位为num值，遍历数组把小于x的和小于区下一位交换，然后小于区扩大一位，大于x的放大于区前一位，然后大于区缩小一位。然后递归前面操作

     - 数组的第一位是一个基准数

     - 从右开始解锁一个比基准数小的数，如果找到了，停下来

     - 再从左开始解锁一个比基准数大的数，如果找到了，停下来，如果1，2两者停下来的位置，未相遇，将停下来的元素交换位置

     - 直到两者相遇后，称之为基准数归位，将基准数和停下来的元素交换位置，再按照之前的逻辑反复操作

       > 1. 方法是3个参数
       > 2. 解锁操作实际上是一个while
       > 3. 条件：当前这个数 >= baseNum  j--
       > 4. 左边也是一个解锁，实际上是一个while条件，当前这个数 <= baseNum  i++

     ```java
     public static void quickSort(int[] arr) {
         if (arr == null || arr.length < 2) {
             return;
         }
         quickSort(arr, 0, arr.length - 1);
     }
     private static void quickSort(int[] arr, int l, int r) {
         if (l < r) {
             //加上这行则为随机快排
     		swap(arr, l + (int) (Math.random() * (r - l + 1)), r);
             int[] p = partition(arr, l, r);
             quickSort(arr, l, p[0] - 1);
             quickSort(arr, p[1] + 1, r);
         }
     }
     private static int[] partition(int[] arr, int l, int r) {
         int less = l - 1;
         int more = r + 1;
         int cur = l;
         while (cur < more) {
             if (arr[cur] < arr[r]) {
                 swap(arr, ++less, cur++);
             } else if (arr[cur] > arr[r]) {
                 swap(arr, cur, --more);
             } else {
                 cur++;
             }
         }
         return new int[]{less + 1, more - 1};
     }
     ```

     > 在工程上是不允许递归函数出现的，因为准备递归函数的代价比较高，函数的指针、函数的变量域、code中的哪一行。系统压栈会将和业务有关或无关的信息都记下来，准备函数它常数时间比较大。而且系统栈递归了多少层之后会报错 不安全，所以工程上一定是改为的非递归版本

   - ==堆排（堆，就算被火车撞了也不能忘）==

     优点：形成了结构大小为N，每次新进来一个数调整代价为logN（非常逆天，想想40多亿的数），也就是二叉树的高度。（因为是满二叉树，所以高度和节点是O(log^N^)的关系，15个节点高度就是四层）
     
     建立大根堆heapinsert：0到 i-1位置已经是大根堆，进加入的 i调整代价为logi-1，i+1位置调整代价为logi，则N个节点代价为log1+...log^N-1^ = O(N)
     
     heapify过程：
     
     将整数数组（ 7-6-3-5-4-1-2 ）按照堆排序的方式进行升序排列，请问在第一轮排序结束之后，数组的顺序是（）
     
     堆排序首先将堆顶元素与最后一个元素互换，然后对未排序的部分维护堆的性质，从堆顶元素开始互换，2的左右分别是6和3,由于6比3大，因此2与6互换，然后2的左右分别是5和4，由于5比4大，因此2与5互换形成最终的堆。顺序为6532417
     
     ```java
     public static void heapSort(int[] arr) {
         if (arr == null || arr.length < 2) {
             return;
         }
         for (int i = 0; i < arr.length; i++) {
             //建立大根堆
             heapInsert(arr, i);
         }
         int size = arr.length;
         swap(arr, 0, --size);
         while (size > 0) {
             heapify(arr, 0, size);
             swap(arr, 0, --size);
         }
     }
     private static void heapInsert(int[] arr, int index) {
         while (arr[index] > arr[(index - 1) / 2]) {
             swap(arr, index, (index - 1) / 2);
             index = (index - 1) / 2;
         }
     }
     private static void heapify(int[] arr, int index, int size) {
         int left = index * 2 + 1;
         //左叶子大于--size就不再继续；left+1<size是判断--size时右叶子越界与否
         while (left < size) {
             int largest = left + 1 < size && arr[left + 1] > arr[left] ? left + 1 : left;
             largest = arr[index] < arr[largest] ? largest : index;
             if (largest == index) {
                 break;
             }
             swap(arr, largest, index);
             index = largest;
             left = index * 2 + 1;
         }
     }
     ```
     
     

   > 样本量不估计常数，只估计规模
   >
   > 剖析递归行为和递归行为时间复杂度的估算
   > master公式的使用
   > T(N) = a*T(N/b) + O(N^d)
   > 1) log(b,a) > d -> 复杂度为O(N^log(b,a))
   > 2) log(b,a) = d -> 复杂度为O(N^d * logN)
   > 3) log(b,a) < d -> 复杂度为O(N^d)  

3. 综合排序算法

   首先和判断数组中的数据类型，

   如果是基本数据类型则用快排，因为基础类型不用考虑稳定性（也就是像两个3，谁在前 谁在后）

   自己定义的类型如student用归并排序，一个班的同学先按分数排序，再按班级排序，此时相同班级的个体可能不一样

   样本量极少（小于60的情况下）用插入排序

   > 综合排序在样本量很小的情况下，为什么会选择复杂度很高的排序。因为常数项很低
   >
   > 为什么基础类型用快排自己定义的类型用归并排序？因为基本类型不需要稳定性，而自己定义的类型需要具有稳定性算法

4. 一致性Hash算法，一致性Hash算法的应用

5. **荷兰国旗问题**

6. **遍历一颗二叉树**

   递归遍历左右节点

   左节点：2n+1

   右节点：2n+2

### JVM

1. **JVM的内存结构（模型）**

   线程私有：每个线程独立包含程序计数器、栈、本地方法栈（线程私有意味着生命周期和线程一致）

   线程共享：堆、堆外内存（【方法区】永久代或元空间、CodeCache 代码缓存（也就是 JIT 编译产物））

   垃圾回收是和堆、方法区有关。其它的是线程私有，不存在垃圾回收

   [Stack Memory and Heap Space in Java | Baeldung](https://www.baeldung.com/Java-stack-heap)

   > JDK6 以后常量池移入堆中
   >
   > String 常量池位置：
   >
   > - jdk1.6: 永久代（方法区）
   > - jdk1.7: 堆内存
   > - jdk1.8: 堆里面的元空间

   ![Java 堆栈空间](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/Java%20%E5%A0%86%E6%A0%88%E7%A9%BA%E9%97%B4.jpg)

   <img src="https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/JVM%20%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B.jpg" alt="JVM 内存模型" style="zoom: 33%;" />

   一个进程包含着整个运行时数据区对应的是一个 JVM 实例，进程里面的每个线程拥有一套 `虚拟机栈`、`本地方法栈`、`程序计数器`，同时所有线程共享 `方法区` 和 `堆` 空间

   - 栈（虚拟机栈）：每一个方法就是一个栈帧

     - 栈是什么：是每个线程创建时对应创建的虚拟机栈，其内部保存一个个的栈帧（Stack Frame），也就是对应着一次次方法的调用

     - 生命周期：它的生命周期是跟随线程的，线程结束时栈内存也就释放了，所以对于栈来说不存在垃圾回收问题

     - 作用：存储方法的局部变量，包括 8 种基本数据类型和对象的应用地址 reference address（真正的对象在堆空间中），并参与方法的调用与返回（也就是入栈和出栈）

     - 栈运行原理：压栈和出栈遵循 FILO 先进后出

     - 开发中可能遇到异常 java.lang.StackOverflowError：出现这个异常，在项目中定位代码时，发现同事的代码里进行了递归调用方法，结果栈调用层级过多，导致线程栈满了，就会出现此异常。

       > 可以使用 VM 启动参数 -Xss 来设置线程的最大栈空间
       
       ```java
       // 默认不设置栈大小情况下 i = 9879
       // 设置栈大小：-Xss256k，i = 2304
       private static int i = 1;
       public static void main(String[] args) {
           System.out.println(i++);
           main(args);
       }
       ```

     **栈帧：**

     - 局部变量表

       定义为一个数字数组，主要用于存储方法参数和定义在方法体内的局部变量，局部变量包括各类包括 8 种基本数据类型和对象的应用地址 reference address，以及 returnAddress 类型。

       由于局部变量表是建立在线程的栈上，是线程的私有数据，因此不存在数据安全问题

       局部变量表的最大容量在编译期就确定下来了，用字节码看是保存在方法的 Code 属性的 Maximum local variables 中，在方法运行期间是不会改变局部变量表的大小的。

       局部变量表中的变量只在当前方法调用中有效，当方法调用结束后会随着栈帧的销毁而销毁。

       ```java
       public static void main(String[] args) {
           LocalVariablesTest test = new LocalVariablesTest();
           int num = 10;
           test.test1();
       }
       private void test1() { }
       ```

       > IDEA 插件 Jclasslib 和 javap -c 命令都能查看：
       >
       > Ljava：L 是指引用类型变量

       ![局部变量表字节码](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/%E5%B1%80%E9%83%A8%E5%8F%98%E9%87%8F%E8%A1%A8%E5%AD%97%E8%8A%82%E7%A0%81.jpg)

       **Slot 的理解**

       局部变量表的单位是一个个 Slot，JVM 会为局部变量中的每一个 Slot 都分配一个访问索引，通过索引即可访问到对应的局部变量值。

       如果当前帧是由 <font color='red'> 构造方法 </font> 或者 <font color='red'> 实例方法（非静态方法的普通方法）</font> 创建的，那么该对象引用 this 将会存放在 index 为 0 的 Slot 处，其余的参数按照参数表顺序继续排列。他们两个方法可以用是因为他们对应的局部变量表中是有变量声明的，而静态方法则会编译出错。

       > double、long 会占据两个 Slot，相当于字节码里面的两个 Index

       局部变量表中的变量也是重要的垃圾回收根节点，只要被局部变量表中直接或间接引用的对象都不会被回收。如果局部变量表的变量不存在了，那么指针也就不存在了，垃圾就会被回收

       ![JVM 栈的局部变量表 Slot 理解](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/JVM%20%E6%A0%88%E7%9A%84%E5%B1%80%E9%83%A8%E5%8F%98%E9%87%8F%E8%A1%A8%20Slot%20%E7%90%86%E8%A7%A3.jpg)

     - 操作数栈 OperandStack

       主要用于保存计算过程的中间结果，同时作为计算过程中变量临时的存储空间

       操作数栈的最大容量在编译期就确定下来了，用字节码看是保存在方法的 Code 属性的 Maximum stack size 中（相当于类里面有几个方法）

       如果被调用的方法带有返回值的话，其返回值将会被压入当前栈帧的操作数栈中，并更新 PC 寄存器中下一条需要执行的字节码指令。

       代码追踪（执行流程）：[JVM/1_内存与垃圾回收篇/5_虚拟机栈 · 陌溪/LearningNotes - 码云 - 开源中国](https://gitee.com/moxi159753/LearningNotes/tree/master/JVM/1_内存与垃圾回收篇/5_虚拟机栈#代码追踪)

     - 动态链接 Dynamic Linking（指向运行时常量池的方法引用）

       字节码中，所有的变量和方法引用都会作为符号引用保存在常量池，常量池运行以后就在方法区了（运行时加载进发放区的所以也叫运行时常量池）

       作用：将这些符号引用转换为调用方法的直接引用

       > 为什么需要动态链接？为什么需要指向运行时常量池的方法引用
       >
       > 因为这样就在不同的方法里，都可以共享的调用同一份常量或者方法引用。这样就只需要存储一份，节省了空间
       >
       > 为什么需要运行时常量池？
       >
       > 常量池提供了一些符号和常量，便于指令识别。在不同的方法里都有可能调用同一份数据（两个方法调用同一个 num -> int num = 1;），没必要各自拥有一份，只需要放入一份到运行时常量池大家去引用即可

       **方法的调用：**

       ![方法调用](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/%E6%96%B9%E6%B3%95%E8%B0%83%E7%94%A8.jpg)

       在 JVM 中，将符号引用转换为调用方法的直接引用与方法的绑定机制相关。methodB 调用 methodA 时，字节码体现就是符号引用 `#6` 会去对应的常量池找到直接引用 `CONSTANT_Methodref_info` ，找到对应的方法

       

       虚方法：编译期已经确定，运行期不可变的叫虚方法。有静态方法、私有方法、final 方法、实例构造器、父类方法

       非虚方法：除虚方法外都为非虚方法，比如多态，不确定运行哪个子类方法

       普通调用指令

       - invokestatic：调用静态方法，解析阶段确定唯一方法版本
       - invokespecial：调用 `<init>` 方法、私有及父类方法，解析阶段确定唯一方法版本
       - invokevirtual：调用所有虚方法
       - invokeinterface：调用接口方法

       动态调用指令：

       - invokedynamic：动态解析出需要调用的方法，然后执行

       > 对应的打印如下字节码

       ![方法调用的虚方法与非虚方法字节码](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/%E6%96%B9%E6%B3%95%E8%B0%83%E7%94%A8%E7%9A%84%E8%99%9A%E6%96%B9%E6%B3%95%E4%B8%8E%E9%9D%9E%E8%99%9A%E6%96%B9%E6%B3%95%E5%AD%97%E8%8A%82%E7%A0%81.jpg)

       ```java
       public class Son extends Father {
       
           public Son() {
               super();
           }
       
           public Son(int age) {
               this();
           }
       
           // 不是重写的父类的静态方法，因为静态方法不能被重写
           public static void showStatic(String str) {
               System.out.println("son " + str);
           }
       
           private void showPrivate(String str) {
               System.out.println("son private " + str);
           }
       
           public void show() {
               // =========================== 非虚方法 ===========================
               showStatic("good"); // invokestatic
               super.showStatic("nice"); // invokestatic
               showPrivate("Kimochi"); // invokestatic
               super.showNormalMethod(); // invokestatic
               showFinal(); // 虽然显示的是 invokevirtual，但因为被 final 修饰，不能被子类重写，所以也是非虚方法
               // =========================== 虚方法 ===========================
               showNormalMethod(); // invokevirtual，子类会重写父类方法，编译期确定不下来
               info(); // invokevirtual
       
               MethodInterface in = null;
               in.methodA(); // invokeinterface 要想运行成功，需要子类实现方法，重写时又不知子类是谁。所以表现为虚方法
           }
       
           private void info() { }
       
           public static void main(String[] args) {
               Son son = new Son();
               son.show();
           }
       }
       
       class Father {
       
           public Father() {
               System.out.println("father 的空参构造");
           }
       
           public static void showStatic(String str) {
               System.out.println("father " + str);
           }
       
           public final void showFinal() {
               System.out.println("father show final");
           }
       
           public void showNormalMethod() {
               System.out.println("father normal method");
           }
       }
       
       interface MethodInterface {
           void methodA();
       }
       ```

       函数式接口创建对象为 invokedynamic，创建的对象是谁的确定不了，是根据等号右边的值来确定的，有点类似于 Python 这样的动态语言，info = 13，根据 13 来确定是 int 类型

       ```java
       Func func = s -> { // invokedynamic
           return true;
       }
       ```

       **虚方法表：**

       JVM 为了提高性能呢，它在类的方法区建立一个虚方法表 virtual method table（非虚方法不会出现在表中）来实现使用索引表来代替查找。这样在子类重写之后，就不用向上一层层判断有没有改方法，而是直接用自己的方法

       虚方法表会在类加载的 `链接阶段` 被创建并开始初始化，类的变量初始值准备完成之后，JVM 会把该类的方法表也初始化完毕。

       如果类中重写了方法，那么调用时会在自己重写了的虚方法表中查找，如果没有才到 Object 的虚方法表中查找

       <img src="https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/%E6%96%B9%E6%B3%95%E8%B0%83%E7%94%A8%E4%B9%8B%E8%99%9A%E6%96%B9%E6%B3%95%E8%A1%A8.jpg" alt="方法调用之虚方法表" style="zoom: 33%;" />

       ```java
       public class CockerSpaniel extends Dog implements Friendly{
           @Override
           protected void finalize() { }
           public void eat(){ }
           @Override
           public void sayHello() { }
           @Override
           public void sayGoodbye() { }
           public static void main(String[] args) {
               System.out.println(new CockerSpaniel().toString());
           }
       }
       class Dog {
           public void sayHello(){ }
       
           @Override
           public String toString() {
               return "Dog";
           }
       }
       interface Friendly {
           void sayHello();
           void sayGoodbye();
       }
       ```

       > 比如没有重写的指向 Object，重写了的指向自己，比如自定义对象 Son，它没重写 toString()，父对象 Father 也没有重写 toString()，那么调用 Son.toString() 时就会调用 Object 的 toString() 

     - 方法返回地址 Return Address

       存放调用该方法的 PC 寄存器的值。一个方法的结束，有两种方式：1. 正常执行完成 2. 出现未处理的异常，非正常退出，无论通过哪种方式退出，在方法退出后都返回到该方法被调用的位置

       i. 方法正常退出时，<font color='red'>调用者的程序计数器的值会作为返回地址，即调用该方法指令的下一条指令地址</font>

       ii. 方法异常退出时，不会给调用者返回值，返回地址要通过异常表来确定，栈帧不会保存这部分信息

   - ==堆（重点优化）：==年轻代、年老代

     ![JVM metaspace](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/JVM%20metaspace.png)

     年轻代是类的诞生、成长、消亡的区域，而它又分为 Eden 区和 Survivor 区，所有的类都是在 Eden 区被 new 出来的。Survivor 区呢又分为 Survivor 0 区和 Survivor 1 区。当 Eden 的空间用完时，程序又需要创建对象，JVM 的垃圾回收器就会触发 Minor GC 采用 [复制清除算法](#fuzhiqingchu) 对 Eden 区进行垃圾回收，将 Eden 区中不再被其他对象所引用的对象进行销毁。然后将 Eden 区中剩余的对象移动到 S0 区。若 S0 区也满了，再对该区进行复制清除，然后移动到 S1 区。就这样反复 15 次后还没回收掉再移动到年老代。若年老代也满了，那此时就会触发 FullGC 进行内存清理，这时使用到的是标记压缩算法。年老代执行了 Full GC 后发现依然无法进行对象的保存，就会产生 OOM 异常 "OutOfMemoryError"，通常 Full GC 所消耗的性能是 Minor GC 的十倍以上

     > GC 策略的话，会根据实际业务来测试
     >
     > - 服务器如果是单核的，一般会用 serial 的 GC 机制
     >
     > - 多线程的可以使用 parallel 的 GC 机制
     > - 对事务有要求且希望不要因为 Full GC 的卡顿导致服务器的卡顿或是延迟，希望更低的延迟的话，我们会采用 CMS 的策略（为什么延迟比较低：不是等堆满了才回收的，而是采用分段回收）
     >
     > 如果出现 Java.lang.OutOfMemoryError：Java heap space 异常，说明 Java 虚拟机的堆内存不够。
     >
     > 原因有二：
     >
     > - Java 虚拟机的堆内存设置不够，可以通过参数 - Xms、-Xmx 来调整。
     > - 代码中创建了大量对象，并且长时间不能被垃圾收集器收集（GC 链能够指向 GC ROOTS）
     >
     > 新 new 出来的对象在堆里面，堆又在内存里面

   - 方法区(Java 8 前叫 Permanent Gen 永久带)  几乎不会被回收，Java 8 开始称之为元数据，所属于堆

   - PC 寄存器：存储下一条要执行的指令地址

     - 有什么用？因为 CPU 需要不停的切换各个线程，切换回来的时候得知道接着从哪开始继续执行。

     - 为什么设置为线程私有？还是为了准确地记录各个线程正在执行的当前字节码指令地址，切换回来的时候得知道接着从哪开始继续执行。

   - 本地方法栈

     虚拟机栈用于管理 Java 方法的调用，而本地方法栈管理本地方法库、本地接口的调用，线程私有，内存可动态配置大小

   - 本地接口、本地方法库

     执行非 Java 代码，比如原子引用 AtomicInteger 底层就是 native 方法，用它的就是因为 C++ 底层是汇编，执行效率是最高的

2. [Memory Management in Java Interview Questions (+Answers) | Baeldung](https://www.baeldung.com/Java-memory-management-interview-questions)

3. **JVM内存模型**

   - 类加载器：负责加载class文件

   - 运行时内存分为两部分

     - 线程私有内存（栈内存）：本地方法栈，PC程序寄存器

     - 线程共享内存（堆内存）：静态变量、常量、类信息、运行时常量池、实例变量(new出来的对象)

       Method Area 方法区（class文件在方法区）：方法区是被所有线程共享，所有字段和方法字节码，以及一些特殊方法如构造函数，接口代码也在此定义。简单说，所有定义的方法的信息都保存在该区域，此区属于共享区间。 静态变量+常量+类信息+运行时常量池存在方法区中，实例变量存在堆内存中

       > 总结：栈管运行、堆管存储

4. **谈谈你对类加载器的理解**

   > Java 中的所有类，必须被装载到 JVM 中才能运行，这个装载工作是由 JVM 中的类装载器完成的，类装载器所做的工作实质是把类文件从硬盘读取到内存中

   类加载器的作用：

   - 类加载器子系统负责从文件系统或者网络中加载 class 文件， class 文件在文件开头有特定的文件标识（cofe babe）

   - ClassLoader 只负责把 .class 字节码文件加载到内存，至于它是否可以运行则由 Execution Engine 决定

     > 过年相亲，七大姑八大姨把女孩带过来了，成不成就靠我自己（Execution Engine）来决定

   - 加载的类信息存放于一块称为方法区的内存空间（1.8 后叫元空间）。除了类的信息外，方法区中还会存放运行时常量池信息，可能还包括字符串字面量和数字常量（这部分常量信息是 class 文件中常量池部分的内存映射）

     > 运行时常量池：常量池在堆中，运行时把它加载到内存里，就叫运行时常量池

   虚拟机自带的类加载器：

   - 启动类加载器 BootstrapClassLoader
     - 由 C/C++ 实现，嵌套在 JVM 内部，用来加载 $JAVA_HOME/jre/lib/rt.jar 等 Java 核心库，用来提供 JVM 自身需要的类
     - 它就是顶层父类加载器，它加载 `扩展类加载器` 和 `应用类加载器` ，由于是用 C++ 实现的，所以用 Java 代码打印它是个 null
     - 出于安全考虑，启动类加载器只加载包名为 java、javax、sun 等开头的类
   - 扩展类加载器 ExtensionClassLoader
     - 由 Java 语言编写，由 sun.misc.Launcher$ExtClassLoader 实现且继承于 ClassLoader，父类为启动类加载器
     - 加载 jre/lib/ext 扩展目录的类库，如果我们自己创建的 jar 放在此目录下，也会自动由它加载
   - 应用程序类加载器 ApplicationClassLoader
     - 也是 Java 语言编写，由 sun.misc.Launcher$AppClassLoader 实现且继承于 ClassLoader，父类为扩展类加载器
     - 负责加载环境变量 classpath 或系统属性 java.class.path 指定路径下的类库
     - 它是程序中默认的类加载器，一般我们自己创建的 Java 应用类都是由它来完成加载，通过 ClassLoader.getSystemClassLoader(); 来获取该类加载器

   ```java
   public static void main(String[] args) {
       Object obj = new Object();
       System.out.println(obj.getClass().getClassLoader());
       MyObject myObject = new MyObject();
       System.out.println(myObject.getClass().getClassLoader());
       System.out.println(myObject.getClass().getClassLoader().getParent());
       System.out.println(myObject.getClass().getClassLoader().getParent().getParent());
   }
   // null
   // sun.misc.Launcher$AppClassLoader@18b4aac2
   // sun.misc.Launcher$ExtClassLoader@74a14482
   // null
   ```

   **JVM类加载的过程（生命周期）| 类加载机制**

   三阶段五步骤

   加载 Loading - 链接 Linking（验证、准备、解析） - 初始化 Initialization

   加载、验证、准备、解析和初始化五个阶段

   - 加载 Loading：

     i. 通过一个类的全限定类名来获取此类的二进制流

     ii. 将字节流所代表的静态存储结构转化为方法区的运行时数据结构

     iii. 在堆中（也就是内存中）生成一个代表该类的 java.lang.Class 对象

     > 方法区是比较虚的概念，具体落地 1.8 以前叫永久代，1.8 以后叫元空间

   - 验证 Verify：目的在于确保 Class 文件的字节流中包含符合当前虚拟机要求，保证被加载类的一个正确性

     比如每个 .class 文件都会以 COFE BABE 开头

   - 准备 Prepare：

     - 为类变量分配内存并且设置该类变量的默认初始值

       > 比如 private static int a = 1; 这里 a 的准备阶段初始值就是 0

     - 但是不包含 final 修饰的 static 常量，因为 final 在编译时就会分配内存，声明的 5 就是 5，后期都不能被修改了

     - 这里不会被实例变量分配初始化，因为还没创建对象，还是在类的加载过程

       > 类变量会分配到方法区；而实例变量是随着对象一起分配到 Java 堆中

   - 解析 Resolve：符号引用替换为直接引用 

     - 符号引用：用 #1 2 3 来间接引用

       > Java 中，一个 Java 类将会编译成一个 class 文件。在编译时，Java 类并不知道所引用的类的实际地址，因此只能使用符号引用来代替。比如 org.simple.People 类引用 org.simple.Language 类，在编译时 People 类并不知道 Language 类的实际内存地址

     - 直接引用：指针直接指向实际的内存地址

   - 初始化 Initialization：

     ==在此步骤初始化时，类加载器会把静态代码块和静态变量的显示赋值都会放到一个叫 `<clinit>()` 的构造方法中执行==

     - 是执行<font color='red'>类构造器方法</font> `<clinit>()` 的过程，它不需要定义，是 javac 编译器自动收集类中的所有类变量的赋值和静态代码块的语句合并而来的

       > 注意：要 **变量赋值** 和 **静态代码块** 两者条件同时出现，字节码文件里才会出现 `<clinit>()` 
       >
       > ```java
       > private static int num = 1;
       > 
       > static {
       >     num = 2;
       > }
       > ```

       ![ClassLoader 初始化](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/ClassLoader%20%E5%88%9D%E5%A7%8B%E5%8C%96.jpg)

       > number 变量定义可以放在下面，但是链接阶段下的 prepare 阶段会先把 number = 0 --> inital: 20 --> 10

     -  `<clinit>()` （class init）：不同于<font color='red'>类的构造器</font> ，构造器在 JVM 视角下对应的是 `<init>()` 方法，任何一个类声明以后，内部都会存在一个类的无参构造，<font color='red'>所以任何一个类的字节码对应 Methods 中都会有 `<init>()` </font> 方法

     - 如果该类具有父类，JVM 会保证先执行父类的 `<clinit>()` ，也就是子类加载之前先加载父类

       ```java
       public static void main(String[] args) {
           System.out.println(Son.b);
       }
       static class Father {
           public static int A = 1;
           static {
               A = 2;
           }
       }
       static class Son extends Father {
           public static int b = A;
       }
       // 打印 2，子类加载前先加载父类
       ```

     - JVM 必须保证一个类的 `<clinit>()` 方法（只会加载一次，之后都是操作它的缓存）会多线程下被同步加锁来保证线程安全

       ```java
       public class DeadThreadTest {
       
           public static void main(String[] args) {
               new Thread(() -> {
                   System.out.println(Thread.currentThread().getName() + " 开始");
                   DeadThread deadThread = new DeadThread();
                   System.out.println(Thread.currentThread().getName() + " 结束");
               }, "T1").start();
       
               new Thread(() -> {
                   System.out.println(Thread.currentThread().getName() + " 开始");
                   DeadThread deadThread = new DeadThread();
                   System.out.println(Thread.currentThread().getName() + " 结束");
               }, "T2").start();
           }
       
       }
       
       class DeadThread {
       
           static {
               if (true) {
                   System.out.println(Thread.currentThread().getName() + " 正在初始化当前类...");
                   while (true) { // while 执行，一直循环相当于加锁
                   }
               }
           }
       }
       ```

5. **父类双亲委派机制**

   > 主要起一个保护作用，项目中 String 类肯定大家都在用，假如我把自定义的 String 类传给同事，那他打开整个项目一下就挂了，为了防止被攻击呢，就有了 `父类双亲委派机制`

   what：Java 虚拟机对 class 文件采用的是 <font color='red'> 按需加载 </font> 的方式，也就是说当需要使用该类时才会将它的 class 文件加载到内存生成 class 对象。而且加载某个类的 class 文件时，Java 虚拟机采用的是 <font color='red'> 双亲委派机制 </font>，即把请求交由父类处理，它是一种任务委派模式

   how 工作原理：

   - 如果一个类加载器收到了类加载请求，它并不会自己先去加载，而是把这个请求委托给父类加载器执行

   - 如果父类加载器还存在其父类加载器，就进一步向上委托，依次递归，请求最终将到达顶层启动类加载器

   - 如果父类加载器可以完成类加载任务，就成功返回，倘若父类加载器无法完成此加载任务，子加载器才会尝试自己去加载。

     >  比如我们自己写个 String 类，类加载器会一层层向上找，先找应用类加载器，没有接着找扩展类加载器，还没有到顶层 Bootstrap 启动类加载器去找，发现 rt.jar 下面有 String 类了，就会直接加载，而不加载我们自己写的 String 类

     <img src="https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/%E7%88%B6%E7%B1%BB%E5%8F%8C%E4%BA%B2%E5%A7%94%E6%B4%BE%E6%9C%BA%E5%88%B6.jpg" alt="父类双亲委派机制" style="zoom:33%;" />

   why 优势：

   - 避免类的重复加载

   - 保护程序安全，防止核心 API 被随意篡改，出于安全考虑，Bootstrap 启动类加载器只加载包名为 java、javax、sun 等开头的类，我们自己创建的 java.lang 包下的类运行会报错

     > 自定义类：java.lang.String；自定义类：java.lang.MyTest（报错：阻止创建 java.lang 开头的类）

6. **请你谈谈 JVM 垃圾回收机制（Java 中如何判断一个对象是否是一个垃圾 | JVM 垃圾回收时如何确定垃圾 | 你知道有哪些垃圾回收算法吗？）**

   [JVM 垃圾回收算法 - 尚硅谷 JVM 全套教程，百万播放，全网巅峰（宋红康详解 java 虚拟机）_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1PJ411n7xZ?p=138&spm_id_from=pageDriver)

   线程共享的部分堆、方法区需要垃圾回收

   <font color='red'>什么是垃圾？垃圾是指在程序运行中没有任何指针指向的对象</font>

   常见垃圾回收算法：

   一共两类：1. 标记阶段：引用计数算法、可达性分析算法 2. 清除阶段：标记清除算法、复制算法、标记压缩算法

   - 引用计数算法（Reference Counting）：每个对象保存一个整型的引用计数器属性。用于记录对象被引用的情况。对于一个对象 A，只要有任何一个对象引用了 A，则 A 的引用计数器就加 1；当引用失效时，引用计数器就减 1. 只要对象对象 A 的引用计数器值为 0，就代表可以进行回收。

     缺点：无法处理循环引用问题

     ```java
     public class RefCountGC {
         Object reference = null; // 属性变量
         // 这个成员属性的唯一作用就是占用一点内存
         private byte[] bigSize = new byte[5 * 1024 * 1024];
         public static void main(String[] args) {
             RefCountGC obj1 = new RefCountGC();
             RefCountGC obj2 = new RefCountGC();
             obj1.reference = obj2;
             obj2.reference = obj1;
             obj1 = null;
             obj2 = null;
             // 显示的执行垃圾收集行为，判断obj1 和 obj2是否被回收？
             System.gc();
         }
     }
     ```

     ```java
     // 执行 System.gc(); 垃圾回收前
     Heap
      PSYoungGen      total 151040K, used 18012K [0x0000000717780000, 0x0000000722000000, 0x00000007c0000000)
       eden space 129536K, 13% used [0x0000000717780000,0x0000000718917260,0x000000071f600000)
       from space 21504K, 0% used [0x0000000720b00000,0x0000000720b00000,0x0000000722000000)
       to   space 21504K, 0% used [0x000000071f600000,0x000000071f600000,0x0000000720b00000)
      ParOldGen       total 345600K, used 0K [0x00000005c6600000, 0x00000005db780000, 0x0000000717780000)
       object space 345600K, 0% used [0x00000005c6600000,0x00000005c6600000,0x00000005db780000)
      Metaspace       used 2656K, capacity 4486K, committed 4864K, reserved 1056768K
       class space    used 282K, capacity 386K, committed 512K, reserved 1048576K
     ```

     ```java
     // 执行 System.gc(); 垃圾回收后
     Heap
      PSYoungGen      total 151040K, used 1295K [0x0000000717780000, 0x0000000722000000, 0x00000007c0000000)
       eden space 129536K, 1% used [0x0000000717780000,0x00000007178c3ee8,0x000000071f600000)
     ```

   - 可达性分析算法

     <img src="https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/%E5%8F%AF%E8%BE%BE%E6%80%A7%E5%88%86%E6%9E%90%E7%AE%97%E6%B3%95.jpg" alt="可达性分析算法" style="zoom:33%;" />

     有效地解决在引用计数算法中循环引用的问题，防止内存泄漏的发生。按照引用计数算法来说右边的不是垃圾，而在可达性分析算法里面它是垃圾

     **JVM 如何判断一个对象是否该被 GC？ | 什么叫 GCRoots？**

     从根节点出发进行搜索遍历，能被根节点直接或间接的用引用链连接着的就是可达对象，否则为不可达对象，就可以标记为垃圾对象

     **哪些能能作为 GC Roots 对象（顶点）？**

     i. 虚拟机栈中引用的对象（也就是栈帧中的局部变量表）

     ii. 方法区中的 static 修饰的类静态属性引用的对象

     iii. 方法区中常量引用的对象

     iv. 本地方法栈中 JNI（java native interface）引用的对象，比如线程中的 start 方法，就是 native 方法

     ```java
     public class GCRootsDemo {
     
     //    private static final GCRootsDemo3 g3 = new GCRootsDemo3(); // 常量引用的对象
     //    private static GCRootsDemo2 g2 = new GCRootsDemo2();; // 类静态属性引用的对象
     
         public static void main(String[] args) {
             m1();
         }
     
         private static void m1() {
             GCRootsDemo g1 = new GCRootsDemo(); // 虚拟机栈中引用的对象（栈帧中的局部变量表）
         }
     }
     ```

     

     **Object 下的 finalize() 方法（对象的 finalization 机制）**

     Java 语言提供了对象终止（finalization）机制来允许开发人员提供对象被销毁之前的自定义处理逻辑。

     当垃圾回收器发现没有引用指向一个对象时会先调用这个对象的 finalize () 方法来先自我拯救一下。

     finalize () 方法允许在子类中被重写，用于在对象被回收时进行资源释放。通常在这个方法中进行一些资源释放和清理的工作，比如关闭文件、套接字和数据库连接等（有点像 servlet，在 destroy 销毁前可以自定义处理逻辑）。

     不推荐主动去调用 finalize () 方法，原因有三点：

     i. 调用 finalize () 方法会导致对象复活

     ii. finalize () 方法执行的时间是由 GC 线程决定的，所以如果不发生 GC 的话， finalize () 就永远不会执行

     iii. 如果自己重写的很烂的话（比如死循环）会严重影响 GC 的性能

     finalize () 方法导致的三种状态

     如果从所有的根节点都无法访问到某个对象，说明该对象己经不再使用了。按理说该对象需要被垃圾回收。但事实上呢它处于一种 “刀下留人” 的状况，所以它涉及了三种状态：1. 可触及 2. 可复活 3. 不可触及

     i. 就是从根节点开始通过引用链寻找是可以到达该对象的，此时对象会被判定为 `可触及` 状态

     ii. 对象的所有引用都被释放了，也就是引用链断了，本来该被垃圾收集器回收，但是对象觉得自己还能调用重写的 finalize () 方法复活一下，此时为 `可复活` 状态，如果此时该对象能和引用链的对象连接上就不会被回收

     iii. 调用完 finalize () 方法后对象没有复活会进入 `不可触及` 状态，就再也不可能复活了，因为 finalize () 方法只能被调用一次

     > 判断一个对象是否可被回收，会经历两次标记，具体过程：
     >
     > 1. 对象 A 到 GC Roots 没有引用链，则会进行第一次标记
     > 2. 判断对象是否有必要执行 finalize () 方法
     >    - 如果对象 A 没有重写 finalize () 方法，或者 finalize () 方法已经调用过了，则对象 A 会被判定为不可触及的。
     >    - 如果对象 A 重写 finalize () 方法，且还未执行过，那么 obj 会被插入到 F-Queue 队列中，由一个虚拟机自动创建的、低优先级的 Finalizer 线程触发其 finalize () 方法执行。
     >    - 调用完重写的 finalize () 方法后，GC 会对 F-Queue 队列中的对象进行第二次标记，如果此时该对象能和引用链的对象连接上就不会被回收。否则就再也不可能复活了，因为 finalize () 方法只能被调用一次

     ```java
     public class CanReliveObj {
     
         // 类变量，属于GC Roots的一部分
         public static CanReliveObj canReliveObj;
     
         public static void main(String[] args) throws InterruptedException {
             canReliveObj = new CanReliveObj();
             canReliveObj = null;
             System.gc();
             System.out.println("-----------------第一次gc操作------------");
             // 因为Finalizer线程的优先级比较低，暂停2秒，以等待它
             Thread.sleep(2000);
             if (canReliveObj == null) {
                 System.out.println("obj is dead"); // 不重写 finalize () 第一次就是 dead
             } else {
                 System.out.println("obj is still alive"); //  重写了的话会触发一次 “刀下留人”，然后拯救自己一次
             }
     
             System.out.println("-----------------第二次gc操作------------");
             canReliveObj = null; // 第二次把它置为 null，由于 finalize() 方法只能调用一次，这一次就得死了
             System.gc();
             // 下面代码和上面代码是一样的，但是 canReliveObj却自救失败了
             Thread.sleep(2000);
             if (canReliveObj == null) {
                 System.out.println("obj is dead");
             } else {
                 System.out.println("obj is still alive");
             }
         }
         // =========================== print out ===========================
         // 调用当前类重写的finalize()方法
         // -----------------第一次gc操作------------
         // obj is still alive
         // -----------------第二次gc操作------------
         // obj is dead
     
         // 此方法只会调用一次
         @Override
         protected void finalize() throws Throwable {
             super.finalize();
             System.out.println("调用当前类重写的finalize()方法");
             canReliveObj = this; // 当前待回收的对象在 finalize () 方法中与引用链上的对象 obj 建立了联系
         }
     }
     ```

     **内存泄漏（&工具使用）：**当不想再使用一个对象时，这个对象还在被直接或间接的引用着，没办法被垃圾收集器回收掉，可以先使用 JVisualVM 工具捕获 heap dump 文件，然后用 Eclipse 出的 Memory Analyzer (MAT) 工具查看这个对象对应这条链路的 GC Roots 是谁

     使用 VM 命令 -Xms8m -Xmx8m -XX:+HeapDumpOnOutOfMemoryError 模拟堆内存溢出，使用 JProfiler 打开生成的堆文件 java_pid26000.hprof

     ```java
     Exception in thread "main" java.lang.OutOfMemoryError: Java heap space
     	at com.liuilin.JVM.GC.HeapOOM.<init>(HeapOOM.java:17)
     	at com.liuilin.JVM.GC.HeapOOM.main(HeapOOM.java:23)
     java.lang.OutOfMemoryError: Java heap space
     Dumping heap to java_pid26000.hprof ...
     Heap dump file created [4998650 bytes in 0.011 secs]
     ```

     ```java
     public class HeapOOM {
     
         byte[] buffer = new byte[1024 * 1024]; // 创建 1M 文件
     
         public static void main(String[] args) {
             List<HeapOOM> list = new ArrayList<>();
             Date date = new Date();
             for (int i = 1; i <= 100; i++) {
                 list.add(new HeapOOM());
                 // 暂停一会儿线程
                 try { TimeUnit.MICROSECONDS.sleep(200); } catch (InterruptedException e) { e.printStackTrace(); }
             }
             System.out.println("数据添加完毕");
             new Scanner(System.in).next();
             list = null; // 使对象为空，好像垃圾收集器回收对象
             date = null;
             System.out.println("list and date Object 已清空，请继续操作");
             new Scanner(System.in).next();
             System.out.println("已结束");
         }
     }
     ```

   - <span id='fuzhiqingchu'>复制清除算法（Mark - Sweep）</span>：发生在年轻代，复制对象之后，谁空谁是 To 区

     当堆中的有效内存空间（available memory）被耗尽的时候，就会停止整个程序（也被称为 stop the world），然后会进行标记、清除操作

     - 标记：GC 会从引用根节点开始遍历，<font color='red'>标记所有被引用的对象</font>，一般是在对象的 Header 中记录为可达对象
     - 清除：GC 会对堆内存从头到尾进行线性的遍历，如果发现某个对象在其 Header 中没有标记为可达对象，就会将其回收

     <img src="https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/GC%20%E6%A0%87%E8%AE%B0%E6%B8%85%E9%99%A4%E7%AE%97%E6%B3%95.jpg" alt="GC 标记清除算法"  />

     **优缺点：**它的优点的通用性高，比较容易理解，但它也有很多缺点：

     - 但是它的效率不太高，会进行两次的数据全遍历
     - 在进行 GC 时，会停止整个程序（Stop The World），导致系统停顿
     - 这种方式清理出来的空闲空间是不连续的，会产生内存碎片。而且还需要维护一个空闲列表，列表也要占用内存空间

     **何为清除？**

     这里所谓的清除并不是真的置空，而是把需要清除的对象地址保存在空闲的地址列表里。下次有新对象需要加载时呢先判断垃圾的位置空间够不够，够的话才存放

   - 复制算法

     ![GC 复制算法](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/GC%20%E5%A4%8D%E5%88%B6%E7%AE%97%E6%B3%95.jpg)

     

   [JVM Garbage Collectors | Baeldung](https://www.baeldung.com/jvm-garbage-collectors)

7. **你说你做过 JVM 调优和参数配置，请问如何盘点查看 JVM 系统默认值**

   查看一个 JVM 的初始值：

   jps：查看 java 进程和应用程序主类的完整包名

   jinfo -flag：查看某个 JVM 属性值是否开启

   jinfo -flags：查看当前能查看到的所有参数

   > Non-default：默认的参数信息
   >
   > Command line：自己设置的参数信息

   **JVM 参数类型**

   - -X 参数

   - -XX 参数

     - Boolean 类型：-XX:+ 或 - 某个属性值，+ 表示开启；- 表示关闭

       > -XX:+PrintGCDetails：打印 GC 收集细节

     - KV 设置值类型：-XX: 属性 Key = 属性值 Value

       > -XX:MetaspaceSize=1024m	# 设置元空间为 1 G
       >
       > -XX:MaxTenuringThreshold=15	# 设置到老年代所要经过的次数

     那有两个经典参数：-Xms 和 -Xmx 你如何解释呢？（坑题！）

     它两还是属于 -XX 参数，相当于

     -Xms = -XX:InitialHeapSize

     -Xmx = -XX:MaxHeapSize

   **查看参数盘点家底**

   > `=` 是默认参数，`:=` 是修改后的最新参数 

   java -XX:+PrintFlagsInitial	# 查看初始值

   java -XX:+PrintFlagsFinal	# 查看最终值（初始值可能被修改掉）

   java -XX:+PrintCommandLineFlags -version	# 打印命令行参数，最后可以看到用的什么垃圾收集器

   ```java
   PS C:\Users\Daniel> java -XX:+PrintCommandLineFlags -version
   -XX:InitialHeapSize=530074624 -XX:MaxHeapSize=8481193984 -XX:+PrintCommandLineFlags -XX:+UseCompressedClassPointers -XX:+UseCom
   pressedOops -XX:-UseLargePagesIndividualAllocation -XX:+UseParallelGC
   openjdk version "1.8.0_292"
   OpenJDK Runtime Environment (build 1.8.0_292-b10)
   OpenJDK 64-Bit Server VM (build 25.292-b10, mixed mode)
   ```

   ```bash
PS C:\Users\Daniel> jps
   10704
   11024 Jps
   22872 RemoteMavenServer36
   11548 HelloGC
   26572 Launcher
   PS C:\Users\Daniel> jinfo -flag PrintGCDetails 11548
   -XX:+PrintGCDetails
   PS C:\Users\Daniel> jinfo -flag MetaspaceSize 11548
   -XX:MetaspaceSize=21807104
   PS C:\Users\Daniel> jinfo -flag MaxTenuringThreshold 11548
   -XX:MaxTenuringThreshold=15
   PS C:\Users\Daniel> jinfo -flags 22856
   Attaching to process ID 22856, please wait...
   Debugger attached successfully.
   Server compiler detected.
   JVM version is 25.292-b10
   Non-default VM flags: -XX:CICompilerCount=4 -XX:InitialHeapSize=530579456 -XX:MaxHeapSize=8482979840 -XX:MaxNewSize=2827485184
   -XX:MinHeapDeltaBytes=524288 -XX:NewSize=176685056 -XX:OldSize=353894400 -XX:+UseCompressedClassPointers -XX:+UseCompressedOops
    -XX:+UseFastUnorderedTimeStamps -XX:-UseLargePagesIndividualAllocation -XX:+UseParallelGC
   Command line:  -javaagent:C:\Users\Daniel\AppData\Local\JetBrains\Toolbox\apps\IDEA-U\ch-0\212.4746.92\lib\idea_rt.jar=9231:C:\
   Users\Daniel\AppData\Local\JetBrains\Toolbox\apps\IDEA-U\ch-0\212.4746.92\bin -Dfile.encoding=UTF-8
   
   ```
   
8. **你平时工作用过的 JVM 常用基本配置参数有哪些？**

   [Java 8 JVM 参数 Java Platform, Standard Edition Tools Reference for Oracle JDK on Windows, Release 8](https://docs.oracle.com/javase/8/docs/technotes/tools/windows/index.html)

   - -Xms（ -XX:+InitialHeapSize）memory startup：初始化大小内存，默认为物理内存的 1/64

   - -Xmx（-XX:+MaxHeapSize）memory max：最大分配内存，默认为物理内存的 1/4

   - -Xss（-XX:+ThreadStackSize）stack size：设置单个线程栈的大小，默认为 512k~1024k（值依赖于是哪个平台）

   - -Xmn？（-XX:+MetaspaseSize）：该值越大，出现 Stack Overflow 异常的概率就变小了

     元空间的本质和永久代类似，都是对 JVM 规范中方法区的实现。不过元空间与永久代之间最大的区别在于<font color='red'>元空间并不在虚拟机中，而是使用本地物理内存</font>。因此，默认情况下元空间的大小仅受本地内存限制

   - -XX:+PrintGCDetails：输出 GC 收集日志的详细信息
   
     ```java
     // 设置启动 VM option 为 -Xms10m -Xmx10m -XX:+PrintGCDetails
     public class HelloGC {
         public static void main(String[] args) throws InterruptedException {
             System.out.println("Hello Java");
             byte[] bytes = new byte[50 * 1024 * 1024]; // new 50m 对象，引发OOM
         }
     }
     // ================================== print out ==================================
     // [GC (Allocation Failure) [PSYoungGen: 1631K->488K(2560K)] 1631K->692K(9728K), 0.0009002 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]
     // [GC (Allocation Failure) [PSYoungGen: 488K->496K(2560K)] 692K->748K(9728K), 0.0005780 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]
     // [Full GC (Allocation Failure) [PSYoungGen: 496K->0K(2560K)] [ParOldGen: 252K->585K(7168K)] 748K->585K(9728K), [Metaspace: 3221K->3221K(1056768K)], 0.0056517 secs] [Times: user=0.09 sys=0.00, real=0.01 secs]
     // [GC (Allocation Failure) [PSYoungGen: 0K->0K(2560K)] 585K->585K(9728K), 0.0008178 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]
     // [Full GC (Allocation Failure) [PSYoungGen: 0K->0K(2560K)] [ParOldGen: 585K->568K(7168K)] 585K->568K(9728K), [Metaspace: 3221K->3221K(1056768K)], 0.0055486 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]
     // Heap
     //  PSYoungGen      total 2560K, used 89K [0x00000000ffd00000, 0x0000000100000000, 0x0000000100000000)
     //   eden space 2048K, 4% used [0x00000000ffd00000,0x00000000ffd16510,0x00000000fff00000)
     //   from space 512K, 0% used [0x00000000fff00000,0x00000000fff00000,0x00000000fff80000)
     //   to   space 512K, 0% used [0x00000000fff80000,0x00000000fff80000,0x0000000100000000)
     //  ParOldGen       total 7168K, used 568K [0x00000000ff600000, 0x00000000ffd00000, 0x00000000ffd00000)
     //   object space 7168K, 7% used [0x00000000ff600000,0x00000000ff68e140,0x00000000ffd00000)
     //  Metaspace       used 3278K, capacity 4496K, committed 4864K, reserved 1056768K
     //   class space    used 349K, capacity 388K, committed 512K, reserved 1048576K
     // Exception in thread "main" java.lang.OutOfMemoryError: Java heap space
    // 	at com.liuilin.JVM.GC.HelloGC.main(HelloGC.java:10)
     ```

     - GC：新生代

       ![GC 分配内存详解（PrintGCDetails）](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/GC%20%E5%88%86%E9%85%8D%E5%86%85%E5%AD%98%E8%AF%A6%E8%A7%A3%EF%BC%88PrintGCDetails%EF%BC%89.jpg)

       新生区占 1/3，养老区占 2/3 = 2560k + 9728k = 10m

     - FullGC：老年代

       

       规律：名称 - GC前内存占用 -> GC后内存占用（该区内存总大小）

   - -XX:SuvivorRatio

     新生代（Young 区）中 Eden、s0 和 s1 空间的比例默认 - XX:SurvivorRatio=8， Eden:S0:S1 =8:1:1 

     设置 -XX:SurvivorRatio=4， Eden:S0:S1 = 4:1:1

     SurvivorRatio 值就是设置 eden 区的比例占多少

     > Young 区配置小了 GC 就会很频繁，老年代需要配的很大

   - -XX:NewRatio：配置年轻代与年老代在堆结构的占比

     默认 - XX:NewRatio=2 新生代占 1 老年代 2，年轻代占整个堆的 1/3

     假如 - XX:NewRatio=4 新生代占 1，老年代 4，年轻代占整个堆的 1/5。NewRatio 值就是设置老年代的占比，剩下的 1 给新生代

     新生代 1/3 ，老年代 2/3

     > -Xms10m -Xmx10m -XX:+PrintGCDetails -XX:+UseSerialGC -XX:NewRatio=2

   - -XX:MaxTenuringThreshold：设置垃圾最大年龄，也就是 From 和 To 之间移动的次数

     -XX MaxTenuring Threshold=0：如果设置为0的话，则年轻代对象不经过 Survivor区，直接进入年老代。对于年老代比较多的应用，可以提高效率。

     如果这个值设置的比较大，那么年轻代对象会在 Survivor 区进行多次复制，这样可以增加对象在年轻代的存活时间，不让它那么容易的进入年老代。理论上是这样，但是 Java8 开始就这个值就只能设置为 0-15 之间

   典型 JVM 参数设置案例：

   配置前查看初始参数
   
   ```java
   -XX:G1ConcRefinementThreads=8 
   -XX:GCDrainStackTargetSize=64 
   -XX:InitialHeapSize=530074624 // 530m
   -XX:MaxHeapSize=8481193984 // 8G
   -XX:+PrintCommandLineFlags // 
   -XX:ReservedCodeCacheSize=251658240 
   -XX:+SegmentedCodeCache 
   -XX:+UseCompressedClassPointers 
   -XX:+UseCompressedOops 
   -XX:+UseG1GC // G1 垃圾收集器
-XX:-UseLargePagesIndividualAllocation 
   ```

   配置参数后： -Xms128m -Xmx4096m -Xss1024k -XX:MetaspaceSize=512m -XX:+PrintCommandLineFlags -XX:+PrintGCDetails -XX:+UseSerialGC
   
   ```java
   -XX:InitialHeapSize=134217728 // 128m
   -XX:MaxHeapSize=4294967296 // 4G
   -XX:MetaspaceSize=536870912 // 512m
   -XX:+PrintCommandLineFlags
   -XX:+PrintGCDetails
   -XX:ThreadStackSize=1024 // 1024k
   -XX:+UseCompressedClassPointers
   -XX:+UseCompressedOops
   -XX:-UseLargePagesIndividualAllocation
-XX:+UseSerialGC // 并行垃圾收集器
   ```

   ```java
   public static void main(String[] args) throws InterruptedException {
       long totalMemory = Runtime.getRuntime().totalMemory(); // JVM 总内存量
       long maxMemory = Runtime.getRuntime().maxMemory(); // JVM 试图使用的最大内存量
       System.out.println("TOTAL_MEMORY(-Xms) = " + totalMemory + "（字节）" + (totalMemory / 1024 / 1024) + "MB");
       System.out.println("MAX_MEMORY(-Xmx) = " + maxMemory + "（字节）" + (maxMemory / 1024 / 1024) + "MB");
   }
   // ==================================== print out(32G computer) ====================================
   // TOTAL_MEMORY(-Xms) = 508559360（字节）485MB
   // MAX_MEMORY(-Xmx) = 7540834304（字节）7191MB
   ```

9. **Java 中的四种引用类型及其含义（强软弱虚引用的区别以及 GC 对他们执行怎样的操作）**

   - 强引用：就算 OOM 了也不回收，就是普通的引用 Person p = new Person ()；

     ```java
     private static void softRefMemoryEnough() {
         Object o1 = new Object();
         SoftReference<Object> softReference = new SoftReference<>(o1);
         System.out.println("o1 = " + o1);
         System.out.println("softReference = " + softReference.get());
         o1 = null;
         System.gc();
         System.out.println("o1 = " + o1);
         System.out.println("softReference = " + softReference.get());
     }
     // ================================== print out ==================================
     // o1 = java.lang.Object@75b84c92
     // softReference = softReference = java.lang.Object@75b84c92
     // o1 = null
     // softReference = java.lang.Object@75b84c92
     ```

   - 软引用：需要用 `java.lang.ref.SoftReference` 类来实现，JVM 内存够用时不会被回收，不足时会被回收。通常用在对内存敏感的程序中，像 MyBatis 里面的一些内部类用的就是软引用

     ```java
     /**
      * VM 配置，故意产生大对象并配置小的内存，让它内存不够用了导致 OOM，看软引用的回收情况
      * -Xms10m -Xmx10m -XX:+PrintGCDetails
      */
     private static void softRefMemoryNotEnough() {
         Object o1 = new Object();
         SoftReference<Object> softReference = new SoftReference<>(o1);
         System.out.println("o1 = " + o1);
         System.out.println("softReference = " + softReference.get());
         o1 = null;
         try {
             byte[] bytes = new byte[30 * 1024 * 1024]; // new 30m 大小的对象，导致 OOM
         } catch (Exception e) {
             e.printStackTrace();
         } finally {
             System.out.println("o1 = " + o1);
             System.out.println("softReference = " + softReference.get());
         }
     }
     // o1 = java.lang.Object@75b84c92
     // softReference = java.lang.Object@75b84c92
     // o1 = null
     // softReference = null
     ```

   - 弱引用 WeakReference：需要用 `java.lang.ref.WeakReference` 类来实现，只要发生 GC 就会被回收无论 JVM 内存是否足够都会回收该对象占用的内存

     ```java
     public class WeakReferenceDemo {
         public static void main(String[] args) {
             Object o1 = new Object();
             WeakReference<Object> weakReference = new WeakReference<>(o1);
             System.out.println("o1 = " + o1);
             System.out.println("weakReference = " + weakReference.get());
     
             o1 = null;
             System.gc();
     
             System.out.println("o1 = " + o1);
             // 此时只将 o1 置为了 null，然后进行 GC，没有动 WeakReference 对象，但结果是只要进行了 GC，软引用对象就会被回收
             System.out.println("weakReference = " + weakReference.get());
         }
         // ================================ print out ================================
         // o1 = java.lang.Object@75b84c92
         // weakReference = java.lang.Object@75b84c92
         // o1 = null
         // weakReference = null
     }
     ```

     你既然知道弱引用的话，能谈谈 WeakHashMap 吗？

     只要 key 置为 null 并触发 GC，弱引用对象就会被回收
     
     ```java
     private static void weakHashMap() {
         WeakHashMap<Integer, String> weakHashMap = new WeakHashMap<>();
         Integer key = new Integer(2); // 必须要是 new Integer(2) 对象，因为下面需要把 key 置为 null
         String value = "WeakHashMap";
         weakHashMap.put(key, value);
         System.out.println("weakHashMap = " + weakHashMap);
         key = null; // 只要 key 置为 null 并触发 GC，弱引用对象就会被回收
         System.out.println("weakHashMap = " + weakHashMap);
         System.gc();
         System.out.println("weakHashMap = " + weakHashMap);
     }
     // weakHashMap = {2=WeakHashMap}
     // weakHashMap = {2=WeakHashMap}
     // weakHashMap = {}
     ```
     
   - 虚引用 PhantomReference：
   
     虚引用需要java.lang.ref.PhantomReference类来实现
   
     虚引用并不会决定对象的生命周期。如果一个对象仅持有虚引用，<font color='red'> 那么它就和没有任何引用一样，在任何时候都可能被垃圾回收器回收 </font>，它不能单独使用也不能通过它访问对象，虚引用必须和引用队列（Reference Queue）联合使用。
   
     虚引用的主要作用是跟踪对象被垃圾回收的状态。只是提供了一种确保对象被 finalize 以后，做某些事情的机制。PhantomReference 的 get 方法总是返回 nul，因此无法访问对应的引用对象。其意义仅仅在于监控对象的回收状态，假如一个对象已经进入 finalization 阶段，可以在 GC 回收的前做进一步处理
   
     也就是说设置虚引用关联的唯一目的就是 <font color='red'> 在这个对象被收集器回收的前收到一个系统通知或者后续添加进一步的处理 </font>。类似于 Servlet 的生命周期，在 destory 之前可以再做点事情。比如打印一句话 —— 我要被回收啦（相当于一种通知机制）
   
     ```java
     public class PhantomReferenceDemo {
         public static void main(String[] args) throws InterruptedException {
             Object o1 = new Object();
             ReferenceQueue<Object> referenceQueue = new ReferenceQueue<>();
             PhantomReference<Object> phantomReference = new PhantomReference<>(o1, referenceQueue);
     
             System.out.println("o1 = " + o1);
             System.out.println("phantomReference = " + phantomReference.get());
             System.out.println("referenceQueue = " + referenceQueue.poll());
     
             o1 = null;
             System.gc();
             Thread.sleep(500); // 确保执行完 GC
             System.out.println("==================== ok ====================");
     
             System.out.println("o1 = " + o1);
             System.out.println("phantomReference = " + phantomReference.get());
             // 打印出来对象，原因是弱引用被垃圾回收前一刻会放入引用队列
             System.out.println("referenceQueue = " + referenceQueue.poll());
         }
         // ================================ print out ================================
         // o1 = java.lang.Object@75b84c92
         // phantomReference = null
         // referenceQueue = null
         // ==================== ok ====================
         // o1 = null
         // phantomReference = null
         // referenceQueue = java.lang.ref.PhantomReference@6bc7c054
     }
     ```

引用队列 ReferenceQueue：软 / 若 / 虚引用都有个机制，被回收前需要保存在引用队列下

> 软 / 若 / 虚引用的对象调 get 方法只会返回 null，但是一旦发生 GC，就会把对象放入到引用队列里

软 / 弱应用实际应用场景：假如有一个应用需要读取大量本地图片（安卓手机、Chrome 浏览器和前端都是需要加载大量图片），每次请求都从硬盘读取的话很慢，会严重影响系统性能。可以加载进缓存，但是如果一次性全部加载进内存中又有可能造成 OOM

解决（软引用、弱引用）：设计思路是用一个 HashMap 来保存图片的路径和相应图片对象关联的软引用（或弱引用）之间的映射关系，在内存不足时， JVM 会自动回收这些缓存图片对象所占用的空间，从而有效地避免了 OMM 的问题

   > ```java
   > Map<String, SoftReference<Bitmap>> imageCache = new HashMap<String,SoftReference<Bitmap>>();
   > ```
   >
   > 内存够的时候用缓存 + 内存，不够要 GC 时，就把缓存的那部分释放加给内存，从而避免 OOM
   >
   > MyBatis 缓存源码那块大量使用到的就是软引用

10. **GC 的常见算法，CMS 以及 G1 的垃圾回收过程，CMS 的各个阶段哪两个是 Stop the world 的，CMS 会不会产生碎片，G1 的优势**

11. **GC 每个算法的优缺点和原理(标记清除和标记整理算法的理解以及优缺点)**

    - 标记清除算法（年老代）

      - 标记：标记的过程其实就是遍历所有的GC Roots，然后将所有GC Roots可达的对象标记为存活对象
      - 清除：清除的过程会遍历堆中所有的对象，将没有标记的对象全部清除掉
      - 缺点：内存不连续，对象放不下时有可能提前触发GC；效率不高：先标记，后清除

    - 复制清除算法（分配担保原则）（年轻代​）

      - 原理：将原有的内存空间分为两块，每次只使用其中一块，在垃圾回收时，将正在使用的内存中的存活对象复制到未使用的内存块中，然后清除正在使用的内存块中的所有对象
      - 缺点：内存缩小为原来的一半
      - 优点： 效率高 ，存放的对象本身就是一些朝生夕死的对象（没有太多引用指向它，移动起来高效）

      > JVM规范中，Eden区和Survivor区比例1 ：1，而商业版JVM实现上，它的比例是8：1：1
      >
      > 分配担保原则： 年轻代在内存中只有1/4 ，相对整个堆而言较小，而且还要分配两片内存给s0，s1。所以如果此时出现了一个大对象，这个对象就会直接进入年老代

    - 标记压缩算法/标记整理算法（年老代）

      - 原理：标记所有从根节点开始的可达对象，将将所有的存活对象压缩到内存的一端，然后将剩下的死亡对象和空闲对象全部回收
      - 缺点：效率低（对象自身特征决定的，一般都是些池对象，被很多引用指向的对象，移动起来费劲）
      - 优点： 没有内存碎片

    - 分代收集算法

      - 存活率低：少量对象存活，适合复制算法：在新生代中，每次GC时都发现有大批对象死去，只有少量存活（新生代中98%的对象都是“朝生夕死”），那就选用复制算法，只需要付出少量存活对象的复制成本就可以完成GC
      - 存活率高：大量对象存活，适合用标记-清理/标记-整理：在老年代中，因为对象存活率高、没有额外空间对他进行分配担保，就必须使用“标记-清理”/“标记-整理”算法进行GC

12. **请你谈谈 OOM？| 你工作中都遇到过哪些异常（错误）**

    ![the_superclass_of_all_errors_and_exceptions](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/the_superclass_of_all_errors_and_exceptions.jpg)

    - java.lang.StackOverflowError

    - java.lang.OutOfMemoryError: Java heap space

    - java.lang.OutOfMemoryError: GC overhead limit exceeded：连续进行多次 GC，98% 的时间都拿去做 GC，但却回收了不到 2% 的堆内存，效果非常不理想

      ```java
      public class GCOverhead {
          public static void main(String[] args) {
              int i = 0;
              List<String> list = new ArrayList<>();
              try {
                  while (true) {
                      list.add(String.valueOf(++i).intern());
                  }
              } catch (Throwable e) {
                  System.out.println("---i: " + i);
                  e.printStackTrace(); // java.lang.OutOfMemoryError: GC overhead limit exceeded
                  throw e;
              }
          }
      }
      ```

      > 经历了多轮 FullGC 发现垃圾还是回收不动：[Full GC (Ergonomics) [PSYoungGen: 2047K->2047K(2560K)] [ParOldGen: 7082K->7082K(7168K)] 9130K->9130K(9728K), [Metaspace: 3290K->3290K(1056768K)], 0.0288561 secs] [Times: user=0.09 sys=0.00, real=0.03 secs] 
      >
      > 新 new 的字符串对象在常量池，Java8 之后在 MetaSpace

    - java.lang.OutOfMemoryError: Direct buffer memory

      ```java
      // 配置参数：-Xms10m -Xmx10m -XX:+PrintGCDetails -XX:MaxDirectMemorySize=5m
      public class DirectBufferMemory {
          public static void main(String[] args) {
              System.out.println("配置的 MaxDirectMemory：" + sun.misc.VM.maxDirectMemory() / (double) 1024 / 1024 + "MB");
              //暂停一会儿线程
              try { TimeUnit.SECONDS.sleep(3); } catch (InterruptedException e) { e.printStackTrace(); }
              // Exception in thread "main" java.lang.OutOfMemoryError: Direct buffer memory
              ByteBuffer byteBuffer = ByteBuffer.allocateDirect(6 * 1024 * 1024);
          }
      }
      ```

      导致原因：写 NIO 程序经常使用 ByteBuffer 来读取或者写入数据，这是一种基于通道（Channe）与缓冲区（Buffer）的 I/O 方式，它可以使用 Native 函数库直接分配堆外内存，然后通过一个存储在 Java 堆里的 DirectByteBuffer 对象作为这块内存的引用进行操作。这样就能在一些场景中显著提高性能，因为避免了在 Java 堆 和 Native 堆中来回复制数据

      ByteBuffer.allocate (capability) 第一种方式是分配 JVM 堆内存，属于 GC 管辖范围，由于需要拷贝所以速度相对较慢

      ByteBuffer. allocteDirect (capability) 第二种方式是分配 OS 本地内存，不属于 GC 管辖范围，由于不需内存拷贝所以速度相对较快。

      但如果不断分配本地内存，堆内存很少使用，那么 VM 就不需要执行 GC, DirectByteBuffer 对象们就不会被回收，这时候堆内存充足，但本地内存可能已经使用光了，再次尝试分配本地内存就会出现 OutOfMemoryError，那程序就直接崩溃了。

      > 本地物理内存是一开始 JVM 分配的是总物理内存的 1/4，比如 32G 内存，1/4 就是 8G

    - java.lang.OutOfMemoryError: unable to create new native thread：高并发请求服务器时，经常会出现该异常，准确的讲该 native thread 异常与对应的平台有关

      ```java
      public class UnableCreateNewThread {
          public static void main(String[] args) {
              // 没有跳出循环的条件，会一直创建线程
              for (int i = 0; ; i++) {
                  System.out.println("i = " + i);
                  new Thread(() -> {
                      //暂停一会儿线程，让每一个线程都阻塞在这里，诱导发生 OOM
                      try { TimeUnit.SECONDS.sleep(Integer.MAX_VALUE); } catch (InterruptedException e) { e.printStackTrace(); }
                  }, ""+i).start();
              }
          }
      }
      ```

      导致原因：

      - 应用程序创建了太多线程（一个应用进程创建多个线程超过系统承载极限）
      - 应用服务器并不允许你 linux 的应用程序创建这么多线程，系统默认允许单个进程可以创建的线程数是 1024 个。应用创建超过这个数量，就会报 java.lang.OutOfMemoryError: unable to create new native 

      解决办法：

      - 想办法降低你应用程序创建线程的数量，分析应用是否真的需要创建这么多线程，如果不是就需要修改代码将线程数降到最低
      - 但对于有的应用，确实需要创建很多线程，远超过 linux 系统的默认普通用户 1024 个线程的限制（root 用户不受限），那可以通过修改 Linux 服务器配置，扩大 linux 的默认限制

    - java.lang.OutOfMemoryError: Metaspace

      JVM 参数

      -XX:MetaspaceSize=10m -XX:MaxMetaspaceSize=10m

      ```java
      public class MetaspaceOOM {
          static class OOMTest{}
          public static void main(String[] args) {
              int i = 0;
              try {
                  while (true) {
                      i++;
                      Enhancer enhancer = new Enhancer();
                      enhancer.setSuperclass(OOMTest.class);
                      enhancer.setUseCache(false);
                      enhancer.setCallback(new MethodInterceptor() {
                          @Override
                          public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable {
                              return methodProxy.invokeSuper(o,args);
                          }
                      });
                      enhancer.create();
                  }
              } catch (Throwable e) {
                  // --- 多少次后发生了异常：540
                  // java.lang.OutOfMemoryError: Metaspace
                  System.out.println("--- 多少次后发生了异常："+i);
                  e.printStackTrace();
              }
          }
      }
      ```

      Java8 以后用的是 Metaspace 来替代永久代，Metaspace 是方法区在 HotSpot 中的实现，它与永久代最大的区别在于 Metaspace 并不在虚拟机内存而是使用的是本地内存

      永久代（java8 后被 Metaspace 原空间取代了）存放了以下信息：1. 虚拟机加载的类信息（像什么 rt.jar 包中的 Object.class、ArrayList.class 等等 2. 常量池 3. 静态变量 3. 即时编译后的代码

      导致原因：元空间初始大小只有 20m 左右，在元空间里面不断的加载静态类，最终会把 Metaspace 撑爆

      > java -XX:+PrintFlagsInitial 查看的 MetaspaceSize = 21810376（20m 多）

13. 哈哈哈

    年轻代：用复制算法

    年老代：用标记清除算法、标记整理算法

    Garbage Collectors 垃圾收集器：
    
    ![Garbage Collectors](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/Garbage%20Collectors.jpg)
    
    - Serial（串行垃圾收集器）顺序、依次的意思：它为单线程环境设计且只用一个线程进行垃圾收集，收集垃圾时会暂停用户线程，所以不适合服务器环境
    - Parallel（并行垃圾收集器）：多个垃圾收集线程并行工作，垃圾收集时用户线程也是要暂停的。比较适用于科学计算 / 大数据处理首台处理等弱交互场景
    - CMS（并发垃圾收集器）：用户线程和垃圾收集线程同时执行（不一定是并行，可能是交替执行），它不需要停顿用户线程。适用对响应时间有要求的场景，停个 0.01s 当然可以，停个七八秒的话那肯定不行。互联网公司一般都用它
    - Garbage first（G1 垃圾收集器）：Java8 开始用 G1 收集器。G1 垃圾回收器将堆内存分割成不同的区域然后并发的对其进行垃圾回收
    
    > 停顿操作：就是 STW（Stop-the-world）
    >
    > 好比在餐厅吃饭，一个清洁工过来和你说，您先起来一下我打扫下卫生（Serial）；多个清洁工过来和你说（Parallel）；多个清洁工说您先搬到另一桌吃着，我们打扫完您再回来（CMS）
    
14. **怎么查看服务器默认垃圾收集器是哪个？生产上是如何配置垃圾收集器的？谈谈你对垃圾收集器的理解？**

    > http://www.ityouknow.com/jvm/2017/09/03/jvm-command.html
    >
    > Server / Client 模式分别什么意思？
    >
    > 32 位 Windows 系统默认只会使用 Client 的 JVM 模式
    >
    > 32 位其它系统，2G 内存同时有 2 个 CPU 以上用 Server 模式，低于该配置还是 Client 模式
    >
> 64 位 only server 模式
    
    - 年轻代
    
      - 串行收集器
    
      - 并行收集器
    
        年轻代里面有 Eden 区，天天 new 对象，会打扫的频繁一些，也就是在频繁创建对象的 Young 区有多个 GC 线程。年老代是活过 15 次才移过来，所以不用频繁打扫，还是只有一个 GC 线程
    
        JVM 参数：-XX:+UseParNewGC（启动 ParNew 收集器，只影响年轻代，不影响年老代）
    
        开启上述参数后，会使用：ParNew（年轻代用）+ Serial Old（年老代用）的收集器组合，新生代使用复制算法，老年代采用标记整理算法
    
        > -Xms10m -Xmx10m -XX：+PrintGCDetails-XX：+PrintCommandL ineFlags -XX：+UseserialGC（DefNew+Tenured）
        >
        > -Xms10m -Xmx10m -XX：+PrintGCDetails -XX：+PrintCommandLineFlags -XX：+UseParNewGC（ParNew+Tenured）
        >
        > -Xms10m -Xmx10m -XX：+PrintGCDetails -XX：+PrintCommandL ineFlags -XX：+UseParalleLGC（PSYoungGen+ParoldGen）
        >
        > 4.1-Xms10m-xmx10m-xx：+PrintGCDetails-xx：+PrintCommandLineFLags-xx：+UseParalleloldGC（PSYoungGen+ParoldGen）100
        >
        > 4.2不加就是默认 UseParal lelGC-Xms10m -Xmx10m -XX：+PrintGCDetails -XX：+PrintCommandLineFlags（PSYoungGen+ParoldGen）
        >
        > -Xms10m -Xmx10m -XX：+PrintGCDetails -XX：+PrintCommandLineFlags -XX：+UseConcMarkSweepGC
      - 并行收集器
    
        Parallel ScavengeParNew 收集器类似也是一个新生代垃圾收集器，使用的是复制算法，也是一个并行的多线程的垃圾收集器，俗称吞吐量优先收集器。一句话：串行收集器在年轻代和年老代的并行化
    
        它关注的重点是：可控制的吞吐量
    
        > 吞吐量（Thoughput = 运行用户代码时间 /（运行用户代码时间 + 垃圾收集时间），也即比如程序运行 100 分钟，垃圾收集时间 1 分钟，吞吐量就是 99%）。高吞吐量意味着高效利用 CPU 的时间，它多用于在后台运算而不需要太多交互的任务。
    
    - 年老代
    
      - 串行收集器
    
      - 并行收集器
    
      - ==并发标记清除收集器 CMS==
    
        cMs收集器（Concurrent Mark Sweep：并发标记清除）是一种以获取最短回收停顿时间为目标的收集器。适合应用在互联网站或者B/S系统的服务器上，这类应用尤其重视服务器的响应速度，希望系统停顿时间最短。CMS非常适合堆内存大、CPU核数多的服务器端应用，也是G1出现之前大型应用的首选收集器。
    
        四个步骤：
    
        - 初始标记（initial mark）：标记 GCRoots 可达对象，耗时短
    
        - 并发标记（concurrent mark）：从第一步标记的对象出发，并发的标记可达对象
    
        - 重新标记（CMS remark）：可能有的对象又重新被用起来了，就不能清除，需要修正一下标记结果
    
        - 并发清除（CMS concurrent sweep）和用户线程一起：清除 GCRoots 不可达对象，和用户线程一起工作，不需要暂停工作线程。然后根据标记结果直接清理对象
    
          优点：并发收集停顿低
    
          缺点：
    
          i. 并发执行对 CPU 资源压力大
    
          > 由于并发进行，CMS在收集与应用线程会同时会增加对堆内存的占用，也就是说，CMS必须要在老年代堆内存用尽之前完成垃圾回收，否则CMS回收失败时，将触发担保机制，串行老年代收集器将会以STW的方式进行一次GC，从而造成较大停顿时间I
    
          ii. 采用的标记清除算法会导致大量内存碎片
    
    - 如何选择垃圾收集器？
    
      | 参数                                     | 新生代垃级收集器             | 新生代算法                             | 老年代垃圾收集器                                             | 老年代算法 |
      | :--------------------------------------- | ---------------------------- | -------------------------------------- | ------------------------------------------------------------ | :--------- |
      | -XX:+UseSerialGC                         | SerialGC                     | 复制                                   | SerialOldGC                                                  | 标整       |
      | -XX:+UseParNewGC                         | ParNew                       | 复制                                   | SerialOldGC                                                  | 标整       |
      | -XX:+UseParallelGC/-XX:+UseParallelOldGc | Parallel[Scavenge]           | 复制                                   | Parallel Old                                                 | 标整       |
      | -XX:+UseConcMar kSweepGC                 | ParNew                       | 复制                                   | CMS+SerialOld 的收集器组合（Serial Old 作为 CMS 出错的后备收集器） | 标清       |
      | -XX:+UseG1GC                             | G1 整体上采用标记 - 整理算法 | 局部是通过复制算法，不会产生内存碎片。 |                                                              |            |


15. **G1 垃圾收集器**

    > -Xms10m-xmx10m-xx:+PrintGcDe-xx:PrintCommand ineFlags-xx:UseG1GC

    G1 是什么：

    CMS垃圾收集器虽然减少了暂停应用程序的运行时间，但是它还是存在着内存碎片问题。于是，为了去除内存碎片问题，同时又保留CMS垃圾收集器低暂停时间的优点，也就是 STW 时间更可控，G1在停顿时间上添加了预测机制，用户可以指定期望停顿时间，JAV7发布了一个新的垃圾收集器-G1垃圾收集器。JDK9中 G1 已经成为了默认收集器
    
    特点：
    
    1：G1能充分利用多CPU、多核环境硬件优势，尽量缩短STW
    2：G1整体上采用标记整理算法，局部是通过复制算法，不会产生内存碎片。
    3：宏观上看G1之中不再区分年轻代和老年代。把内存划分成多个独立的子区域（Region），可以近似理解为一个围棋的棋盘。
    4：G1收集器里面讲整个的内存区都混合在一起了，但其本身依然在小范围内要进行年轻代和老年代的区分，保留了新生代和老年代，但它们不再是物理隔离的，而是一部分 Region的集合且不需要是连续的，也就是说依然会采用不同的GC方式来处理不同的区域。
    5：G1虽然也是分代收集器，但整个内存分区不存在物理上的年轻代与老年代的区别，也不需要完全独立的 survivor（to space）堆做复制准备。G1只有逻辑上的分代概念，或者说每个分区都可能随G1的运行在不同代之间前后切换；
    
    底层原理：
    
    Region 区域化垃圾收集器：最大好处是化整为零，避免全内存扫描，只需要按照区域来进行扫描即可。
    
    > 如果一个对象特别特别大，应该直接放到养老区
    
    实战 - 配置 G1 参数： 开始 G1 + 设置最大内存 + 最大 GC 停顿时间 -XX:+UseG1GC -Xmx32g -XX:MaxGCPauseMillis=100
    
    > 100 毫秒就把垃圾收集完
    
    和 CMS 相比有两个优势：1. 不会产生内存碎片 2. 可以精准的控制停顿时间，它是把堆（年轻代和年老代）划分为多个固定大小的区域，每次根据允许停顿的时间去收集垃圾最多的区域。
    
    我是个订单微服务，启动的时候需要堆内存大一些，不要用默认的，java -server -Xms1024m -Xmx1024m -X:+UseG1GC -jar springboot1.0-SNAPSHOT.war
    
    > 有没有把 SpringBoot 部署到 Undertow 下面？部署了的，我们在 Undertow 下用 Jmeter 做压测，QPS 比 tomcat 要高 3000 多
    
16. **生产环境服务器变慢，谈谈你的诊断思路和性能评估？| 说说 Linux 下你常用的命令？**

    > 系统慢一般情况下是两种情况：一个是 CPU，还有个是磁盘 IO

    - 整机：top

      uptime：系统性能命令的精简版，可以打印出 load average

      load average 系统平均负载值：v1.57+0.89+0.40=2.86/3=0.953*100% 大于 60%，说明系统负担比较重，需要优化程序

    - CPU：vmstat -n 2 3（查看 CPU）

      一般 vmstat 工具的使用是通过两个数字参数来完成的，第一个参数是采样时间间隔数单位是秒，第二个参数是采样的次数

      procs

      - r：运行和等待 CPU 时间片的进程数，原则上 1 核的 CPU 的运行队列不要超过 2，整个系统的运行队列不能超过总核数的 2 倍，否则代表系统压力过大
      - b：等待资源的进程数，比如正在等待磁盘 I/0、网络 I/0 等。

      CPU

      - us：用户进程消耗 CPU 时间百分比，us 值高代表用户进程消耗 CPU 时间多，如果长期大于 50%，则需要优化程序
      - sy：内核进程消耗的 CPU 时间百分比
      - us+sy：参考值为 80%，如果 us+sy 大于 80%，说明可能存在 CPU 不足。
      - id：处于空闲的 CPU 百分比
      - wa：系统等待 IO 的 CPU 时间百分比
      - st：来自于一个虚拟机偷取的 CPU 时间的百分比工

      > 查看额外：
      >
      > - 查看所有 CPU 核信息：mpstat -P ALL 2
      > - 每个进程使用 CPU 的用量分解信息：pidstat -u 1 -p 进程编号

    - 内存：free

      应用程序可用内存/系统物理内存>70%内存充足

      应用程序可用内存/系统物理内存<20%内存不足，需要增加内存

      20%<应用程序可用内存/系统物理内存<70%内存基本够用

      查看额外：pidstat -p 进程号 -r 采样间隔秒数

    - 硬盘：df [-h]

      查看文件系统磁盘空间使用情况（-h：human readable）以人类可读的格式

    - 磁盘 IO：iostat

      大表存储，大批量的进行磁盘 IO 就会导致 IO 慢，长时间 IO 慢也会导致系统出问题

      > iostat -xdk 2 3：2 秒取样一次，共取样 3 次
      >
      > -x     Display extended statistics. 显示扩展统计信息。
      >
      > -d     Display the device utilization report. 显示设备利用率报告。
      >
      > -k     Display statistics in kilobytes per second. 以千字节每秒显示统计信息。
      >
      > - rkB/s 每秒读取数据量 kB
      > - wkB/s 每秒写入数据量 kB
      > - svctm I/O 请求的平均服务时间，单位毫秒
      > - await I/O 请求的平均等待时间，单位毫秒；值越小，性能越好
      > - <font color='red'>util 一秒里有百分几的时间用于 IO 操作。接近 100% 时，表示磁盘带宽跑满了，就需要优化程序或者增加磁盘</font>
      > - rkB/s、wkB/s 根据系统应用不同会有不同的值，但有规律遵循：长期、超大数据读写，肯定不正常，需要优化程序的读取。
      > - svctm 的值与 await 的值很接近，表示几乎没有 IO 等待，磁盘性能好，如果 await 的值远高于 svctm 的值，则表示 l/O 队列等待太长，需要优化程序或换更快的磁盘。

      查看额外：pidstat -d [采样间隔秒数] -p [进程号]

    - 网络 IO：ifstat

      ifstat l

      可以查看各个网卡的 in、out，观察网络负载情况，程序网络读写是否正常，程序网络优化增加网络带宽

17. **假如生产环境出现 CPU 占用过高，请谈谈你的分析思路和定位？ | 谈谈你记忆深刻的故障**

    一般出故障了，你如何调试 + 排查 + 检索？

    Google + Stack Overflow + GitHub

    i. 首先我会用 top 命令找到 CPU 占比最高的程序

    ii. 然后用 ps -ef | grep java 或 jps 进一步定位，来得知是怎样一个后台程序惹的事

    <font color='red'>iii. 定位到具体线程或代码</font>

    ​	ps -mp [进程 id] -o THREAD,tid,time

    ​	参数解释：-m：显示所有线程；-p 进程使用 CPU 时间；-o 参数后为用户自定义格式 [线程的 id，时间]

    iv. 定位到线程后将 10 进制的线程 ID 转换为 16 进制英文小写格式（可以用命令 printf "%x\n" 或计算器）

    v. jstack [线程 id] | grep [线程 16 进制 id] -A60

    ​	打印前 60 行，然后直接找到项目的包名并定位到具体行数

18. **对于 JDK 自带的 JVM 监控和性能分析工具用过那些？一般你是怎么用的？**

    - jps

    - jinfo

    - jmap（抓取内存快照）

      Case：

      - 映射对快照：jmap -heap [进程 ID]

      - 抓取堆内存：

        - 生成 hprof 文件并下载到本地

          

        - MAT 分析插件工具

    - jstat（统计信息监视工具）

19. **JVM优化**

    https://www.liaoxuefeng.com/article/1336345083510818

    MaxPermSize：permanent最大永久大小

    最深刻的就是最近做的在线教育项目，其中我在里面有负责一个课程搜索模块，就是把用户搜索的内容进行分词然后把相关度高的结果返回到页面，当时把后台模块写好了以后是可以在本地系统上运行的，但是用 Jenkins 构建以后一运行就遇到了 OOM 内存溢出错误，当时遇到的这个问题的时候第一时间想起来了以前看的关于虚拟机的书，于是我在虚拟机的配置上添加了一个参数 `- XX：+HeapDumpOnOutOfMemoryError` ，尝试将 dump 文件保留到本地，然后采用了 jmap 命令去分析这个 dump 文件，发现年老代那个参数 Old Generation 每次一启动都是满着的，然后去看了虚拟机的配置参数，发现虚拟机中的 - xmx 参数只有 256M，而程序需要的内存大小为 500M（因为需要加载一个 MIT 的提取名词的包），所以最后通过设置成 1024M 解决了这个问题，我感觉通过这个学到了很多

    > Permanent Generation: 永久代是保存类文件的地方。这些是类编译后的结果和 JSP 页面。如果这个空间已满，它将触发一个 Full GC 垃圾收集。如果 Full GC 不能清除旧的未引用类，并且又没有空间扩展永久代的话，就会抛出一个 OOM， JVM 就崩溃了
    >
    > 我推测是与 jvm 垃圾回收有关。jvm 虚拟机中将堆分为新生代和老年代，而当 new 了一个对象以后，由于是强引用，这个对象在经历 minorGC 的时候，年龄会变大，在达到参数 MaxTenuringThreshold 值的时候，就会进入到老年代中。一直进行这个过程，那么老年代中的活着的对象就会越来越多，最后老年代满了以后发生 fullGC，而 fullGC 是很耗时间的，尤其是当老年代越大，那么 fullGC 就越耗时间。这个系统周期性出现这个问题的就是由于对象周期性地把老年代填充满了，然后 jvm 虚拟机周期性地去进行 fullGC 去回收垃圾，当回收的时候系统性能就下降，当回收结束时系统性能就上升。
    >
    > 那么如何解决呢？通过调整新生代与老年代的比例（该值可以通过参数 –XX：NewRatio 来指定），调低老年代占的内存大小，这样老年代很快就满了，就会提前进行 fullGC，直到调整到发生 fullGC 时候对于系统性能影响不大的时候（用户察觉不出来），那么调优结束。

    1：建议用 64 位操作系统，内存的利用率更多，吞吐量更大

    2：XMX 和 XMS 设置一样大，MaxPermSize 和 MinPermSize 设置一样大，这样可以减轻伸缩堆大小带来的压力

    3：调试的时候设置一些打印参数，如 - XX:+PrintClassHistogram -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintHeapAtGC -Xloggc:log/gc.log，这样可以从 gc.log 里看出一些端倪出来。

    4：系统停顿的时候可能是 GC 的问题也可能是程序的问题，多用 jmap 和 jstack 查看，或者 killall -3 Java，然后查看 Java 控制台日志，能看出很多问题。有一次，网站突然很慢，jstack 一看，原来是自己写的 URLConnection 连接太多没有释放，改一下程序就 OK 了

    5：如果用了缓存，那么年老代应该大一些，缓存的 HashMap 不应该无限制长，建议采用 LRU 算法的 Map 做缓存，LRUMap 的最大长度也要根据实际情况设定。

    6：垃圾回收时 promotion failed 是个很头痛的问题，一般可能是两种原因产生 第一个原因是救助空间不够，救助空间里的对象还不应该被移动到年老代，但年轻代又有很多对象需要放入救助空间； 第二个原因是年老代没有足够的空间接纳来自年轻代的对象；这两种情况都会转向 Full GC，网站停顿时间较长。 第一个原因我的最终解决办法是去掉救助空间，设置 - XX:SurvivorRatio=65536 -XX:MaxTenuringThreshold=0 即可， 第二个原因我的解决办法是设置 CMSInitiatingOccupancyFraction 为某个值（假设 70），这样年老代空间到 70% 时就开始执行 CMS，年老代有足够的空间接纳来自年轻代的对象

    7：采用并发回收时，年轻代小一点，年老代要大，因为老年代用的是并发回收，即使时间长点也不会影响其他程序继续运行，网站不会停顿

20. **获取 dump 文件方式**

    在命令行使用 jmap

    使用 JVisualVM 导出

21. **常见堆内存分析工具**

    | 产品功能                                                     | MAT  | JProfiler | Visual VM | jhat | jmap | hprof |
    | ------------------------------------------------------------ | ---- | --------- | --------- | ---- | ---- | ----- |
    | 对象关联分析、深浅堆、GC ROOT、内存泄漏检测、线程分析、提供自定义程序扩展扩展 | Y    | N         | N         | N    | N    | N     |
    | 离线全局分析                                                 | Y    | N         | Y         | Y    | N    | N     |
    | 内存实时分配情况                                             | N    | Y         | Y         | Y    | Y    | Y     |
    | OQL                                                          | Y    | N         | Y         | N    | N    | N     |
    | 内存分配堆栈、热点比例                                       | N    | Y         | N         | N    | N    | N     |
    | 堆外内存分析                                                 | N    | N         | N         | N    | N    | N     |

    

### JUC 多线程

多线程模板的企业级口诀：高并发下前提一定是高内聚、低耦合

上联：线程操作资源类

下联：判断干活唤醒通知

横批：严防多线程下的虚假唤醒（使用 while）

> 并发编程高级面试解析
>
> 一、Synchronized 相关问题
>
> 1. Synchronized 用过吗，其原理是什么
> 2. 你刚才提到获取对象的锁，这个锁到底是什么？如何确定对象的锁
> 3. 什么是可重入性，为什么说 Synchronized 是可重入锁？
> 4. JVM 对 Java 的原生锁做了哪些优化？
> 5. 为什么说 Synchronized 是非公平锁？
> 6. 什么是锁消除和锁粗化？
> 7. 为什么说 Synchronized 是一个悲观锁？乐观锁的实现原理又是什么？什么是 CAS，它有
> 8. 乐观锁一定就是好的吗？
>
> 二、可重入锁 ReentrantLock 及其他显式锁相关问题
> 1. 跟 Synchronized 相比，可重入锁 ReentrantLock 其实现原理有什么不同？
> 2. 那么请谈谈 AQS 框架是怎么回事儿？
> 3. 请尽可能详尽地对比下 Synchronized 和 ReentrantLock 的异同。
> 4. ReentrantLock 是如何实现可重入性的？

[本书简介・深入浅出 Java 多线程](http://concurrent.redspider.group/)

[不可不说的 Java “锁” 事 - 美团技术团队](https://tech.meituan.com/2018/11/15/java-lock.html)

[Java中的多线程你只要看这一篇就够了 - 简书](https://www.jianshu.com/p/40d4c7aebd66)

![1553052790171](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/1553052790171.png)



你来讲讲你了解的 JUC（多线程）：volatile（可见性、禁止指令重排 - 单例、不保证原子性）- CAS - 原子引用

[java.util.concurrent (Java Platform SE 8 )](https://docs.oracle.com/javase/8/docs/api/) 

[java.util.concurrent.atomic (Java Platform SE 8 )](https://docs.oracle.com/javase/8/docs/api/)

[java.util.concurrent.locks (Java Platform SE 8 )](https://docs.oracle.com/javase/8/docs/api/)

Java 中 ReentrantLock 和 Synchronized 都是可重入锁，可重入锁的一个优点是可一定程度避免死锁

![Java 主流锁](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/Java%20%E4%B8%BB%E6%B5%81%E9%94%81.png)

1. ~~**为什么要使用多线程（你了解的多线程）**~~

   what：线程就好比轻量级的进程，是程序执行的最小单位，线程间切换和调度的成本远远小于进程。另外在现在多核 CPU 时代，意味着多个线程可以同时运行，这减少了线程上下文切换的开销。而且多线程可以大大提高系统整体的并发能力以及性能

   从计算机背后来探讨：

   - 单核时代： 在单核时代，多线程主要是为了提高 CPU 和 IO 利用率问题。<font color='red'> 单线程情况下只有一个线程进行 CPU 计算时，那 IO 操作会空闲 </font>；而进行 IO 操作时，CPU 会空闲。我们就可以用多线程，让一个线程执行 CPU 计算的同时，开另一个线程去进行 IO 操作来提高利用率
   - 多核时代： 多核时代是为了提高 CPU 利用率。当我们要计算一个复杂的任务时，我们只用一个线程的话，只会有一个 CPU 被利用到，处理的很慢，而多个线程呢可以让多个 CPU 被利用到（因为是现在多核嘛，我们可以让一个核来跑一个线程），处理的更快，提高了 CPU 的利用率

   比如说下载个 100m 的东西，开一个线程需要 10s，而开 100 个线程只需要 1s

   但是用上多线程之后又会带来一系列问题，比如当多个线程操作同一个共享变量时，就会触发线程安全问题。讲到线程安全问题呢得先提一下 JMM

   > 那我们可以加锁，加锁呢有两种解决方案，一个是悲观锁，一个是乐观锁

2. **请谈谈你对 volatile 的理解（volatile 关键字的作用 | 请你谈谈 JMM）**

   > 硬盘（MySQL）< 内存（Redis）< CPU
   >
   > 数据一般存储在 MySQL 硬盘上，硬盘的 IO 是纯硬件的，它有它的上线，达到一定阈值后很难有突破，除非硬件上有突破。
   >
   > 而现在大数据时代需要快速的存取，那么可以把部分数据不存在 MySQL，转为存储在 Redis 这样的内存里面。
   >
   > CPU 的速度更大于内存，但是 CPU 只管计算不管存储，假如 CPU 计算完了还没传给内存，就会一直在那耗着，这肯定不行，所以中间就需要有一个缓存的东西 —— 一二三级缓存（CPU Cache Memory），来把计算完的东西存放在缓存里

   volatile 是 JVM 提供的比 Synchronized 轻量级的同步机制，它有三大特性：保证内存的可见性、禁止指令重排、但不保证原子性。那说到 volatile 的特性呢需要先了解到 <font color='red'>JMM（Java 内存模型 Java Memory Model）</font>

   JMM：JMM（Java 内存模型 Java Memory Model, 简称 JMM）本身是一种抽象的概念，它主要是用它解决并发过程中的可见性、有序性和原子性问题，具体实现方式有很多，像这个轻量级的 volatile

   > 了解：
   >
   > JMM 关于同步规定：
   >
   > i. 线程解锁前，必须把共享变量的值刷新回主内存
   >
   > ii. 线程加锁前，必须读取主内存的最新值到自己的工作内存
   >
   > iii. 加锁解锁是同一把锁
   >
   > 由于 JVM 运行程序的实体是线程，而每个线程创建时 JVM 都会为其创建一个工作内存（有些地方成为栈空间）, 工作内存是每个线程的私有数据区域，而 JMM 中规定所有变量都存储在主内存，主内存是共享内存区域，所有线程都可访问，但线程对变量的操作（读取赋值等）必须在工作内存中进行，首先要将变量从主内存拷贝到自己的工作空间，然后对变量进行操作，操作完成再将变量写回主内存，<font color='red'> 不能直接操作主内存中的变量 </font>，各个线程中的工作内存储存着主内存中的变量副本拷贝，因此不同的线程无法访问对方的工作内存，线程之间的通讯（传值）必须通过主内存来完成

     ![JMM 内存模型](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/JMM%20%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B.jpg)

   - 可见性
     
     > 当多个线程操作同一个共享变量时，就有可能触发线程并发问题。使用 volatile 关键字修饰的变量，保证了其在多线程之间的可见性。也就是每次读取到 volatile 修饰的变量时一定是最新的数据
     
     ![JMM 内存可见性](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/JMM%20%E5%86%85%E5%AD%98%E5%8F%AF%E8%A7%81%E6%80%A7.jpg)
     
     比如当前是个主内存为 32G 的电脑，我新 new 一个 Goods 商品对象，新 new 的对象呢是在堆中，堆又是在内存中。Goods 对象它有个库存属性 num = 10，当有多个线程（T1、T2、T3）来操作同一个共享变量 num 时，就有可能触发线程并发问题。由于 JMM 规定不允许直接修改主内存的值，而是要把主内存值拷回到各自线程的工作内存进行操作也就是共享变量副本，此时线程的值都为 10，当 T1 线程把 num 值修改为 9，接着修改完之后把数据写回主内存。此时线程之间的数据是不可见的，那就需要一种机制就是当线程修改了数据写回主内存，就要立马通知到其他线程来获取最新数据。这种机制就叫内存的可见性。那解决方案呢就是使用 volatile 关键字修饰修饰变量，来保证了其在多线程之间的可见性。也就是每次线程来读取到 volatile 修饰的变量时一定是最新的数据

     [**如何解决可见性问题代码**](#visualAndAtomicResolve)：[interview/VolatileDemo.java at master · liuilin/interview](https://github.com/liuilin/interview/blob/master/interview_code/src/com/liuilin/JUC/VolatileDemo.java)
     
   - 禁止指令重排序

     这也就是对应着 JMM 的第二个特性 —— 有序性。比如高考试卷发下来一般是先把会做的做了，不按照题的顺序做，这就是重排序。但是用了 volatile 来禁止指令重排之后，相当于强制要求必须按题的顺序做，不可以跳着做

     > 计算机在执行程序时，为了提高性能，编译器和处理器一般会做<font color='red'>指令重排</font>，那分为三点：
     >
     > i. 单线程环境下要确保程序最终执行结果和代码顺序执行的结果一致
     >
     > ii. 处理器在进行重排序时必须要考虑指令之间的<font color='red'>数据依赖性</font>（比如 a = a + 5，要先有 int a = 0 才行）
     >
     > iii. 多线程环境中线程交替执行，由于编译器优化重排的存在，两个线程使用的变量无法保持一致性，以至于结果也会不同
     
     **你在那些地方用到过 volatile？**

     ==实际应用 —— [单例设计模式](#singleton)==

     单例：保证一个类在内存中只有一个实例，同时设置构造方法为私有，防止别的对象来 new
     
     ```java
     /**
      * 懒汉模式
      */
     public class LazySingleton {
         private static LazySingleton instance = null;
         private LazySingleton() {}
         public static LazySingleton getInstance() {
             if (instance == null) {
                 instance = new LazySingleton();
             }
             return instance;
         }
     }
     ```
     
     上面版本在单线程下完全没问题，但在多线程情况下就会出现线程安全问题，也就是两个线程同时判断 `instance == null` 时都判断成功，往下走就同时 new 了对象。那想到最简单的方案就是加锁， synchronized 同步锁来让线程一个一个的通过，也就优化为了 <font color='red'>DCL 加锁版本</font>（Double-checked locking <span id='DCL'>双重校验锁</span> / 双端校验锁）：
     
     what：DCL 是给程序加 synchronized 代码块锁，同时在加锁前后都做一次 if 判断，确认对象完全为 null 了才创建实例对象
     
     **加 synchronized 保证线程安全了，为什么还要加 volatile？：**
     
     当然我们把 synchronized 放到静态代码方法上保证单例，但这肯定是不推荐的，因为它太重了。锁住整个方法的话（如果修饰 static 方法时是锁住的整个类）。虽然保证了数据一致性，但是并发性和系统性能就下降了，里面有很多不需要的东西也锁住了。
     
     所以应该用 synchronized 同步代码块，在外层先判断实例为空才锁住同步代码块。这样既能保证数据一致性，也能提高并发性。但还是有同样有并发问题，要内层也要添加 if 判空
     
     ```java
     private static volatile LazySingleton instance = null;
     // ...
     public static LazySingleton getInstance() {
         if (instance == null) { // 这样效率更高，不然每个线程都要走一遍同步锁，先判断为空就返回
             synchronized (LazySingleton.class) {
                 if (instance == null) { // 保证线程安全，只 new 一个对象
                   instance = new LazySingleton();
                 }
             }
         }
         return instance;
     }
     ```
     
     看似程序没问题了 ，但由于指令重排的存在，DCL 机制不能保证一个线程安全，原因在于某一个线程在执行到第一次读取到内层判断的 instance == null 时，instance 的引用对象可能还没有完成初始化
     
     实际上 `new LazySingleton();` 操作底层字节码有有三步操作：
     
     i. new：分配内存空间（这个对象占多大字节就分配多大，[过程见](#newObject)），此时 int i = 0
     
     ii. invokespecial：初始化对象（调用默认的 `<init>` 构造方法后 i = 1;）
     
     iii. astore_1：设置 instance 引用指向刚分配的内存地址（此时才 instance != null）
     
     ```java
     // 简写为 T，用来举例
     class T {
         int i = 1;
     }
     T t = new T();
     
     
     // 字节码...
     // 创建 Singleton 对象实例，分配内存
     0 new #2 <com/liuilin/JVM/T>
     //3 dup
     // 调用默认的 <init> 构造方法初始化对象
     4 invokespecial #3 <com/liuilin/JVM/T.<init> : ()V>	
     // 存入局部方法变量表
     7 astore_1
     //8 return
     ```
     
     由于步骤 2 和步骤 3 不存在数据依赖性，所以会发生指令重排序。（数据依赖性就是指比如 a = a + 5，那你得现有 int a = 0 才行），单线程下指令重排不会影响结果，但是多线程情况下就不一样了，指令排序之后可能先执行步骤 3，再执行步骤 2，先执行步骤 3 来设置 instance 的指向刚分配的内存地址。接着另一个线程进来判断 instance 不为 null，就直接返回了，但返回的是一个未初始化对象的实例，因为步骤 2 的初始化对象步骤没有走，此时就会报错，也就是出现了线程安全问题。
     
     **解决方案呢就是使用 volatile 来修饰 instance 实例**
     
     实现细节：JVM 使用了屏障来禁止屏障两边的指令重排，JVM 的 happens-before 原则规定了 8 种情况下都得加屏障，不允许重排序，其中就有 volatile
     
     > as if serial：不管如何重排序，单线程执行的结果不会改变
       >
     > 用于理解指令重排案例：
       >
     > ```java
       > public class Resource {
       > 
       >  int a = 0;
       >  boolean flag = false;
     > 
       >  public static void main(String[] args) {
     >      Resource resource = new Resource();
       >      new Thread(() -> {
     >          resource.method1();
       >     }, "T1").start();
       > 
       >     new Thread(() -> {
       >        resource.method2();
       >      }, "T2").start();
       >  }
       >    
       >     public void method1() {
       >      flag = true;        // 语句 2
       >         a = 1;              // 语句 1
       >     }
       >    
       >     // 多线程环境中线程交替执行，由于编译器优化重排的存在，两个线程使用的变量（flag 和 a）无法保持一致，导致结果也不同
       >     public void method2() {
       >              if (flag) {
       >             a = a + 5;      // 语句 3
       >           System.out.println(Thread.currentThread().getName() + " --- return value --- " + a);
       >         }
       >     }
       > }
       >    ```
       >    
       >    指令重排只是有一定概率发生，并不是每次都发生
       >    
       > 情况一：不会发生指令重排，T1 线程走完 method1，T2 线程走完 method2，a = 1 + 5 = 6
       >    
       >    情况二：会发生指令重排，由于 `语句 1`  `语句 2` 没有数据依赖性 ，所以可能发生指令重排，T1 线程会先执行 `flag = true`  ，然后 T1 线程被挂起，此时 a = 0，T2 线程走完 method2 并打印输出 a = 0 + 5 = 5
       >    
       >    情况三：和情况二一样还是会发生指令重排，在 T2 线程走完 `语句3` a = 0 + 5 = 5 还没打印时，T2 线程就被挂起了，接着 T1 线程执行 a = 1，此时最终打印输出的值就为 1
     
   - 不保证原子性：

     what：原子性是不可分割且保证完整性，也就是某个线程正在做某个具体业务时，中间不可以被加塞或分割。要么同时成功，要么同时失败。

     ![volatile 不保证原子性](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/volatile%20%E5%8E%9F%E5%AD%90%E6%80%A7.jpg)

     在操作 num++ 时，首先线程会把主内存对象数据拷贝到各自线程的工作内存，T1 线程进行 +1 操作然后写回主内存，修改完后正要通知其他线程的时候被挂起了。此时 T2 线程也进行 num++ 操作把数据 11 写回主内存了，这时之前的 num = 11 就被覆盖。因此本来三个线程应该累加到 13 的，由于上面数据被覆盖了，导致无法完成原子操作，最终数据就变为 11。

     [**如何解决原子性问题代码实现：**](#visualAndAtomicResolve)[interview/VolatileDemo.java at master · liuilin/interview](https://github.com/liuilin/interview/blob/master/interview_code/src/com/liuilin/JUC/VolatileDemo.java)

     加 Synchronized 可以解决，保证只有一个线程来操作，但是不推荐使用它，有点杀鸡用牛刀的感觉，就是因为这个锁太重了。那除此外呢我们还可以用 [java.util.concurrent.atomic (Java Platform SE 8 )](https://docs.oracle.com/javase/8/docs/api/) 包下的 AtomicInteger 来保证原子性（底层是用的 CAS）

     > 由于 num++ 是不可分割的操作，对应的字节码解读出来 num++ 做了三个步骤：
     
     ```java
     public void addPlusPlus();
       descriptor: ()V
       flags: (0x0001) ACC_PUBLIC
       Code:
         stack=3, locals=1, args_size=1
            0: aload_0							// 从局部变量 0 中装载引用类型值
            1: dup								// 复制栈顶部一个字长内容
            // getfield：获得初始值
            2: getfield      #2                  // Field num:I
            // iconst_1 + iadd：执行 +1
            5: iconst_1
            6: iadd
            // putfield：把累加后的值写回主内存
            7: putfield      #2                  // Field num:I
           10: return
         LineNumberTable:
           line 12: 0
         line 13: 10
         LocalVariableTable:
         Start  Length  Slot  Name   Signature
               0      11     0  this   Lcom/liuilin/JUC/GoodsByte;
     ```
     
     <span id='visualAndAtomicResolve'>**解决可见性和原子性代码实现**</span>
   ```java
   /**
    * 1. 验证 volatile 可见性
    *  1.1 假如 int number = 0; number 变量之前根本没有添加 volatile 关键字修饰，没有可见性
    *  1.2 加入 volatile 后可以解决可见性问题
    *
    * 2. 验证 volatile 不保证原子性
    *  2.1 原子性指的是什么意思？
    *  不可分割，完整性，也即某个线程正在做某个具体业务时，中间不可以被加塞或分割。需要整体完整。要么同时成功，要么同时失败。
    *  2.2 volatile 不保证原子性案例
    *  2.3 why
    *  2.4 如何解决原子性
    *      - 加 Synchronized
    *      - 使用 JUC 下面的 AtomicInteger
    *
    * @author liuqiang
    * @since 2021-07-29
    */
   public class VolatileDemo {
       public static void main(String[] args) {
           // visualByVolatile();
           Goods goods = new Goods();
           for (int i = 1; i <= 20; i++) {
               new Thread(() -> {
                   for (int j = 1; j <= 1000; j++) {
                       // 实际值应该是 20000 才对，但是由于不保证原子性，最终值不到 20000
                       goods.addPlusPlus(); 
                       // goods.addMyAtomic();
                   }
               }, String.valueOf(i)).start();
           }
           // 需要等待前面的所有线程都计算完成后再走后面的 main 线程（为什么是大于 2？因为后台默认有两个线程：1. main 线程；2 GC 线程）
           while (Thread.activeCount() > 2) {
               Thread.yield(); // 挂起不执行此线程
           }
           System.out.println(Thread.currentThread().getName() + " --- int final num value --
           System.out.println(Thread.currentThread().getName() + " --- AtomicInteger final nu
       }
       // volatile 可以保证可见性，及时通知其它线程，主物理内存的值已经被修改。
       private static void visualByVolatile() {
           Goods goods = new Goods();
           new Thread(() -> {
               System.out.println(Thread.currentThread().getName() + " --- come in");
               // 执行业务逻辑
               try { TimeUnit.SECONDS.sleep(3); } catch (InterruptedException e) { e.printSta
               goods.buyGoods();
               System.out.println(Thread.currentThread().getName() + " --- update");
           }, "T1").start();
           // main 线程
           while (goods.num == 10) {
               // main 现在一直会在这里循环等待，直到商品库存不等于 10 才跳出循环
           }
           System.out.println(Thread.currentThread().getName() + " --- mission complete.");
       }
   }
   class Goods {
       // int num = 10;
       volatile int num = 10; // 用 volatile 保证数据可见性，没加 volatile 会导致 main 线程一直等待不结束
       AtomicInteger atomicInteger = new AtomicInteger();
       public void buyGoods() {
           this.num = this.num - 1;
       }
       // 注意此时 number 前面是加了 volatile 关键字修饰的，所以说 volatile 不保证原子性
       public void addPlusPlus() {
           num++;
       }
       public void addMyAtomic() {
           atomicInteger.getAndIncrement();
       }
   }
   ```

3. **讲一讲 Atomiclnteger，为什么要用 CAS 而不是 synchronized？（CAS知道吗？如何实现的？CAS有什么缺陷，该如何解决）**

   CAS ---> Unsafe ---> CAS 底层思想---> CAS 缺点（ABA问题） ---> 原子引用更新 ---> 如何规避 ABA 问题

   ```java
   public static void main(String[] args) {
           AtomicInteger atomicInteger = new AtomicInteger(10);
           System.out.println(atomicInteger.compareAndSet(10, 9) + " current value: " + atomicInteger.get());
           System.out.println(atomicInteger.compareAndSet(10, 8) + " current value: " + atomicInteger.get());
       }
   // true current value: 9
   // false current value: 9
   ```

   CAS（全称为：Compare And Swap 比较并交换）：是一种无锁算法，在不使用锁（没有线程被阻塞）的情况下实现多线程之间的变量同步。底层是 <font color='red'> 一条 CPU 并发原语 </font> ，功能是把物理内存的真实值和线程的期望值进行比较，如果相同就把最新值赋给主物理内存，否则就要重新获得主物理内存的最新值，循环 CAS 操作。并发原语的指令执行是原子性的，执行过程不可被中断。也就不会造成数据不一致的问题，说明是线程安全的

   > <font color='red'>CAS -> 无锁算法 -> 多线程之间变量同步 -> CPU 并发原语 -> 内存值和期望值 -> 原子的 -> 线程安全</font>

   ![CAS 解决 volatile 的原子性问题](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/CAS%20%E8%A7%A3%E5%86%B3%20volatile%20%E7%9A%84%E5%8E%9F%E5%AD%90%E6%80%A7%E9%97%AE%E9%A2%98.jpg)

   既然 volatile 无法保证原子性，那这回商品对象 Goods 的 num 值用 new AtomicInteger (10) 对象包裹起来，T1 线程想要修改主内存的值时，此时会把物理内存的真实值 10 和 T1 线程的期望值 10 进行比较，发现相同就替换，调用方法 incrementAndGet () 来进行 +1 操作来替换主内存值。接着 T2 线程过来发现主物理内存的真实值 11 和线程的期望值 10 不相同，结果替换失败，然后会重新读取主内存的真实值到 T2 线程的工作内存，再次重复去比较操作，直到成功为止

   > 并发原语：一般是指由若干条指令组成的程序段，用来实现某个特定功能，在执行过程中不可被中断。一旦开始执行，就不能被中断，否则就会出现操作错误，造成系统混乱。它不会造成数据不一致问题（也就说明它是线程安全的）

   **CAS 底层原理是什么？如果知道，谈谈你对 Unsafe 的理解**

   CAS 底层调用的是 Unsafe 类：

   1. 由于 Java 方法无法直接访问底层系统，只有通过本地（native）方法来访问。Unsafe 相当于开了一个后门，我们可以基于该类的方法来像 C 指针一样直接操作内存的数据

   2. 变量 valueOffset，表示该变量值在内存中的偏移地址，通过内存偏移地址可以获取到物理内存的真实值

   3. 变量 value 用 volatile 修饰，保证了多线程之间的内存可见性

   底层源码：查看 AtomicInteger 的自增函数 getAndIncrement () 的源码时，发现自增函数底层调用的是 unsafe.getAndAddInt ()。

   > 但是由于 JDK 本身只有 Unsafe.class，只通过 class 文件中的参数名，并不能很好的了解方法的作用，所以我们通过 OpenJDK 8 来查看 Unsafe 的源码：

   ```java
   // AtomicInteger 源码
   public class AtomicInteger extends Number implements java.io.Serializable 
       private static final long serialVersionUID = 6214790243416807050L;
       // setup to use Unsafe.compareAndSwapInt for updates
       private static final Unsafe unsafe = Unsafe.getUnsafe();
       private static final long valueOffset;
       static {
           try {
               valueOffset = unsafe.objectFieldOffset
                   (AtomicInteger.class.getDeclaredField("value"));
           } catch (Exception ex) { throw new Error(ex); }
       }
       private volatile int value;
   ```

   ```java
   // ------------------------- JDK 8 -------------------------
   // AtomicInteger 自增方法
   public final int getAndIncrement() {
     return unsafe.getAndAddInt(this, valueOffset, 1);
   }
   
   // Unsafe.class
   // var1：当前对象（AtomicInteger 对象）；var2：当前对象内存地址的值（偏移地址）；var5：期望值；var4：需要增加的数
   public final int getAndAddInt(Object var1, long var2, int var4) {
     int var5;
     do {
         // 获得当前对象的内存地址的值（相当于把主物理内存值拷贝到工作内存）
         var5 = this.getIntVolatile(var1, var2);
         // 如果当前对象 o 的 offset（内存地址的值）与
     } while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4));
     return var5;
   }
   
   // ------------------------- OpenJDK 8 -------------------------
   // Unsafe.java
   public final int getAndAddInt(Object o, long offset, int delta) {
      int v;
      do {
          // 期望值：获得当前对象的内存地址的值（把主物理内存的真实值拷贝到工作内存）
          v = getIntVolatile(o, offset);
          // 如果当前对象 o 的 offset（内存地址的值）与工作内存的期望值 v 相等，那么就替换主内存的值为 v + 需要变动的值 delta（v + 1）
      } while (!compareAndSwapInt(o, offset, v, v + delta));
      return v;
   }
   
   public final native boolean compareAndSwapInt(Object o, long offset, int expected, int x); // 底层是 C 或 C++ 的代码
   ```

   根据 OpenJDK 8 的源码我们可以看出，用 `getIntVolatile ()` 获得当前对象的内存地址值（相当于把主物理内存值拷贝到本地线程的工作内存），然后 `compareAndSwapInt()` 判断如果 `内存值` 与工作内存的 `期望值 v` 相等，那么就替换主内存的值为线程的最新值（ `v + 需要变动的值 delta（v + 1）`），否则返回 false，继续循环进行 CAS，直到设置成功为止才退出循环并且将旧的期望值返回。<font color='red'>CAS 最最底层是 JDK 通过调用汇编指令 lock cmpxchg（compare and exchange）</font>，cmpxchg 它也不是原子的，也可能被别的线程打断，需要加 lock 锁来锁住内存总线

   > 整个 “比较并更新” 操作封装在 compareAndSwapInt () 中，在 JNI（Java Native Interface） 里是借助于一个 CPU 指令完成的，属于原子操作，可以保证多个线程都能够看到同一个变量的最新值。

   **为什么要用 CAS 而不是 synchronized？**

   因为 synchronized 加锁之后，同一时间段只能有一个线程来访问，一致性得到了保障，但并发性下降（因为锁太重，锁住了整个方法或代码块）。而 CAS 是无锁（也就是没有 Kernel 内核状态的锁，不需要向内核申请），不断的比较并替换，这样就既保证了数据一致性，又保证了并发性

   **CAS缺点：**CPU - 共享变量 - ABA 问题

   1. **循环时间长且 CPU 开销大：**CAS 操作不成功会导致一直自旋，里面有个 do while 循环，会给 CPU 带来非常大的开销。

   2. **只能保证一个共享变量的原子操作：**当对一个共享变量执行操作时，我们可以使用循环 CAS 的方式来保证原子操作，但操作多个共享变量时就得加锁来保证原子性

      不过好在 Java 从 1.5 开始 JDK 提供了 AtomicReference 类来保证引用对象之间的原子性，可以把多个共享变量放在一个对象里来进行 CAS 操作。

   3. **ABA 问题：**首先是先把数据拷贝到 T1、T2 线程的工作内存，CAS 在操作值的时候会去检查内存值是否发生变化，没有发生变化才会更新内存值。比如内存值原来是 A，后来变为了 B，接着又变为了 A，然后 T1 线程挂起，T2 线程进行 CAS 比较时发现内存值没有发生变化，然后改为最新值 C。但是实际上内存值是有变化的，这就是 CAS 的 ABA 问题。

      ![ABA 问题](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/ABA%20%E9%97%AE%E9%A2%98.jpg)

      ABA 问题解决思路：

      > JDK 除了提供原子整型 AtomicInteger 之外，还提供了可自定义泛型的原子引用类 AtomicReference<V>

      - 在变量前面添加版本号，每次变量更新的时候都把版本号 +1，这样变化过程就从 “A－B－A” 变成了 “1A－2B－3A”。
      - JDK 从 1.5 开始提供了 AtomicStampedReference 类通过增加版本戳的方式来解决 ABA 问题
      
      ```java
      public class ABA {
      
          static AtomicReference<Integer> atomicReference = new AtomicReference<>(10);
          private static AtomicStampedReference<Integer> atomicStampedReference = new AtomicStampedReference<>(10, 1);
      
          public static void main(String[] args) {
              System.out.println("==================== ABA 问题产生 ===================");
              new Thread(() -> {
                  atomicReference.compareAndSet(10, 11);
                  atomicReference.compareAndSet(11, 10);
              }, "T1").start();
      
              new Thread(() -> {
                  // 确保上面的 T1 线程先完成 ABA 问题
                  try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); }
                  System.out.println(atomicReference.compareAndSet(10, 100) + " --- " + atomicReference.get());
              }, "T2").start();
      
              // 确保上面线程已执行完毕
              try { TimeUnit.SECONDS.sleep(2); } catch (InterruptedException e) { e.printStackTrace(); }
              System.out.println("=================== ABA 问题解决 ===================");
              new Thread(() -> {
                  int stamp = atomicStampedReference.getStamp();
                  System.out.println(Thread.currentThread().getName() + " --- " + "第 1 次版本号：" + stamp);
                  //暂停一会儿线程
                  try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); }
                  atomicStampedReference.compareAndSet(10, 11, atomicStampedReference.getStamp(), atomicStampedReference.getStamp() + 1);
                  System.out.println(Thread.currentThread().getName() + " --- " + "第 2 次版本号：" + atomicStampedReference.getStamp());
                  atomicStampedReference.compareAndSet(11, 10, atomicStampedReference.getStamp(), atomicStampedReference.getStamp() + 1);
              }, "T3").start();
      
              new Thread(() -> {
                  int stamp = atomicStampedReference.getStamp();
                  System.out.println(Thread.currentThread().getName() + " --- " + "第 1 次版本号：" + stamp);
                  // 确保上面的 T3 线程先完成 ABA 问题
                  try { TimeUnit.SECONDS.sleep(3); } catch (InterruptedException e) { e.printStackTrace(); }
                  boolean res = atomicStampedReference.compareAndSet(10, 100, stamp, stamp + 1);
                  System.out.println(Thread.currentThread().getName() + " --- " + res + "，当前版本号：" + atomicStampedReference.getStamp());
                  System.out.println(Thread.currentThread().getName() + " --- " + "最新值" + atomicStampedReference.getReference());
              }, "T4").start();
          }
          // ============================= ABA 问题产生 =============================
          // true --- 100
          // ============================= ABA 问题解决 =============================
          // T3 --- 第 1 次版本号：1
          // T4 --- 第 1 次版本号：1
          // T3 --- 第 2 次版本号：2
          // T4 --- false，当前版本号：3
          // T4 --- 最新值10
      }
      ```
      

4. **悲观锁 VS 乐观锁，请讲一下它们的优缺点**

   悲观锁与乐观锁是一种广义上的理念。在 Java 和数据库中都有对应的实际落地。

   what：

   - 对于同一个数据的并发操作，悲观锁认为它在操作数据时一定有别的线程来修改数据，因此它会在操作数据时先加锁来确保数据不会被其它线程修改。Java 中 synchronized 关键字和 Lock 的实现类都是悲观锁

   - 而乐观锁认为它在操作数据时不会有别的线程修改数据，所以不会添加锁，只是在更新数据的时候去判断之前有没有其它线程修改了数据。如果数据没有被修改，那么线程会将最新的数据写入主内存。如果数据已经被其他线程修改了，则根据不同的实现方式执行不同的操作（报错或者自旋）

     > 乐观锁在 Java 中是通过使用无锁编程来实现，最常采用的是 CAS 算法，Java 原子引用类中的递增操作就通过 CAS 自旋实现的。

   why：

   - 悲观锁适合写操作多的场景，像数据库这样需要保证数据一致性的，在写操作时加锁来保证数据一致性

     > 传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁

   - 乐观锁适合读操作多的场景，无锁的特性能够使其读操作的性能大幅提升。增大了系统吞吐量

     > 在数据库中可以定义一个 version 字段，在操作之前先获取当前数据的 version，在执行将获得的 version 当作参数传递到数据库，提交时判断当前的 version 和传入的 version 是否一致，如果不一致则认为别人已经操作过当前 version，就不允许提交

   ![悲观锁 VS 乐观锁](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/%E6%82%B2%E8%A7%82%E9%94%81%20VS%20%E4%B9%90%E8%A7%82%E9%94%81.png)

   how：

   光说概念有些抽象，我们来看下乐观锁和悲观锁的调用方式示例：

   ```java
   // ------------------------- 悲观锁的调用方式 -------------------------
   // synchronized
   public synchronized void testMethod() {
   	// 操作同步资源
   }
   // ReentrantLock
   private ReentrantLock lock = new ReentrantLock(); // 需要保证多个线程使用的是同一个锁
   public void modifyPublicResources() {
   	lock.lock();
   	// 操作同步资源
   	lock.unlock();
   }
   
   // ------------------------- 乐观锁的调用方式 -------------------------
   private AtomicInteger atomicInteger = new AtomicInteger();  // 需要保证多个线程使用的是同一个AtomicInteger
   atomicInteger.incrementAndGet(); //执行自增1
   ```

5. **谈谈你对 Synchronized 关键字的理解（Synchronized关键字的用法，优缺点 | Synchronized 和 Lock 的区别）**

   [只有马士兵老师能把多线程与高并发最底层的Synchronized原理和Volatile关键字的字节码原语讲的这么透彻_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1tz411q7c2?p=1)

   ==Synchronized 加锁，同一时间段只有一个线程来访问，其它线程会被 block 阻塞住，线程访问完之后才到下一个线程访问。它的一致性得到了保障但并发性、系统性能下降==

   ![1553322829198](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/1553322829198.png)

   通过 Monitor.Enter 和 Monitor.Exit 实现获得锁和释放锁的过程，后续的线程回去同步等待（Lock 可以主动去释放锁 Synchronized 是被动）（通过 Monitor.Enter 来获得锁，没有获得锁的会放到队列里面去，当 Monitor.Exit 出来以后通知队列去出队列，意味着让下一个线程继续获得这个锁）

   方法声明时使用，线程获得的是成员锁，即一次只能有一个线程进入该方法其他线程要想在此时调用该方法，只能排队等候，当前线程执行完该方法后，别的线程才能进入对某一代码块使用，这样一次只有一个线程进入该代码块。此时，线程获得的是成员锁使用 Synchronized，当多个线程尝试获取锁时，未获取到锁的线程会不断的尝试获取锁，而不会发生中断，这样会造成性能消耗 (Javap -v *.class 看字节码)

   

   用户态与内核态

   jdk 早期的时候，这个 synchronized 的底层实现是重量级锁，重量级到这个 synchronized 要去找操作系统去申请锁的地步，这就会造成效率非常低。后来 Java 开始越来越多的处理高并发程序，大家觉得这个 synchrionized 太重了不好用，后来改进之后才有了锁升级的概念

   这个锁升级的概念呢，是这样的，原来呢都要去找操作系统，要找内核去申请这把锁，到后期做了对 synchronized 的一些改进，他的效率比原来要改变了不少，改进的地方。

   当我们使用 synchronized 的时候 HotSpot 的实现是这样的：上来之后第一个去访问某把锁的线程 比如 sync (Object) ，来了之后先在这个 Object 的头上面 markword 记录这个线程。（如果只有第一个线程访问的时候实际上是没有给这个 Object 加锁的，在内部实现的时候，只是记录这个线程的 ID（偏向锁））

   偏向锁如果有线程争用的话，就升级为自旋锁，概念就是（有一个哥们儿在蹲马桶 ，另外来了一个哥们，他就在旁边儿等着，他不会跑到 cpu 的就绪队列里去，而就在这等着占用 cpu，用一个 while 的循环在这儿转圈玩儿， 很多圈之后不行的话就再一次进行升级）自旋锁转圈十次之后，升级为重量级锁，重量级锁就是去操作系统那里去申请资源。这是一个锁升级的过程

   > 补上上厕所带门的图----
   >
   > 偏向锁（实际也没有锁）：有点类似于我在厕所门口贴牌（Lock Header）说有人就把厕所占用了。多少情况下我们不需要把门锁住再上厕所，而是贴牌说有人就直接进去上厕所了，不经过操作系统效率更高。举例：
   >
   > 为什么会有偏向锁？
   >
   > 多数 synchronized 方法在很多情况下只有一个线程在运行
   >
   > - StringBuffer 中的一些 sync 方法
   >
   >   大部分时间只有自己一个线程在做 append() 操作，就不需要去申请大锁，直接贴牌说有人就进行操作了
   >
   > - Vector 中的一些 sync 方法
   >
   > 此时又来了两个线程，发现上面有贴牌，说怎么可以你一个人用呢，就开始采用 CAS 自旋锁操作，三个线程一起争抢，谁能贴上牌谁就能占用。当然刚开始的 T1 线程还是会优先的继续操作，其他两个线程会用 CAS 自旋来读取最新值，看现在还是不是你 T1 线程，如果不是了就赶紧把贴牌换成自己的，重复到成功为止
   >
   > 偏向锁 -> 轻量级锁：只有有线程来竞争就会升级为轻量级锁（CAS 不需要向内核申请大锁）
   >
   > 轻量级锁 -> 重量级锁：1.6 以前 while 循环自旋 10 圈之后，还没到我这个线程就会升级为重量级锁，或者有多个线程在等待，线程数超过核数的 1/2。而现在都是 JVM 做自适应升级，已经不用我们调了
   >
   > 还有一种情况是偏向锁里有线程有特别耗时的操作或者 wait ，就会造成 `重度竞争` ，直接升级为重量级锁
   >
   > **为什么已经有了轻量级锁了之后还需要重量级锁呢？**
   >
   > 在轻量级锁时，一个线程在做操作，其他线程会做 CAS 自旋，特别消耗 CPU 资源，假如有 1000 个线程在自旋等待的话情况更糟糕。此时就要用到重量级锁，重量级锁相当于一个等待队列 waitset，它会把之前所有在等待的线程全部放到等待队列里面来，然后由操作系统来唤醒该执行操作的线程来拿锁

   synchronized 的底层字节码实现：会发现有一个进入的操作 `monitorenter`，和两个出去的操作 `monitorexit` 。上锁解锁的意思

   那为什么一个会 `monitorenter` 会对应两个 `monitorexit` 呢？

   是因为第一个是正常退出，第二个 `monitorexit` 为了做异常退出，确保一定要退出

   ```java
    0 new #2 <java/lang/Object>
    3 dup
    4 invokespecial #1 <java/lang/Object.<init> : ()V>
    7 astore_1
    8 aload_1
    9 dup
   10 astore_2
   11 monitorenter
   12 getstatic #3 <java/lang/System.out : Ljava/io/PrintStream;>
   15 aload_1
   16 invokestatic #4 <org/openjdk/jol/info/ClassLayout.parseInstance : (Ljava/lang/Object;)Lorg/openjdk/jol/info/ClassLayout;>
   19 invokevirtual #5 <org/openjdk/jol/info/ClassLayout.toPrintable : ()Ljava/lang/String;>
   22 invokevirtual #6 <java/io/PrintStream.println : (Ljava/lang/String;)V>
   25 aload_2
   26 monitorexit
   27 goto 35 (+8)
   30 astore_3
   31 aload_2
   32 monitorexit
   33 aload_3
   34 athrow
   35 return
   ```

   **偏向锁是否一定比自旋锁效率高？**

   在明确知道有非常多线程回来抢占资源的时候，就绕过偏向锁了，直接进入重量级锁，偏向锁会多一步锁撤销（撕贴牌）过程

   > JVM启动过程，会有很多线程竞争（明确），默认情况下就会启动时不打开偏向锁，过一段儿时间再打开

   图里面的第二个匿名偏向

   刚上来的时候偏向锁已启动（没有加 synchronized，也就是匿名偏向

   内存屏障 lock addl

   > java -XX:+PrintFlagsFinal -version | [wc -l] [grep BiaseLocking]：拿到所有 -XX 参数，`wc -l` 打印出行数，`grep BiaseLocking` 过滤出和偏向锁相关的参数

6. **Synchronized 和 Lock 的区别**

   |                          | Synchronized                                                 | Lock                                                         |
   | :----------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
   | 原始构成                 | synchronized 关键字属于 JVM 层面<br />monitorenter 底层是通过 monitor 对象来完成，其实 wait / notify 等方法也依赖于 monitor 对象，只有在同步方法中才能调用 wait / notify 等方法<br />monitorexit | Lock 是具体类 [Lock (Java Platform SE 8 )](https://docs.oracle.com/javase/8/docs/api/) ，是 API 层面的锁 |
   | 使用方法                 | 不需要用户手动释放锁，JVM 会自动让线程释放对锁的占用         | ReentrantLock 需要用户手动释放锁，否则可能导致死锁现象       |
   | 等待是否可被中断         | 不可被中断，除非抛出异常或正常执行完成                       | 1. 设置超时时间 tryLock (long timeout,TimeUnit unit) <br />2. lockInterruptibly () 方代码块中，调用 interrupt () 方法可以中断 |
   | 加锁是否公平             | 非公平锁                                                     | ReentrantLock 两者都可以，默认是非公平锁，但构造方法内可以传入 boolean 值，true 为公平锁，false 为非公平锁 |
   | 锁绑定多个条件 Condition | 没有这个机制                                                 | ReentrantLock 可用来实现分组唤醒需要唤醒的线程，可以做到精确唤醒。而不是想 synchronized 一样要么随机唤醒一个线程，要么全部唤醒 |

   Lock 优势代码案例：

   ```java
   package com.liuilin.JUC;
   
   import java.util.concurrent.locks.Condition;
   import java.util.concurrent.locks.Lock;
   import java.util.concurrent.locks.ReentrantLock;
   
   /**
    * 题目：多线程之间按顺序调用，实现 A -> B-> C 三个线程启动，要求如下：
    *  T1 打印 1 次，T2 打印 2 次，T3 打印 3 次
    *  紧接着
    *  T1 打印 1 次，T2 打印 2 次，T3 打印 3 次
    *  来 2 轮
    *
    * @author liuqiang
    * @since 2021-08-03
    */
   public class SyncReentrantLockDemo {
   
       public static void main(String[] args) {
           ShareResource shareResource = new ShareResource();
           new Thread(() -> {
               for (int i = 1; i <= 2; i++) {
                   shareResource.print1();
               }
           }, "T1").start();
           new Thread(() -> {
               for (int i = 1; i <= 2; i++) {
                   shareResource.print2();
               }
           }, "T2").start();
           new Thread(() -> {
               for (int i = 1; i <= 2; i++) {
                   shareResource.print3();
               }
           }, "T3").start();
       }
       // =========================== print out ===========================
       // T1 print1() 打印第 1 次
       // T2 print2() 打印第 1 次
       // T2 print2() 打印第 2 次
       // T3 print3() 打印第 1 次
       // T3 print3() 打印第 2 次
       // T3 print3() 打印第 3 次
       // T1 print1() 打印第 1 次
       // T2 print2() 打印第 1 次
       // T2 print2() 打印第 2 次
       // T3 print3() 打印第 1 次
       // T3 print3() 打印第 2 次
       // T3 print3() 打印第 3 次
   }
   
   class ShareResource {
   
       private int num = 1;
       private Lock lock = new ReentrantLock();
       private Condition c1 = lock.newCondition();
       private Condition c2 = lock.newCondition();
       private Condition c3 = lock.newCondition();
   
       public void print1() {
           lock.lock();
           try {
               // 判断
               while (num != 1) {
                   c1.await();
               }
               // 干活
               for (int i = 1; i <= 1; i++) {
                   System.out.println(Thread.currentThread().getName() + " print1() 打印第 " + i + " 次");
               }
               // 唤醒通知 2 号线程
               num = 2;
               c2.signal();
           } catch (InterruptedException e) {
               e.printStackTrace();
           } finally {
               lock.unlock();
           }
       }
   
       public void print2() {
           lock.lock();
           try {
               // 判断
               while (num != 2) {
                   c2.await();
               }
               // 干活
               for (int i = 1; i <= 2; i++) {
                   System.out.println(Thread.currentThread().getName() + " print2() 打印第 " + i + " 次");
               }
               // 唤醒通知 3 号线程
               num = 3;
               c3.signal();
           } catch (InterruptedException e) {
               e.printStackTrace();
           } finally {
               lock.unlock();
           }
       }
   
       public void print3() {
           lock.lock();
           try {
               // 判断
               while (num != 3) {
                   c3.await();
               }
               // 干活
               for (int i = 1; i <= 3; i++) {
                   System.out.println(Thread.currentThread().getName() + " print3() 打印第 " + i + " 次");
               }
               // 重新唤醒通知 1 号线程
               num = 1;
               c1.signal();
           } catch (InterruptedException e) {
               e.printStackTrace();
           } finally {
               lock.unlock();
           }
       }
   }
   ```

   字节码

   ```java
   public static void main(String[] args) {
       synchronized (new Object()) {
       }
       new ReentrantLock();
   }
   ```

   ```java
   public static void main(java.lang.String[]);
     descriptor: ([Ljava/lang/String;)V
     flags: ACC_PUBLIC, ACC_STATIC
     Code:
       stack=2, locals=3, args_size=1
          0: new           #2                  // class java/lang/Object
          3: dup
          4: invokespecial #1                  // Method java/lang/Object."<init>":()V
          7: dup
          8: astore_1
          9: monitorenter
         10: aload_1
         11: monitorexit
         12: goto          20
         15: astore_2
         16: aload_1
         17: monitorexit
         18: aload_2
         19: athrow
         20: new           #3                  // class java/util/concurrent/locks/ReentrantLock
         23: dup
         24: invokespecial #4                  // Method java/util/concurrent/locks/ReentrantLock."<init>":()V
         27: pop
         28: return
       Exception table:
          from    to  target type
             10    12    15   any
             15    18    15   any
       LineNumberTable:
         line 12: 0
         line 14: 10
         line 15: 20
         line 16: 28
       LocalVariableTable:
         Start  Length  Slot  Name   Signature
             0      29     0  args   [Ljava/lang/String;
       StackMapTable: number_of_entries = 2
         frame_type = 255 /* full_frame */
           offset_delta = 15
           locals = [ class "[Ljava/lang/String;", class java/lang/Object ]
           stack = [ class java/lang/Throwable ]
         frame_type = 250 /* chop */
           offset_delta = 4
   ```

   <span id='lockDiff'>**Synchronized 和 ReentrantLock（可重入锁）的区别**</span>

   同：两者都是可重入锁

   | 异： | Synchronized                                                 | ReentrantLock                                                |
   | ---- | ------------------------------------------------------------ | ------------------------------------------------------------ |
   | 优点 | Synchronized 是 Java 里的关键字，优势在于不需要用户手动的去释放锁，也不会造成死锁，它会在方法或代码块执行完之后，系统自动让线程释放锁 | ReentrantLock 是类，那它就比 Synchronized 更灵活，可以被继承、可以有方法。ReentrantLock 可以在 try lock() 中可以给个规定时间，规定时间内拿不到锁就放弃 |
   | 缺点 | Synchronized 容易导致线程积压，因为它要等第一个线程锁释放之后才执行下一个线程。比如一段代码里面有个方法要执行 5s，那么其它线程只有等它执行完<br />ReentrantLock 可以在 try lock() 中可以给个规定时间，规定时间内拿不到锁就放弃 | 但它必须得在 finally 代码块中手动 unlock，不然会造成死锁     |

   > 抢不到锁就死等的业务用 Synchronized

   Synchronized :可重入锁、互斥性、可见性

7. **公平锁、非公平锁、可重入锁、递归锁、自旋锁，谈谈你对它们的理解？请手写一个自旋锁。**

   - 公平锁 VS 非公平锁

     公平锁：指多个线程按照申请锁的顺序来获取锁，类似于排队先到先得

     非公平锁：是指多个线程获取锁的顺序并不是按照申请锁的顺序来获取锁，有可能后申请的线程比先申请的线程优先获取锁。那在高并发的情况下，有可能会造成优先级反转或者饥饿现象

     > 优先级反转：就是前面的线程被后面的线程插队了
     >
     > 饥饿现象：后面的线程一直被插队，一直拿不到锁

     区别：

     公平锁优缺点：公平锁的优点是等待锁的线程不会饿死。缺点是整体吞吐效率相对非公平锁要低，等待队列中除第一个线程以外的所有线程都会阻塞，CPU 唤醒阻塞线程的开销比非公平锁大。

     非公平锁优缺点：非公平锁的优点是可以减少唤起线程的开销，整体的吞吐效率高，因为线程有几率不阻塞直接获得锁，CPU 不必唤醒所有线程。缺点是处于等待队列中的线程可能会饿死，或者等很久才会获得锁。

     并发包中 ReentrantLock 的创建可以指定构造函数的 boolean 类型来得到公平锁或非公平锁，默认不传是非公平锁，Synchronized 也是非公平锁

   - 可重入锁（递归锁）

     可重入锁又名递归锁，指的是同一个线程在外层方法获取锁的时候，再进入该线程的内层方法会自动获取锁（前提锁对象得是同一个对象或者 class），不会因为之前已经获得锁还没释放而被阻塞。Java 中 ReentrantLock 和 synchronized 都是可重入锁，它的优点是在一定程度上避免了死锁

     ```java
     package com.liuilin.JUC;
     
     import java.util.concurrent.TimeUnit;
     import java.util.concurrent.locks.Lock;
     import java.util.concurrent.locks.ReentrantLock;
     
     /**
      * 可重入锁代码演示
      * @author liuqiang
      * @since 2021-08-02
      */
     public class ReenterLockDemo {
     
         public static void main(String[] args) {
             Phone phone = new Phone();
             System.out.println("=========================== Synchronized ===========================");
             new Thread(() -> {
                 phone.sendSMS();
             }, "T1").start();
     
             new Thread(() -> {
                 phone.sendSMS();
             }, "T2").start();
     
             // 暂停一会儿线程
             try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); }
             System.out.println("=========================== ReentrantLock ===========================");
             Thread t3 = new Thread(phone, "T3");
             Thread t4 = new Thread(phone, "T4");
             t3.start();
             t4.start();
         }
         // =========================== Synchronized ===========================
         // T1 --- send message...
         // T1 --- send email
         // T2 --- send message...
         // T2 --- send email
         // =========================== ReentrantLock ===========================
         // T3 --- invoke get()...
         // T3 --- invoke set()
         // T4 --- invoke get()...
         // T4 --- invoke set()
     
     }
     
     class Phone implements Runnable {
     
         Lock lock = new ReentrantLock();
     
         public synchronized void sendSMS() {
             System.out.println(Thread.currentThread().getName() + " --- send message...");
             sendEmail();
         }
     
         public synchronized void sendEmail() {
             System.out.println(Thread.currentThread().getName() + " --- send email");
         }
     
         @Override
         public void run() {
             get();
         }
     
         private void get() {
             lock.lock();
             try {
                 System.out.println(Thread.currentThread().getName() + " --- invoke get()...");
                 set();
             } finally {
                 lock.unlock();
             }
         }
     
         private void set() {
             System.out.println(Thread.currentThread().getName() + " --- invoke set()");
         }
     }
     ```

   - 手写自旋锁

     ```java
     public class SpinLock {
     
         AtomicReference<Thread> atomicReference = new AtomicReference<>();
     
         public static void main(String[] args) {
             SpinLock spinLock = new SpinLock();
             new Thread(() -> {
                 spinLock.lock();
                 // 暂停一会儿线程
                 try { TimeUnit.SECONDS.sleep(5); } catch (InterruptedException e) { e.printStackTrace(); }
                 spinLock.unlock();
             }, "T1").start();
     
             // 暂停一会儿线程
             try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); }
             new Thread(() -> {
                 spinLock.lock();
                 // 暂停一会儿线程
                 try { TimeUnit.SECONDS.sleep(3); } catch (InterruptedException e) { e.printStackTrace(); }
                 spinLock.unlock();
             }, "T2").start();
         }
         // =========================== print out ===========================
         // T1 coming...
         // T2 coming...
         // T1 unlock...
         // T2 unlock...
     
         private void lock() {
             System.out.println(Thread.currentThread().getName() + " coming...");
             while (!atomicReference.compareAndSet(null, Thread.currentThread())) {
             }
         }
     
         private void unlock() {
             System.out.println(Thread.currentThread().getName() + " unlock...");
             atomicReference.compareAndSet(Thread.currentThread(), null);
         }
     }
     ```

   - 共享锁（读锁）VS 独占锁（排它锁 / 写锁）

     比如我在黑板上写东西，如果只允许一个人进来读写的话，虽然数据一致性可以保证，但是并发性急剧下降。应该让一个人一个人进来写操作时同时允许其他人可以在窗户外共享读

     - 独占锁：也叫排他锁，是指该锁一次只能被一个线程所持有。如果线程 T 对数据 A 加上排它锁后，则其他线程不能再对 A 加任何类型的锁。获得排它锁的线程即能读数据又能修改数据。JDK 中的 synchronized 和 JUC 中 Lock 的实现类就是互斥锁。

     - 共享锁：指该锁可被多个线程所持有。如果线程 T 对数据 A 加上共享锁后，则其他线程只能对 A 再加共享锁，不能加排它锁。获得共享锁的线程只能读数据，不能修改数据。

       对 ReentrantReadWriteLock 其读锁是共享锁，其写锁是独占锁。

       在 ReentrantReadWriteLock 里面，读锁和写锁的锁主体都是 Sync，但读锁和写锁的加锁方式不一样。读锁是共享锁，写锁是独占锁。读锁的共享锁可保证并发读非常高效，而读写、写读、写写的过程互斥，因为是读写分离的。所以 ReentrantReadWriteLock 的并发性相比一般的互斥锁有很大提升。

     读写锁：写操作是独占 + 原子，过程连续不可被分割和打断

     以下代码未加读写锁的时候，写操作会被打断，需要加写锁。读操作时允许它并发读

     ```java
     public class ReadWriteLockDemo {
     
         public static void main(String[] args) {
             Cache cache = new Cache();
             for (int i = 1; i <= 3; i++) {
                 int finalInt = i;
                 new Thread(() -> {
                     cache.put(String.valueOf(finalInt), String.valueOf(finalInt));
                 }, String.valueOf(i)).start();
             }
     
             for (int i = 1; i <= 3; i++) {
                 int finalInt = i;
                 new Thread(() -> {
                     cache.get(String.valueOf(finalInt));
                 }, String.valueOf(i)).start();
             }
         }
         // =========================== before print out ===========================
         // 1 线程正在写入...
         // 2 线程正在写入...
         // 3 线程正在写入...
         // 1 线程正在读取...
         // 2 线程正在读取...
         // 3 线程正在读取...
         // 1 线程写入完成
         // 2 线程读取完成，值为：null
         // 2 线程写入完成
         // 3 线程读取完成，值为：null
         // 1 线程读取完成，值为：null
         // 3 线程写入完成
         // =========================== after print out ===========================
         // 2 线程正在写入...
         // 2 线程写入完成
         // 1 线程正在写入...
         // 1 线程写入完成
         // 3 线程正在写入...
         // 3 线程写入完成
         // 1 线程正在读取...
         // 2 线程正在读取...
         // 3 线程正在读取...
         // 1 线程读取完成，值为：1
         // 2 线程读取完成，值为：2
         // 3 线程读取完成，值为：3
     
     }
     class Cache{
         private volatile Map<String, Object> map = new HashMap<>();
         private ReadWriteLock rwLock = new ReentrantReadWriteLock();
     
     
         public void put(String key,Object value){
             rwLock.writeLock().lock();
             try {
                 System.out.println(Thread.currentThread().getName() + " 线程正在写入...");
                 // 暂停一会儿线程
                 try { TimeUnit.MICROSECONDS.sleep(300); } catch (InterruptedException e) { e.printStackTrace(); }
                 map.put(key, value);
                 System.out.println(Thread.currentThread().getName() + " 线程写入完成");
             } finally {
                 rwLock.writeLock().unlock();
             }
     
         }
     
         public void get(String key){
             rwLock.readLock().lock();
             try {
                 System.out.println(Thread.currentThread().getName() + " 线程正在读取...");
                 // 暂停一会儿线程
                 try { TimeUnit.MICROSECONDS.sleep(300); } catch (InterruptedException e) { e.printStackTrace(); }
                 Object res = map.get(key);
                 System.out.println(Thread.currentThread().getName() + " 线程读取完成，值为：" + res);
             } finally {
                 rwLock.readLock().unlock();
             }
     
         }
     
     }
     ```

     > 凡是 Cache 缓存的东西，都要用 volatile 修饰，让别的线程立马可见。

8. **CountDownLatch、CyclicBarrier、Semaphore 使用过吗？**

   - CountDownLatch

     让一些线程阻塞直到另一些线程完成一系列操作后才被唤醒

     > Count DownLatch 主要有两个方法，当一个或多个线程调用 await 方法时，调用线程会被阻塞。其它线程调用 countDown () 方法时会将计数器减 1（调用 countDown () 方法的线程不会阻塞），当计数器的值变为零时，因调用 await 方法被阻塞的线程会被唤醒，继续执行。

     ```java
     @Getter
     @AllArgsConstructor
     enum CountryEnum {
         one(1, "齐"),
         two(2, "楚"),
         three(3, "燕"),
         four(4, "赵"),
         five(5, "魏"),
         six(6, "韩");
     
         private int code;
     
         private String desc;
     
         public static CountryEnum valueOf(Integer code) {
             return Arrays.stream(values())
                     .filter(v -> v.getCode() == code)
                     .findFirst()
                     .orElse(null);
         }
     }
     
     public class CountDownLatchDemo {
     
         public static void main(String[] args) throws InterruptedException {
             CountDownLatch countDownLatch = new CountDownLatch(3);
             for (int i = 1; i <= 3; i++) {
                 new Thread(() -> {
                     System.out.println(Thread.currentThread().getName() + " 上完自习，离开图书馆");
                     countDownLatch.countDown();
                 }, String.valueOf(i)).start();
             }
             countDownLatch.await();
             System.out.println(Thread.currentThread().getName() + " 最后关门走人");
     
             CountDownLatch countDownLatch1 = new CountDownLatch(6);
             // 暂停一会儿线程
             try { TimeUnit.SECONDS.sleep(3); } catch (InterruptedException e) { e.printStackTrace(); }
             for (int i = 1; i <= 6; i++) {
                 new Thread(() -> {
                     System.out.println(Thread.currentThread().getName() + " 国被灭");
                     countDownLatch1.countDown();
                 }, CountryEnum.valueOf(i).getDesc()).start();
             }
             countDownLatch1.await();
             System.out.println(Thread.currentThread().getName() + " 秦国一统天下");
         }
         // =========================== print out ===========================
         // 1 上完自习，离开图书馆
         // 3 上完自习，离开图书馆
         // 2 上完自习，离开图书馆
         // main 最后关门走人
         // 齐 国被灭
         // 楚 国被灭
         // 燕 国被灭
         // 韩 国被灭
         // 赵 国被灭
         // 魏 国被灭
         // main 秦国一统天下
     }
     ```

   - CyclicBarrier

     CyclicBarrier 的字面意思是可循环（ Cyclic）使用的屏障（Barrier）。它要做的事情是，让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续干活，线程进入屏障通过 CyclicBarrier 的 await（）方法。

     ```java
     public class CyclicBarrierDemo {
     
         public static void main(String[] args) {
             CyclicBarrier cyclicBarrier = new CyclicBarrier(7, () -> {
                 System.out.println(Thread.currentThread().getName() + " --- 七颗龙珠收集完成，开始召唤神龙...");
             });
             for (int i = 1; i <= 7; i++) {
                 int finalInt = i;
                 new Thread(() -> {
                     System.out.println(Thread.currentThread().getName() + " 收集到了第" + finalInt + "龙珠");
                     try {
                         cyclicBarrier.await();
                     } catch (InterruptedException e) {
                         e.printStackTrace();
                     } catch (BrokenBarrierException e) {
                         e.printStackTrace();
                     }
                 }, String.valueOf(i)).start();
             }
         }
     }
     ```

   - Semaphore

     信号量主要用于两个目的，一个是用于多个共享资源的互斥使用，另一个用于并发线程数的控制

     4 辆车抢 2 个车位

     ```java
     public class SemaphoreDemo {
     
         public static void main(String[] args) {
             Semaphore semaphore = new Semaphore(2);
             for (int i = 1; i <= 4; i++) {
                 new Thread(() -> {
                     try {
                         semaphore.acquire();
                         System.out.println(Thread.currentThread().getName() + " 抢到停车位");
                         // 暂停一会儿线程
                         try { TimeUnit.SECONDS.sleep(3); } catch (InterruptedException e) { e.printStackTrace(); }
                         System.out.println(Thread.currentThread().getName() + " 号线程停车 3s 后离开了停车场");
                     } catch (InterruptedException e) {
                         e.printStackTrace();
                     } finally {
                         semaphore.release();
                     }
                 }, String.valueOf(i)).start();
             }
         }
         // =========================== print out ===========================
         // 1 抢到停车位
         // 2 抢到停车位
         // 2 号线程停车 3s 后离开了停车场
         // 1 号线程停车 3s 后离开了停车场
         // 3 抢到停车位
         // 4 抢到停车位
         // 4 号线程停车 3s 后离开了停车场
         // 3 号线程停车 3s 后离开了停车场
     }
     ```

   **CyclicBarrier 和 CountDownLatch 的区别 **

   - CyclicBarrier 的某个线程运行到某个点上之后，该线程即停止运行，直到所有的线程都到达了这个点，所有线程才重新运行；CountDownLatch 则不是，某线程运行到某个点上之后，只是给某个数值 - 1 而已，该线程继续运行
   - CyclicBarrier 只能唤起一个任务，CountDownLatch 可以唤起多个任务
   - CyclicBarrier 可重用，CountDownLatch 不可重用，计数值为 0 该 CountDownLatch 就不可再用了

9. **阻塞队列知道吗？**

   阻塞队列，顾名思义，首先它是一个队列，而一个阻塞队列在数据结构中所起的作用大致如下图所示：
   当阻塞队列是空时，从队列中获取元素的操作将会被阻塞。
   当阻塞队列是满时，往队列里添加元素的操作将会被阻塞。

   > 蛋糕店的蛋糕还没生产出来的为空的时候，消费者消费蛋糕的操作会被阻塞。
   >
   > 蛋糕柜子只能放 10 个蛋糕，再生产出的蛋糕就会被阻塞

   **优点：**

   在多线程领域：所谓阻塞，在某些情况下会挂起线程（即阻塞），一旦条件满足，被挂起的线程又会自动被唤醒
   为什么需要 Blocking Queue？好处是我们不需要关心什么时候需要阻塞线程，什么时候需要唤醒线程，因为这一切 BlockingQueue 都给你一手包办了，在 concurrent 包发布以前，在多线程环境下，我们每个程序员都必须去自己控制这些细节，尤其还要兼顾效率和线程安全，而这会给我们的程序带来不小的复杂度。

   **BlockingQueue 架构梳理和分类：**

   - <font color='red'>ArrayBlockingQueue：由数组结构组成的有界阻塞队列 </font>
   - <font color='red'>LinkedBlockingDeque：由链表结构组成的有界（但大小默认值 Integer>MAX_VALUE）阻塞队列 PriorityBlockingQueue：支持优先级排序的无界阻塞队列 </font>
   - DelayQueue：使用优先级队列实现的延迟无界阻塞队列
   - <font color='red'>SynchronousQueue：不存储元素的阻塞队列，也即是单个元素的队列 </font>
   - LinkedTransferQueue：由链表结构组成的无界阻塞队列
   - LinkedBlockingDeque：由了解结构组成的双向阻塞队列

   **BlockingQueue 核心方法：**

   | 方法类型 | 抛出异常  | 特殊值   | 阻塞   | 超时               |
   | -------- | --------- | -------- | ------ | ------------------ |
   | 插入     | add(e)    | offer(e) | put(e) | offer(e,time,unit) |
   | 移除     | remove()  | poll()   | take() | poll(time,unit)    |
   | 检查     | element() | peek()   | 不可用 | 不可用             |

   - 抛出异常

     当阻塞队列满时，再往队列里面 add 插入元素会抛 IllegalStateException: Queue full

     当阻塞队列空时，再往队列 Remove 元素时候回抛出 NoSuchElementException

   - 特殊值插入方法，成功返回 true 失败返回 false

     移除方法，成功返回元素，队列里面没有就返回 null

   - 一直阻塞

     当阻塞队列满时，生产者继续往队列里面 put 元素，队列会一直阻塞直到 put 数据 or 响应中断退出

     当阻塞队列空时，消费者试图从队列 take 元素，队列会一直阻塞消费者线程直到队列可用

   - 超时退出

     当阻塞队列满时，队列会阻塞生产者线程一定时间，超过后限时后生产者线程就会退出

   **实际应用**

   - 生产消费者模式

     - 传统版

       为什么要用 lock 包替代 synchronized，api 文档说 lock 更具扩展性，因为 lock 是类，可继承，可重写等等

       > `Lock` implementations provide more extensive locking operations than can be obtained using `synchronized` methods and statements. They allow more flexible structuring, may have quite different properties, and may support multiple associated [`Condition`](https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/locks/Condition.html) objects.

       ```java
       package com.liuilin.JUC;
       
       import java.util.concurrent.locks.Condition;
       import java.util.concurrent.locks.Lock;
       import java.util.concurrent.locks.ReentrantLock;
       
       /**
        * 题目：一个初始值为零的变量，两个线程对其交替操作，一个加一个减 1，来 5 轮（相当于两个人操作空调，一个加一度，一个减一度，交替执行 5 次）
        *
        * 多线程模板的企业级口诀：高并发下前提一定是高内聚、低耦合
        * 上联：线程    操作  资源类（解耦，空调自带制冷制热功能，而非人的功能）
        * 下联：判断    干活  唤醒通知
        * 横批：严防多线程下的虚假唤醒
        *
        * @author liuqiang
        * @since 2021-08-03
        */
       public class ProdConsumer {
       
           public static void main(String[] args) {
               ShareData data = new ShareData();
               new Thread(() -> {
                   for (int i = 1; i <= 5; i++) {
                       try {
                           data.increment();
                       } catch (InterruptedException e) {
                           e.printStackTrace();
                       }
                   }
               }, "T1").start();
       
               new Thread(() -> {
                   for (int i = 1; i <= 5; i++) {
                       try {
                           data.decrement();
                       } catch (InterruptedException e) {
                           e.printStackTrace();
                       }
                   }
               }, "T2").start();
       
           }
       
       }
       
       class ShareData {
       
           Lock lock = new ReentrantLock();
           int num = 0;
           private Condition condition = lock.newCondition();
       
           public void increment() throws InterruptedException {
               lock.lock();
               try {
                   // 判断
                   while (num != 0) {
                       // 等待
                       condition.await();
                   }
                   // 干活
                   num++;
                   System.out.println(Thread.currentThread().getName() + " 生产一个 " + num);
                   // 唤醒通知
                   condition.signalAll();
       
               } finally {
                   lock.unlock();
               }
           }
       
           public void decrement() throws InterruptedException {
               lock.lock();
               try {
                   // 判断
                   while (num == 0) {
                       // 等待
                       condition.await();
                   }
                   // 干活
                   num--;
                   System.out.println(Thread.currentThread().getName() + " 消费一个 " + num);
                   // 唤醒通知
                   condition.signalAll();
       
               } finally {
                   lock.unlock();
               }
           }
       }
       ```

     - 阻塞队列版

       > 凡是写架构程序，给多人用时，一定要考虑通顺、适配和通用，也就是要传**接口**，不许传具体的类
       >
       > 写：足够的抽象，往高处写
       >
       > 查：足够的细节，往细节落地

       ```java
       public class ProdConsumer_BlockingQueueDemo {
       
           public static void main(String[] args) {
               MyResource myResource = new MyResource(new ArrayBlockingQueue<>(5));
               new Thread(() -> {
                   System.out.println(Thread.currentThread().getName() + " 生产线程启动");
                   try {
                       myResource.product();
                   } catch (InterruptedException e) {
                       e.printStackTrace();
                   }
               }, "Product").start();
       
               new Thread(() -> {
                   System.out.println(Thread.currentThread().getName() + " 消费线程启动");
                   try {
                       myResource.consume();
                   } catch (InterruptedException e) {
                       e.printStackTrace();
                   }
               }, "Consumer").start();
       
               // 暂停一会儿线程
               try { TimeUnit.SECONDS.sleep(5); } catch (InterruptedException e) { e.printStackTrace(); }
               myResource.stop();
               System.out.println(Thread.currentThread().getName() + " --- 5s 时间到，main 线程叫停一切");
           }
       
       }
       
       class MyResource {
       
           BlockingQueue<String> blockingQueue;
           private volatile boolean FLAG = true; // 默认开启生产和消费，volatile 保证生产后别的线程里面可见
           private AtomicInteger atomicInteger = new AtomicInteger();
       
           public MyResource(BlockingQueue<String> blockingQueue) {
               this.blockingQueue = blockingQueue;
               System.out.println(blockingQueue.getClass().getName());
           }
       
           public void product() throws InterruptedException {
               // 判断、干活、唤醒线程
               String data;
               while (FLAG) {
                   data = atomicInteger.getAndIncrement() + "";
                   boolean res = blockingQueue.offer(data, 2L, TimeUnit.SECONDS);
                   if (res) {
                       System.out.println(Thread.currentThread().getName() + " 开始生产，" + data + " 插入成功");
                   } else {
                       System.out.println(Thread.currentThread().getName() + " 开始生产，" + data + " 插入失败");
                   }
                   // 1s 生产一个
                   TimeUnit.SECONDS.sleep(1);
               }
               System.out.println(Thread.currentThread().getName() + " 停止生产");
           }
       
           public void consume() throws InterruptedException {
               while (FLAG) {
                   String res = blockingQueue.poll(2L, TimeUnit.SECONDS);
                   if (res == null || "".equalsIgnoreCase(res)) {
                       FLAG = false;
                       System.out.println(Thread.currentThread().getName() + " 超过 2s 没有获取到蛋糕，消费退出并停止获取");
                       return;
                   }
                   System.out.println(Thread.currentThread().getName() + " 消费蛋糕队列成功，值为：" + res);
               }
           }
       
           public void stop() {
               FLAG = false;
           }
       
       }
       ```

10. **Java 实现多线程有哪几种方式？JDK 1.0 就已经有了 Runnable 接口了，为什么还会有 Callable 接口呢？**

   - 继承 Thread

     new Thread ().start ()； 

   - 实现 Runable

     new Thread (Runnable).start ()

   - Callable + FutureTask

     ```java
     public class CallableDemo {
     
         public static void main(String[] args) throws ExecutionException, InterruptedException {
             // 两个线程：1. main 2. FutureTask
             FutureTask futureTask = new FutureTask<>(new MyCallable());
             FutureTask futureTask1 = new FutureTask<>(new MyCallable());
             new Thread(futureTask, "FutureTask").start();
     //        new Thread(futureTask, "FutureTask1").start(); // 同样的执行应该复用，不应该再计算第二次。所以 Callable 不会打印第二次
             new Thread(futureTask1, "FutureTask").start(); // 用多个 FutureTask 才会打印两次
     //        Integer res2 = (Integer) futureTask.get(); // 阻塞，等待线程执行完才走 res1 打印
     
             Integer res1 = 100;
     //        while (!futureTask.isDone()) {
     //        }
             System.out.println("先执行 futureTask，结果为：" + res1);
             // 要求获得 Callable 线程的计算结果，如果没有计算完成就要去抢，会导致阻塞，得把值结算完成
             Integer res2 = (Integer) futureTask.get(); // 不会阻塞，先打印 res1，再计算结果并等待线程返回
             System.out.println(res1 + res2);
         }
     
     }
     
     class MyCallable implements Callable {
     
         @Override
         public Integer call() throws Exception {
             System.out.println(Thread.currentThread().getName() + " running...");
             // 暂停一会儿线程
             TimeUnit.SECONDS.sleep(3);
             return 1000;
         }
     }
     ```

- 使用线程池 Executors.newCachedThreadPool () 代码：

  ```java
public class HowToCreateThread {
  
    public static void main(String[] args) {
          new MyThread().start();
          new Thread(new MyRunnable(), "Runnable").start();
          new Thread(new FutureTask<>(new MyCallable()), "Callable").start();
  
          ExecutorService service = Executors.newCachedThreadPool();
          service.execute(() -> {
              System.out.println(Thread.currentThread().getName() + " running...");
          });
          service.shutdown();
  
          new Thread(() -> {
              System.out.println(Thread.currentThread().getName() + " thread running...");
          }, "RunnableWithLambda").start();
      }
  
      static class MyThread extends Thread {
  
          @Override
          public void run() {
              System.out.println(Thread.currentThread().getName());
          }
  
      }
  
      static class MyRunnable implements Runnable {
  
          @Override
          public void run() {
              System.out.println(Thread.currentThread().getName());
          }
      }
  
      static class MyCallable implements Callable<Integer> {
  
          @Override
          public Integer call() throws Exception {
              System.out.println(Thread.currentThread().getName());
              return 1;
          }
      }
  }
  ```
  
  Runnable 没有返回值，Callable 有返回值。假如 100 个线程中有 2 个线程执行出错，可以返回是哪两个线程的问题
  
  Runnable 不能抛异常，Callable 可以抛异常。假如 100 个线程中有 2 个线程执行出错，可以看到不同的异常信息

  我平时使用的是 Runnable ，比如我在用懒汉的单例模式来测试它是不安全时

11. **我们知道 ArrayList 是线程不安全的，请编写一个不安全的案例并给出解决方案（方案：CopyOnWrite）**

    ```java
    /**
     * 1. 故障现象
     *  java.util.ConcurrentModificationException
     * 2. 导致原因
     *  并发争抢修改导致，参考我们的签名情况。
     *  一个人正在写入，另外一个人过来抢夺导致数据不一致异常。并发修改异常。
     * 3. 解决方案
     *  3.1 new Vector<>（）；
     *  3.2 Collections. synchronizedList（new ArrayList<>（））；
     *  3.3 new CopyOnWriteArrayList（）；
     * 4. 优化建议（同样的错误不犯第2次）
     * */
    public static void main(String[] args) {
            // List<String> list = new ArrayList<>();
            // List<String> list = new Vector<>();
            // List<String> list = Collections.synchronizedList(new ArrayList<>());
            List<String> list = new CopyOnWriteArrayList<>();
            for (int i = 1; i <= 30; i++) {
                new Thread(() -> {
                    list.add(UUID.randomUUID().toString().substring(0, 8));
                    System.out.println(list);
                }, String.valueOf(i)).start();
            }
    }
    ```

    <img src="https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/CopyOnWrite%20%E5%86%99%E6%97%B6%E5%A4%8D%E5%88%B6%E5%8E%9F%E7%90%86.jpg" alt="CopyOnWrite 写时复制原理" style="zoom: 33%;" />

    CopyonWrite 容器即写时复制的容器。往一个容器添加元素的时候，不直接往当前容器 object [] 添加，而是先将当前容器 bject [] 进行 copy，复制出一个新的容器 object [] newElements，然后新的容器 object [] newElements 里添加元素，添加完元素之后，再将原容器的引用指向新的容器 setArray（newElements）；这样做的好处是可以对 CopyonWrite 容器进行并发的读，而不需要加锁，因为当前容器不会添加任何元素。所以 CopyonWrite 容器也是一种读写分离的思想，读和写不同的容器

    源码：

    ```java
    /**
     * Appends the specified element to the end of this list.
     *
     * @param e element to be appended to this list
     * @return {@code true} (as specified by {@link Collection#add})
     */
    public boolean add(E e) {
        final ReentrantLock lock = this.lock;
        lock.lock();
        try {
            Object[] elements = getArray();
            int len = elements.length;
            Object[] newElements = Arrays.copyOf(elements， len + 1);
            newElements[len] = e;
            setArray(newElements);
            return true;
        } finally {
            lock.unlock();
        }
    }
    ```

12. **TransferValue 值传递问题**

    ```java
    public class TestTransferValue {
    
        // age = 20
        // person.getName() = liu
        // str = Daniel
        public static void main(String[] args) {
            TestTransferValue test = new TestTransferValue();
            int age = 20;
            test.changeValue1(age);
            System.out.println("age = " + age); // 打印的是 main 方法数据
    
            Person person = new Person("lin");
            test.changeValue2(person);
            System.out.println("person.getName() = " + person.getName()); // 打印的是 main 方法数据
    
            String str = "Daniel";
            test.changeValue3(str);
            System.out.println("str = " + str); // 打印的是 main 方法数据
        }
    
        private void changeValue3(String str) {
            str = "xxx";
        }
    
        private void changeValue2(Person person) {
            person.setName("liu");
        }
    
        private void changeValue1(int age) {
            age = 30;
        }
    
    }
    
    @Getter
    @Setter
    @AllArgsConstructor
    class Person {
    
        private String name;
    
    }
    ```

    ![值传递问题](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/%E5%80%BC%E4%BC%A0%E9%80%92%E9%97%AE%E9%A2%98.jpg)

13. **谈谈你对线程池的理解（线程池的工作原理，几个重要参数，然后给了具体几个参数分析线程池会怎么做，最后问阻塞队列的作用是什么？）**

    > 镜像问题：
    >
    > 阿里：线程池的构造类的方法的 5 个参数的具体意义？
    >
    > 美团：使用无界阻塞队列会出现什么问题？
    >
    > 百度：线程池用过吗都有什么参数？底层如何实现的？

    线程池 = ThreadPoolExecutor 类 + 阻塞队列

    - **为什么用线程池？优势是什么**

      new Thread () 每次运行后都还需要 JVM 垃圾回收 

      用线程池之后就不需要我们自己 new 了，就要 Spring 一样，提前注入好，用的时候直接从池里拿

      优势：

      线程池做的工作主要是控制运行的线程的数量，处理过程中 <font color='red'> 将任务放入队列 </font>，然后在线程创建后启动这些任务，如果 <font color='red'> 线程数量超过了最大数量超出数量的线程排队等候 </font>，等其它线程执行完毕，再从队列中取出任务来执行。
      他的主要特点为：<font color='red'> 线程复用；控制最大并发数；管理线程 </font>。
      第一：降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。
      第二：提高响应速度。当任务到达时，任务可以不需要的等到线程创建就能立即执行。
      第三：提高线程的可管理性。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控

      // Array - Arrays | Collection - Collections | Executor - Executors

    - **线程池如何使用？**

      <img src="https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/%E7%BA%BF%E7%A8%8B%E6%B1%A0%E6%9E%B6%E6%9E%84.jpg" alt="线程池架构" style="zoom: 50%;" />

      编码实现：

      所有线程池底层都会调用 ThreadPoolExecutor 类

      ```java
    public ThreadPoolExecutor(int corePoolSize,
                                int maximumPoolSize,
                                long keepAliveTime,
                                TimeUnit unit,
                                BlockingQueue<Runnable> workQueue,
                                ThreadFactory threadFactory,
                                RejectedExecutionHandler handler) {
      // ...
    }
      ```

      - newFixedThreadPool(int nThreads)

        执行长期的任务，性能好很多（多个线程交替执行）
      
        ```java
        public static ExecutorService newFixedThreadPool(int nThreads) {
            return new ThreadPoolExecutor(nThreads, nThreads,
                                          0L, TimeUnit.MILLISECONDS,
                                          new LinkedBlockingQueue<Runnable>());
        }
        ```
      ```
      
      ```
      
    - Executors.newSingleThreadExecutor()
      
      一个任务一个任务执行的场景
      
        ```java
        public static ExecutorService newSingleThreadExecutor() {
            return new FinalizableDelegatedExecutorService
                (new ThreadPoolExecutor(1, 1,
                                        0L, TimeUnit.MILLISECONDS,
                                        new LinkedBlockingQueue<Runnable>()));
      }
        ```
      
      - Executors.newCachedThreadPool()
      
        执行很多短期异步的小程序或者负载较轻的服务器（不知道会用多少线程，不够就扩容）

        ```java
        public static ExecutorService newCachedThreadPool() {
            return new ThreadPoolExecutor(0, Integer.MAX_VALUE,
                                          60L, TimeUnit.SECONDS,
                                          new SynchronousQueue<Runnable>());
        }
        ```
      
        > 还有了解的 2 种
        >
        > newScheduledThreadPool(int corePoolSize)
        >
        > newWorkStealingPool() // Java 8 新出
      
        ```java
        public class ThreadPoolDemo {
        
            public static void main(String[] args) {
        //        ExecutorService threadPool = Executors.newFixedThreadPool(5); // 一池 5 个处理线程（银行 5 个处理业务窗口）
        //        ExecutorService threadPool = Executors.newSingleThreadExecutor(); // 一池 1 个处理线程（只有一个工作人员上班）
                ExecutorService threadPool = Executors.newCachedThreadPool(); // 一池 N 线程，随机扩容多线程
        
                // 池化技术先关池，再操作业务
                try {
                  for (int i = 1; i <= 10; i++) {
                        threadPool.execute(() -> System.out.println(Thread.currentThread().getName() + " 办理业务"));
                      // 暂停一会儿线程
                        try { TimeUnit.MICROSECONDS.sleep(200); } catch (InterruptedException e) { e.printStackTrace(); }
                    }
                } catch (Exception e) {
                    e.printStackTrace();
                } finally {
                    threadPool.shutdown();
                }
            }
        
        }
        ```
      
    - **ThreadPoolExecutor 类 7 大参数的含义：**

      1. corePoolSize：线程池中常驻线程核心数

         在创建了线程池后，当有请求任务来之后就会安排池中的线程去执行请求任务（今日当值线程）

         当线程池中的线程数目达到 corePoolSize后，就会把到达的任务放到缓存队列当中；

      2. maximumPoolSize：线程池能够容纳同时执行的最大线程数，必须大于 1

      3. keepAliveTime：多余的空闲线程的存活时间

         当空闲时间达到 keepAliveTime 并且线程池数量超过 corePoolSize，那么多余的空闲线程会被销毁直到只剩下 corePoolSize 个线程为止
         
      4. unit：KeepAliveTime 的单位

      5. workQueue：阻塞队列，被提交但是还未被执行的任务

      6. threadFactory：线程工厂，用来生成线程池中的工作线程。用于创建线程（一般用默认的即可）

      7. handler：拒绝策略，表示当队列满了并且工作线程 >= 线程的最大线程数 maximumPoolSize

    - **说说线程池的底层工作原理？**

      1. 在创建了线程池之后，线程池会等待提交过来的请求任务。当调用 execute () 方法时就会添加一个请求任务，此时线程池会做判断，如果正在运行的线程数量 < corePoolSize 时，会立马创建线程来执行这个任务

      2. 请求任务变多以后，正在运行的线程数量 > corePoolSize，那么会将这个任务<font color='red'>放入阻塞队列</font>

      3. 阻塞队列也满了并且正在运行的线程数还 < maximumPoolSize，那么还是会创建非核心线程来执行这个任务（相当于在扩容）

      4. 非核心线程也满了并且正在运行的线程数还 >=  maximumPoolSize，那么线程池会执行拒绝策略

      5. 当一个核心线程完成一个任务后，它会从阻塞队列中获取下一个任务来执行

      6. 当一个线程无事可做并且时间超过设置的 keepAliveTime 时，线程池就会判断：

         i. 如果当前运行的线程数 > corePoolSize，那么这个线程就被停掉

         ii. 当线程池执行完所有任务后最终把线程容量会收缩到 corePoolSize 的大小

    ![线程池底层工作原理](https://cdn.jsdelivr.net/gh/liuilin/interview@master/interview_note/img/%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%BA%95%E5%B1%82%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86.jpg)
    ![线程池的主要处理流程图](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/%E7%BA%BF%E7%A8%8B%E6%B1%A0%E7%9A%84%E4%B8%BB%E8%A6%81%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B%E5%9B%BE.jpg)
        

14. **线程池用过吗？生产上你是如何设置参数的？**

    - 线程拒绝策略请你讲讲

      JDK 内置拒绝策略：

      - AbortPolicy (默认)：直接抛出 RejectedException 异常阻止系统正常运行（生产上不敢用，上来就是报异常）
      - CallerRunPolicy:"调用者运行" 一种调节机制，该策略既不会抛弃任务，也不会抛出异常，而是
      - DiscardOldestPolicy：抛弃队列中等待最久的任务，然后把当前任务加入队列中尝试再次提交
      - DiscardPolicy：直接丢弃任务，不予任何处理也不抛出异常。如果允许任务丢失，这是最好的拒绝策略
      
      ```java
      public static void main(String[] args) {
          ThreadPoolExecutor threadPool = new ThreadPoolExecutor(
                  2,
                  5,
                  1L,
                  TimeUnit.SECONDS,
                  new LinkedBlockingQueue<>(3),
                  Executors.defaultThreadFactory(),
                  // new ThreadPoolExecutor.AbortPolicy()
                  // new ThreadPoolExecutor.CallerRunsPolicy()
                  // new ThreadPoolExecutor.DiscardPolicy()
                  new ThreadPoolExecutor.DiscardOldestPolicy()
          );
          // 池化技术先关池，再操作业务
          try {
              for (int i = 1; i <= 10; i++) {
                  threadPool.execute(() -> System.out.println(Thread.currentThread().getName() + " 办理业务"));
              }
          } catch (Exception e) {
              e.printStackTrace();
          } finally {
              threadPool.shutdown();
          }
      }
      ```
      
    - 你在工作中单一的/固定数的/可变的三种创建线程池的方法，你哪个用的多？超级大坑

      答：一个都不用，我是用自定义的。虽然 JDK 内置了 4 种拒绝策略，但是 Executors 返回的线程池对象允许的请求队列长度是 20 多亿，相当于初始化后银行候客区就有 20 多亿的位置，任务哗的一下就把堆撑满了，堆积大量请求，从而导致 OOM。

      > 阿里巴巴开发手册说道
      >
      > 【强制】线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 的方式，这样
      > 的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。
      >
      > 说明： Executors 返回的线程池对象的弊端如下：
      >
      > 1） FixedThreadPool 和 SingleThreadPool:
      >
      > 允许的请求队列长度为 Integer.MAX_VALUE，可能会堆积大量的请求，从而导致 OOM。
      >
      > 2） CachedThreadPool 和 ScheduledThreadPool:
      >
      > 允许的创建线程数量为 Integer.MAX_VALUE， 可能会创建大量的线程，从而导致 OOM。

    - 合理配置线程池你是如何考虑的？

      - CPU 密集型（里面有 while 循环，CPU 哗的一下就上来了）

        what：是该任务需要大量的运算，而没有阻塞，CPU 一直全速运行。

        CPU 密集任务只有在真正的多核 CPU 上才可能得到加速（通过多线程），单线程得不到加速，CPU 的限制

        CPU 密集型任务配置尽可能少的线程数量（一核 CPU 跑一个线程）：一般公式：CPU 核数 + 1 个线程的线程池

      - IO 密集型

        what：会频繁的去数据库读取数据，有 1w 个任务要去数据库 MySQL、Redis 取数据，就叫 IO 密集型
        
        i. 由于 IO 密集型任务线程并不是一直在执行任务，则应配置尽可能多的线程，如 CPU 核数 * 2
        
        ii. IO 密集型时，大部分线程都阻塞，故需要多配置线程数：
        
        参考公式：CPU 核数 / 1 - 阻塞系数
        
        阻塞系数在 0.8~0.9 之间
        
        比如 8 核 CPU：8/1-0.9=80 个线程数
        
        ```java
        // 获取 CPU 核数
        maximumPoolSize = Runtime.getRuntime().availableProcessors() / 1 - 0.9
        ```

15. **死锁编码及定位分析**

    <img src="https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/%E6%AD%BB%E9%94%81.jpg" alt="死锁" style="zoom: 50%;" />

    what：死锁是指两个或两个以上的进程在执行过程中，因争夺资源而造成的一种 <font color='red'> 互相等待 </font> 的现象，若无外力干涉那它们都将无法推进下去。（相当于两个人用手枪互相指着对方）

    why：

    - 系统资源不足
    - 进程运行推进的顺序不合适
    - 资源分配不当

    代码：

    ```java
    public class DeadLockDemo {
    
        public static void main(String[] args) {
            new Thread(new ThreadLockHolder("lockA", "lockB"), "T1").start();
            new Thread(new ThreadLockHolder("lockB", "lockA"), "T2").start();
        }
    
    }
    
    class ThreadLockHolder implements Runnable {
    
        String lock1;
        String lock2;
    
        public ThreadLockHolder(String lockA, String lockB) {
            this.lock1 = lockA;
            this.lock2 = lockB;
        }
    
        @Override
        public void run() {
            synchronized (lock1) {
                System.out.println(Thread.currentThread().getName() + " 自己持有：" + lock1 + "，尝试获得：" + lock2);
                // 暂停一会儿线程
                try { TimeUnit.SECONDS.sleep(2); } catch (InterruptedException e) { e.printStackTrace(); }
                synchronized (lock2) {
                    System.out.println(Thread.currentThread().getName() + " 自己持有：" + lock2 + "，尝试获得：" + lock1);
                }
            }
        }
    }
    ```

    > 注意构造方法，T1 构造的是 lock1 = lockA，T2 构造的是 lock1 = lockB
    >
    > 解读：T1 到 synchronized 那拿到 lockA，接着挂起 2s。T2 进来拿到 lockB 并挂起。都挂完后，T1 发现需要拿到 lock2（lockB）才能往下走，而 T2 线程需要拿到 lock2（lockB）才能往下走。结果出现了互相等待，从而产生死锁

    解决：

    - i. jps -l：Output the full package name for the application's main class or the full path name to the application's JAR file. （输出在运行程序的完整类名）

      ii. 找到 27484 com.liuilin.JUC.DeadLockDemo

      ii. jstack 27484：发现死锁

      ```java
      Java stack information for the threads listed above:
      ===================================================
      "ThreadB":
              at com.liuilin.JUC.ThreadLockHolder.run(DeadLockDemo.java:37)
              - waiting to lock <0x00000007178edd68> (a java.lang.String)
              - locked <0x00000007178edda0> (a java.lang.String)
              at java.lang.Thread.run(Thread.java:748)
      "ThreadA":
              at com.liuilin.JUC.ThreadLockHolder.run(DeadLockDemo.java:37)
              - waiting to lock <0x00000007178edda0> (a java.lang.String)
              - locked <0x00000007178edd68> (a java.lang.String)
              at java.lang.Thread.run(Thread.java:748)
      
      Found 1 deadlock.
      ```

      找到问题所在，修改代码并告知运维

    - jconsole：连接到对应的线程后可直接查看死锁

16. **Lock接口有哪些实现类，使用场景是什么。**

17. **可重入锁的用处及实现原理，写时复制的过程，读写锁，分段锁（ConcurrentHashMap中的segment）**

18. **如何控制线程执行的顺序（ABC三个线程如何保证顺序执行）**

    方法一：可以用线程类的join()方法去保证多线程的顺序性，里面调用的是Object的wait()方法

    join：让主线程等待，子线程结束以后才能继续执行

    ```java
    public static void main(String[] args) throws InterruptedException { 
        thread1.start()；
        threadl.join()；
        thread2.start()；
        thread2.join()；
        thread3.start()；
    }
    ```

    ![1554214612631](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/1554214612631.png)

    方法二：ExecutorService executor = Executors.newSingleThreadExecutor()；

    它是创建一个只有一个线程的线程池不限数量的一个队列，如果通过这个方法去执行，它会把线程放到一个队列里面，而这个队列属于FIFO，这样就达到了一个排队的效果

    ```java
    static ExecutorService executorService = Executors.newSingleThreadExecutor()；
    public static void main(String[] args) throws InterruptedException{
        executorService.submit(threadl)；
        executorService.submit(thread2)；
        executorService.submit(thread3)；
        executorService.shutdown)；
    }
    ```

19. **线程的状态都有哪些（多线程的生命周期）**

    新建、就绪、运行、阻塞、死亡

20. **sleep 和 wait 的区别 **

    sleep () 方法可以在任何地方使用、wait () 方法则只能在同步方法或同步块中使用

    sleep () 是线程 Thread 类的方法，调用后会暂停此线程指定的时间，但监控依然保持，不会释放对象锁，到时间自动恢复

    wait () 是 Object 的方法，调用后会放弃对象锁，进入等待队列，只有调用 notify ()/notifyAll () 才能唤醒指定的线程或者所有线程

21. **notify 和 notifyall 的区别 **

    当一个线程进入 wait 之后，就必须等其他线程进行 notify/notifyall，使用 notifyall，可以唤醒
    所有处于 wait 状态的线程，使其重新进入锁的争夺队列中，而 notify 只能唤醒一个。注意，任何时候只有一个线程可以获得锁，也就是说只有一个线程可以运行 Synchronized 中的代码，notifyall 只是让处于 wait 的线程重新拥有锁的争夺权，但是只会有一个获得锁并执行

22. **谈谈你对 ThreadLocal 的了解，实现原理**

    ThreadLocal 可以看做是一个容器，容器里面存放着属于当前线程的变量。ThreadLocal 类提供了四个对外开放的接口方法

    - void set (Object value) 设置当前线程的线程局部变量的值。
    - public Object get () 该方法返回当前线程所对应的线程局部变量。 
    - public void remove () 将当前线程局部变量的值删除，目的是为了减少内存的占用
    - protected Object initialValue () 返回该线程局部变量的初始值。那 ThreadLocal 内部是如何为每一个线程维护变量副本的呢 其实在 ThreadLocal 类中有一个静态内部类 ThreadLocalMap (其类似于 Map)，用键值对的形式存储每一个线程的变量副本，ThreadLocalMap 中元素的 key 为当前 ThreadLocal 对象，而 value 对应线程的变量副本，每个线程可能存在多个 ThreadLocal

23. **那么请谈谈 AQS 框架是怎么回事儿？**

    [[Deep AQS Principle\] I've drawn 35 diagrams to get you deep into AQS](https://programmer.group/deep-aqs-principle-i-ve-drawn-35-diagrams-to-get-you-deep-into-aqs.html)

    ![img](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/974795c5b6dbbed65b345d8b4d2ec091.jpg)

    AQS：AbstractQueueSynchronizer 抽象队列同步器


### 数据库相关

==SQL题练习：==https://www.jianshu.com/p/476b52ee4f1b

数据库高并发优化思路：http://www.imooc.com/learn/194

1. **数据库性能优化（数据库高并发优化思路）**
- SQL语句优化
- 索引优化
   - 数据库结构优化
- 系统配置优化
   - 服务器硬件优化

2. **事务**

   1. MySQL数据库中事务默认自动提交事务，提交的两种方式：

      自动提交：MySQL就是自动提交的一条DML(增删改)语句会自动提交一次事务

      手动提交：Oracle 数据库默认是手动提交事务需要先开启事务，再提交

      > 修改事务的默认提交方式：set @@autocommit = xx；1 代表自动提交，0 代表手动提交

   2. 事务的四大特征（ACID）：

      - 原子性（Atomic）：是不可分割的最小操作单位，要么同时成功，要么同时失败

      - 一致性（Consistency）：当事务提交或回滚后，数据库会持久化的保存数据

        > 只有合法的数据才可以被写入数据库，否则事务应将其回滚到最初状态。像转账的时候呢不会出现一方少钱了，另一方没有增加的情况

      - 隔离性（Isolation）：事务允许多个用户对同一个数据进行并发访问，而不破坏数据的正确性和完整性。同时，并行事务的修改必须与其他并行事务的修改相互独立

      - 持久性（Durability）：一个事务一旦被提交，它对数据库中数据的改变就是永久性的，接下来即使数据库发生故障也不应该有任何影响

   3. 并发事务带来哪些问题?  

      概念：多个事务之间隔离的，相互独立的。但是如果多个事务操作同一批数据，则会引发一些问题，设置不同的隔离级别就可以解决这些问题。

      存在问题：

      - 脏读：一个事务，读取到另一个事务中没有提交的数据
      - 虚读（不可重复读）：在同一个事务中，两次读取到的数据不一样。
      - 幻读：一个事务操作(DML)数据表中所有记录，另一个事务添加了一条数据，则第一个事务查询不到自己的修改。

   4. 事务的隔离级别：

      - read uncommitted：读未提交

        > 产生的问题：脏读、不可重复读、幻读

      - read committed：读已提交 （Oracle）  不允许读没有提交的数据

        > 产生的问题：不可重复读、幻读

      - repeatable read：可重复读 （MySQL默认）  可以做到同一个事务每次读取的数据是一致的()

        > 产生的问题：幻读

      - serializable：串行化  相当于多线程中的锁，一个事务在操作的时候，其他事务不能进行操作
        可以解决所有的问题（但是效率低）

        > 注意：隔离级别从小到大安全性越来越高，但是效率越来越低
        > 数据库查询隔离级别：select @@tx_isolation;
        > 数据库设置隔离级别：set global transaction isolation level 级别字符串

3. **什么是索引？索引的优缺点，什么字段上建立索引**

   索引：是帮助数据库高效获取数据的排好序的数据结构

   优点：

   - 极大的减少存储引擎需要扫描的数据量
   - 能将随机io变成顺序io
   - 能够帮助我们进行分组、排序等操作

   缺点：

   - 降低更新表的速度，MySQL不仅要存储数据，同时还需要保留下一个节点的地址，当改变了索引后，索引树需要发生改变
   - 占用空间

4. **索引的分类**

   普通索引、唯一索引、主键索引、组合索引（复合索引）

   聚簇索引：指多个字段上创建的索引，只有在查询条件中使用了创建索引时的第一个字段，索引才会被使用。所以它是遵循最左前缀法则的

5. **数据库连接池。**

6. **Durid的常用配置**

7. **存储引擎InnoDB与MyISAM区别**

   区别与使用场景：

   - InnoDB 是事务安全的，支持行级锁定，包括ACID事务支持。如果应用中需要执行大量的INSERT或UPDATE操作，则应该使用InnoDB，这样可以提高多用户并发操作的性能
   - MyISAM 是非事务安全的，支持表级锁定，并且支持全文索引。如果应用中需要执行大量的SELECT查询就用MyISAM

   > http://blog.haohtml.com/wp-content/uploads/2017/01/timg.jpg
   >
   > InnoDB使用的是聚簇索引，将主键组织到一棵B+树中，而行数据就储存在叶子节点上，若使用”where id = 14″这样的条件查找主键，则按照B+树的检索算法即可查找到对应的叶节点，之后获得行数据。若对Name列进行条件搜索，则需要两个步骤：第一步在辅助索引B+树中检索Name，到达其叶子节点获取对应的主键。第二步使用主键在主索引B+树中再执行一次B+树检索操作，最终到达叶子节点即可获取整行数据。 
   >
   > MyISM使用的是非聚簇索引，非聚簇索引的两棵B+树看上去没什么不同，节点的结构完全一致只是存储的内容不同而已，主键索引B+树的节点存储了主键，辅助键索引B+树存储了辅助键。表数据存储在独立的地方，这两颗B+树的叶子节点都使用一个地址指向真正的表数据，对于表数据来说，这两个键没有任何差别。由于索引树是独立的，通过辅助键检索无需访问主键的索引树。 

8. **B-tree**

   关键字对应的数据存在叶子节点上，树节点是按顺序排列的

9. **关于倒排索引**

   不是由记录来确定属性值，而是由属性值来确定记录的位置，因而称为倒排索引(inverted index)倒排索引由两个部分组成：单词词典和倒排文件lucene是基于倒排索引实现的

10. **sql连接查询**

   left join（左连接）：返回包括左表中的所有记录和右表中连接字段相等的记录

   right join （右连接）：返回包括右表中的所有记录和左表中连接字段相等的记录

   inner join （等值连接）：只返回两个表中连接字段相等的行

   full join （全外连接）：返回左右表中所有的记录和左右表中连接字段相等的记录

11. **常见的数据库优化手段**

- 表的设计要规范，选取最适用的字段属性
- 适当建立索引，在频繁作为检索条件，更新较少的字段上建立索引，以提高查询速度
- 分表查询，有水平分割、垂直分割
- 读写分离，读(read)、写(create、update、delete)
- 使用explain来优化查询语句

11. **explain分析语句（itkr）**

    - 执行explain包含的信息

      ![img](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/8dcf3edf-3423-4229-aef0-e9dbf1d42597-877132.jpg)

    - ==id字段三种情况介绍==（优化重要点）

      - 在id相同情况下

        关联查询，执行的顺序由table字段上至下的

        ![img](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/ef75044f-246a-40c1-b2b7-faf323b6f34d-877132.jpg)

      - 在id不同的情况下

        子查询，id的序号会递增，id值越大优先级越高，越先被执行

        ![img](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/dc10b860-29e8-4d00-91b4-cb79360ad708-877132.jpg)

      - 在id相同和不同同时存在的情况下

        - id如果相同，可以认为是一组，从上往下顺序执行，在所在组中，id值越大，优先级越高，越先执行

        - DERIVED表示衍生，意思是s1是通过t3衍生得来的

          ![img](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/bdda6cdc-5b73-4e64-ae35-11a1c938ca77-877132.jpg)

    - select_type的类型

      - simple：简单的select查询，查询中不包含子查询或者union
      - primary：查询中若包含任何复杂的子查询部分，最外层的查询被标记为primary
      - subquery：在select或where列表中包含了子查询
      - derived：在from列表中包含了子查询被标记为derived(衍生)，MySQL会递归执行这些子查询，把结果放在临时表里
      - union
      - union result

    - ==type查询类型介绍==（优化重要点）

      - all：全表扫描，当数据达到百万级别时，性能会有下降，这时需要根据业务情况考虑是否添加索引
      - index：index与all的区别为index类型只遍历索引树。这通常比all快，因为索引文件通常比数据文件小也就是说虽然all和index都是读全表，但index是从索引中读取的，而all是从硬盘中读的​
      - range：只检索给定范围的行，使用一个索引来选择行，key列显示使用了哪个索引一般就是在你的where语句中出现了between，<、>、in等查询​这种范围扫描索引比全表扫描要好，因为它只需要开始于索引的某一点，结束于另一点，不用全部索引​
      - ref
        非唯一性单值索引扫描，返回匹配某个单独值的所有行，它可能会找到多个符合条件的行，所以属于查询和扫描的混合体
      - eq_ref
        唯一索引扫描，对于每个索引键，表中只有一条记录与之匹配
      - const
        表示通过唯一索引一次就找到了，const用于比较primary key或unique索引
      - system
        表只有一条记录，等同于系统表，可以忽略不计
        
        > 从最好到最差依次是
        > system > const > eq_ref > ref > range > index > all
        >
        > 一般来说我会保证查询至少达到range级别，要是能达到ref​就更好

    - possible_keys介绍

      显示可能应用在这张表中的索引，一个或多个查到涉及到的字段上若存在索引，则该索引将被列出，但不一定被查询实际使用

    - ==key介绍==（优化重要点）

      实际使用的索引，如果为NULL，则没有使用索引查询

      若使用了覆盖索引，则该索引仅出现在key列表中possible_keys只是MySQL理论上推测应该用到的索引，但实际上应该以key用到的索引为准

    - key_len介绍

      表示索引中使用的字节数，可通过该列计算查询中使用的索引长度，在不损失精确性的情况下，长度越短越好

    - ref介绍

      显示索引的哪一列被使用了

    - ==rows==（优化重要点）

      大致估算出找到结果所需要读取的行数，这个值是越小越好

    - extra

      using index：出现这个说明MySQL使用了覆盖索引，避免访问了表的数据行，效率不错
      
      using where：这说明服务器在存储引擎收到行后将进行过滤
      
      using temporary：这意味着MySQL对查询结果进行排序的时候使用了一张临时表
      
      using filesort：这个说明MySQL会对数据使用一个外部的索引排序，而不是按照表内的索引顺序进行读取​​​

12. **索引失效**

    > 为staffs表建立了复合索引，索引列为name、age、pos

    ![img](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/cb4572c4-c85e-4eeb-9cbe-e04a56bb4b7c-877132.jpg)

    - 最佳左前缀法则

      - 依次执行三条查询SQL，索引情况正常，都使用到了

        按照索引建立的顺序依次进行查询

        ![img](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/c6e30510-90c1-4246-9f17-1fcd3ed51e6e-877132.jpg)

      - 出现索引失效情况

        未按照索引建立的顺序，跳过第一个索引name，直接使用后面两个查询

        ![img](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/0367427b-ea74-4008-933e-236bf9c234b1-877132.jpg)

      - 总结
        ==如果索引了多列，查询要遵守最左前缀法则。（指的是查询从索引的最左前列开始并且不要跳过索引中的列）==

    - 不要在索引列上做任何（计算、函数、（自动or手动）类型转换）操作，会导致索引失效而转向全表扫描

      在第二条sql中对name索引列查询时使用了left函数，则导致了索引失效

      ![img](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/4de861be-977e-43e2-99e9-8478dc2b433c-877132.jpg)

    - 存储引擎不能使用索引中范围条件右边的的列

      当索引条件中出现了 >、<、in一类的范围条件时，会导致索引失效

      ![img](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/1d342ffd-16cd-4768-b302-1997d3935f7d-877132.jpg)

    - 尽量使用覆盖索引，只访问索引查询，减少select *

      使用select * 和 select 字段，在extra字段上会有一定性能差距

      ![img](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/e7a1004e-515f-4b62-9ed6-0a58dd62a15b-877132.jpg)

    - MySQL中使用is null 或者 is not null，会导致索引失效

      ![img](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/b32c77e7-c197-4602-ab9b-cc318d9879b0-877132.jpg)

    - like以通配符开关 '%adb'，会导致索引失效

      - 当使用like查询时，只 % 在最右边时，MySQL才会使用到索引

        ![img](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/fda5e070-a0a2-4842-9015-37f20388454c-877132.jpg)

      - 如果必须要使用 like %abd%，的解决方案，使用覆盖索引，建立的索引和查询的字段在顺序，个数上最好保持一致

        ![img](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/7d26f956-61b3-41e2-ac6b-0e9c990ae14b-877132.jpg)

    - 字符串不加单引号索引失效

      当name查询条件值跟的是数字时，如果不加单引号，MySQL会自动隐式转换为数字

      ![img](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/a2e7cac8-a6b5-4a8e-9774-b5819d4bee32-877132.jpg)

    - 少用or，用它会导致索引失效

13. **SQL优化**

    https://www.cnblogs.com/Little-Li/p/8031295.html

    i. 尽量不要在 where子句中对字段进行表达式操作或是进行 null 值判断，这样会导致全表索
    
    ii. like也将导致全表扫描，只在%在最右边时才会走索引
    
    iii. 很多时候用 exists 代替 in
    
    iv. 索引并不是越多越好，索引固然可以提高相应的 select 的效率，但同时也降低了 insert 及 update 的效率，因为 insert 或 update 时有可能会重建索引，所以怎样建索引需要慎重考虑，视具体情况而定。一个表的索引数最好不要超过6个，如果太多则应考虑一些不常使用到的列上建的索引是否有必要
    
    v. 尽可能的使用varchar代替char，可以节省存储空间
    
    vi. 如果索引了多列，查询要遵守最左前缀法则
    
    > 1.提高type的等级
    >
    > 2.第二个是看rows是否是减少了的
14. **数据库分页**

    limit

15. **SQL注入问题**

    在拼接sql时，有一些sql的特殊关键字参与字符串的拼接会造成安全性问题a' or 'a' = 'a最终是个恒等式。可以用PreparedStatement对象来解决，“？”作为参数占位符

17. **怎么实现锁表**

### 计算机网络

### Java WEB

1. **cookie 和 session 的区别 **  

   - cookie 数据保存在客户端（最大存 4k），session 数据保存在服务端
   - session 是保存在服务器端的，每个用户都会产生一个 session。并发访问的用户十分多的话会产生非常多的 session，耗费大量的内存，考虑到减轻服务器的压力，可以将不重要的数据放在 cookie 中持久的保存，平时也用来记录用户的一些信息
   - session 的运行依赖 session id，而 session id 是存在 cookie 中的，也就是说如果浏览器禁用了 cookie，同时 session 也会失效（重写 URL，可以在 URL 中传递 session_id）

2. **Get 和 Post 请求方式的区别？**  

   - get 地址栏有参数显示；post 不会再地址栏显示参数 (参数是放在了请求体）
   - get 不安全会限制大小；post 相对安全而理论上不限制大小

2. **Servlet 的生命周期 **  

   - 第一次请求时 Servlet 被初始化且只初始化一次。所以 tomcat 容器中每一个 servlet 只有一个对象存在
   - 初始化后先调用 init 方法，只执行一遍
   - 每个请求，调用一遍 service -> service -> doGet/doPost。以多线程的方式运行
   - 卸载前调用 destroy 方法
   
4. **重定向和转发的区别？**  

   - 重定向是客户端行为，转发是服务器端行为
   - 重定向两次请求两次响应，转发一次请求一次响应
   - 重定向路径需要加工程名，转发的路径不需要加工程名.
   - 重定向可以跳转到任意网站，转发只能在服务器内部进行转发.
   - 重定向会导致 request 对象信息丢失。转发则不会

2. <span id='session'>**session 共享怎么做的（分布式如何实现 session 共享）**</span>

   - 可以使用 tomcat 广播机制实现 session 共享
   - 可以使用 Redis+tomcat 实现 session 共享
   - 可以使用 Spring session 完成 session 共享

3. **Servlet 是安全的吗？**

   是线程不安全的，因为 servlet 是单例模式，当多个客户端共同访问的时候线程不安全。
   尽量用局部变量，同步块，如果当前字段是不会改变的，用 final 修饰

4. **Token**

   - 客户端通过登录请求提交用户名和密码，服务端验证通过后生成一个 Token 与该用户进行关联，并将 Token 返回给客户端
   - 客户端在接下来的请求中都会携带 Token，服务端通过解析 Token 检查登录状态
   - 当用户退出登录、其他终端登录同一账号（被顶号）、长时间未进行操作时 Token 会失效，这时用户需要重新登录

### 设计模式

1. **单例模式，有五种写法，可以参考文章单例模式的五种实现方式**

   what：保证一个类仅有一个实例，并提供全局访问点

   why：

   i. 在内存里只有一个实例，减少了内存开销。特别是那种需要频繁的创建而创建的过程又无法优化的对象

   ii. 避免对资源的多重占用

   iii. 通过私有构造方法保证别的对象无法创建改对象

   **饿汉式：**

   优点：类加载的时候就完成了初始化，避免了线程安全问题

   缺点：没有延迟加载的效果，如果这个类从始至终都没有用过，会造成系统资源的浪费（用懒汉式替代）

   > 懒汉式的 instance 不能修饰为 final 的，因为在修饰前没有初始化好，设为 final 之后就不能修改了
   >
   > 饿汉式用 final 的 instance 实例的话，就得用 `static { instance = new HungrySingleton();}` 静态代码块先完成初始化，并把成员变量 instance 修改为 `private static final HungrySingleton instance` 即可

   ```java
   public class HungrySingleton {
       private static final HungrySingleton instance = new HungrySingleton(); // 类加载的时候就初始化了，final 修饰不可更改
       public HungrySingleton() { }
       public HungrySingleton getInstance() { return instance; }
   }
   ```

   <span id='singleton'>**懒汉式单例（普通版）：**</span>

   ```java
   /**
    * 懒汉模式
    */
   public class LazySingleton {
   
       // 这里用 static是因为 getInstance() 方法是静态的，而静态方法不能访问非静态成员变量，所以instance 必须是静态成员变量
       // getInstance() 方法是静态是因为构造器是私有的，只能通过 Singleton.getInstance() 方法获取对象实例
       private static LazySingleton instance = null;
   
       // 构造器是私有是为了防止其他类通过 new LazySingleton() 来创建对象实例
       private LazySingleton() {
           System.out.println(Thread.currentThread().getName() + " --- 我是构造方法");
       }
   
       public static LazySingleton getInstance() {
           if (instance == null) {
               instance = new LazySingleton();
           }
           return instance;
       }
   
   
       public static void main(String[] args) {
           // 单线程（mian 线程）情况下只构造了一个对象，没有线程安全问题
   //        System.out.println(SingletonDemo.getInstance() == SingletonDemo.getInstance());
   //        System.out.println(SingletonDemo.getInstance() == SingletonDemo.getInstance());
   
           // 打印出多行，说明构造了多个对象，会出现线程安全问题
           for (int i = 1; i <= 10; i++) {
               new Thread(() -> {
                   Singleton.getInstance();
               }, String.valueOf(i)).start();
           }
           
           // 实现 Runnable 方式测试
           // Thread t1 = new Thread(new T());
           // Thread t2 = new Thread(new T());
           // t1.start();
           // t2.start();
       }
   }
   
   class T implements Runnable {
   
       @Override
       public void run() {
           LazySingleton instance = LazySingleton.getInstance();
           System.out.println(Thread.currentThread().getName() + " " + instance);
       }
   }
   ```

   普通版懒汉式会造成线程安全问题，接着需要优化为 [DCL](#DCL) 单例。

   **DCL 双重校验锁单例：**

   ```java
   private static volatile LazySingleton instance = null;
   //...
   public static LazySingleton getInstance() {
       if (instance == null) {
           synchronized (LazySingleton.class) {
               if (instance == null) {
                   instance = new LazySingleton();
               }
           }
       }
       return instance;
   }
   ```

   

3. **Mybatis用到了哪些设计模式**

   - 工厂方法模式（Factory Method pattern）：一对一的关系，一个工厂创建一个与其对应的对象，由子类实现创建对象的操作

     > 参考JdbcTransactionFactory和DefaultObjectFactory.create()，DefaultObjectFactory.create()代码实现如下：
     >
     > ```java
     > @SuppressWarnings("unchecked")
     > @Override
     > public <T> T create(Class<T> type， List<Class<?>> constructorArgTypes， List<Object> constructorArgs) {
     >     Class<?> classToCreate = resolveInterface(type)；
     >     // we know types are assignable
     >     return (T) instantiateClass(classToCreate， constructorArgTypes， constructorArgs)；
     > }
     > ```

   - 建造者模式（Builder pattern）：创建的对象属性比较复杂，要分步骤处理，还是就是构造函数传的参数比较多的情况，对构造函数进行拆分，最后返回一个对象

     > 具体实现也可以不用抽象的Builder，视具体情况而定，可以参考ResultMap：
     >
     > ```java
     > public ResultMap build() {
     >       if (resultMap.id == null) {
     >         throw new IllegalArgumentException("ResultMaps must have an id")；
     >       }
     >       resultMap.mappedColumns = new HashSet<String>()；
     >       resultMap.idResultMappings = new ArrayList<ResultMapping>()；
     >       resultMap.constructorResultMappings = new ArrayList<ResultMapping>()；
     >       resultMap.propertyResultMappings = new ArrayList<ResultMapping>()；
     >       for (ResultMapping resultMapping : resultMap.resultMappings) {
     >           //判断是内嵌查询还是内嵌结果集
     >         resultMap.hasNestedQueries = resultMap.hasNestedQueries || resultMapping.getNestedQueryId() != null；
     >         resultMap.hasNestedResultMaps = resultMap.hasNestedResultMaps || (resultMapping.getNestedResultMapId() != null && resultMapping.getResultSet() == null)；
     >         final String column = resultMapping.getColumn()；
     >         if (column != null) {
     >             //将内部标签属性为column的添加早已映射列
     >           resultMap.mappedColumns.add(column.toUpperCase(Locale.ENGLISH))；
     >         } else if (resultMapping.isCompositeResult()) {
     >           for (ResultMapping compositeResultMapping : resultMapping.getComposites()) {
     >             final String compositeColumn = compositeResultMapping.getColumn()；
     >             if (compositeColumn != null) {
     >               resultMap.mappedColumns.add(compositeColumn.toUpperCase(Locale.ENGLISH))；
     >             }
     >           }
     >         }
     >         if (resultMapping.getFlags().contains(ResultFlag.CONSTRUCTOR)) {
     >           resultMap.constructorResultMappings.add(resultMapping)；
     >         } else {
     >           resultMap.propertyResultMappings.add(resultMapping)；
     >         }
     >         if (resultMapping.getFlags().contains(ResultFlag.ID)) {
     >           resultMap.idResultMappings.add(resultMapping)；
     >         }
     >       }
     >       if (resultMap.idResultMappings.isEmpty()) {
     >         resultMap.idResultMappings.addAll(resultMap.resultMappings)；
     >       }
     >       // lock down collections
     >       resultMap.resultMappings = Collections.unmodifiableList(resultMap.resultMappings)；
     >       resultMap.idResultMappings = Collections.unmodifiableList(resultMap.idResultMappings)；
     >       resultMap.constructorResultMappings = Collections.unmodifiableList(resultMap.constructorResultMappings)；
     >       resultMap.propertyResultMappings = Collections.unmodifiableList(resultMap.propertyResultMappings)；
     >       resultMap.mappedColumns = Collections.unmodifiableSet(resultMap.mappedColumns)；
     >       return resultMap；
     >     }
     > }
     > ```

   - 装饰器模式（Decorator pattern）：通过传入的委派对象，去改变本身对象的责任与行为

     > 参考执行器CachingExecutor、以及缓存实现都用了装饰器模式，CachingExecutor就是一个装饰对象代码如下，通过构造函数传入委派对象Executor ：
     >
     > ```java
     > public class CachingExecutor implements Executor {
     >     private static final Logger log = LoggerFactory.getLogger(CachingExecutor.class)；
     > 
     >   private Executor delegate；
     >   private TransactionalCacheManager tcm = new TransactionalCacheManager()；
     > 
     >   public CachingExecutor(Executor delegate) {
     >     this.delegate = delegate；
     >     delegate.setExecutorWrapper(this)；
     >   }
     > ......
     > }
     > ```

   - 动态代理模式（Proxy pattern）：由JDK的Proxy对象生成代理对象，运行期间动态执行目标方法

     > 参考MapperProxyFactory（相当于客户端）、MapperProxy（代理对象）、SqlSession（委派执行对象），MapperProxy执行源码：
     >
     > ```java
     > @Override
     > public Object invoke(Object proxy， Method method， Object[] args) throws Throwable {
     >     if (Object.class.equals(method.getDeclaringClass())) {
     >       try {
     >         return method.invoke(this， args)；
     >       } catch (Throwable t) {
     >         throw ExceptionUtil.unwrapThrowable(t)；
     >       }
     >     }
     >     //缓存真实调用方法，args为真实方法的参数
     >     final MapperMethod mapperMethod = cachedMapperMethod(method)；
     >     log.debug("执行Mapper类中的方法")；
     >     return mapperMethod.execute(sqlSession， args)；
     > }
     > ```
     >
     > 此外mybatis的logging包下面的ConnectionLogger、PreparedStatementLogger、ResultSetLogger等都是动态代理对象

4. **其他设计模式**

   - 工厂模式：将每个对象，交给了各自工厂去创建。有猫工厂，狗工厂，作用就是建立对象

   - 装饰者模式（增强HttpServletRequest对象、IO流）：继承、装饰者模式、动态代理
     - 增强的内容是不能修改的

     - 被增强的对象可以是任意的

       ```java
       class 咖啡类 {}
       class 有糖咖啡 extends 咖啡类 {}
       class 加奶咖啡 extends 咖啡类 {}
       class 加盐咖啡 extends 咖啡类 {}
       咖啡 a = new 加糖()；
       咖啡 b = new 加盐(a)；//对a进行装饰，就是给a加盐
       咖啡 c = new 加奶(b)；
       ```

   - 组合模式：集合

   - 桥接模式：JDBC编程

4. **设计模式的的六大原则及其含义**

   - 开闭原则（Open Close Principle）

     定义：一个软件实体如类、模块和函数应该对扩展开放，对修改关闭。

     用抽象构建框架，用实现扩展细节

     优点：提高软件系统的可复用性及可维护性

     > 公司的弹性制就是开闭原则，对八小时工作制度的修改是关闭的，什么时候来什么时候走是开放的。早点来的可以早点走，晚点来的晚点走。总之要满足八小时制
     >
     > 实际项目中不能用 System.out.println ("")，因为里面是有锁

     核心思想：就是面向接口编程，而不是面向具体的类。发生变化时可以创建抽象方法来处理新的变化

   - 里氏代换原则（Liskov Substitution Principle）

     里氏代还原则是面向对象设计的基本原则之一。原则：基类存在的的地方，子类一定存在。
     
   - 依赖倒转原则（Dependence Inversion Principle）

     这个原则是开闭原则的基础，针对接口编程，依赖于抽象而不依赖于具体。
     
   - 接口隔离原则（Interface Segregation Principle）

     使用多个隔离的接口，降低类之间的耦合度。便于升级和维护，降低依赖，降低耦合。
     
   - 迪米特法则，又称最少知道原则（Demeter Principle）

     一个实体应当尽量少地与其他实体之间发生相互作用，使得系统功能模块相对独立。
     
   - 合成复用原则（Composite Reuse Principle）

     尽量使用合成、聚合的方式，而不是用继承。

### 分布式系统

1. **谈谈分布式事务（分布式事务的控制）**

   - 事务的ACID特性

     原子性、一致性、隔离性、持久性
   - 分布式事务的产生的原因

     数据库分库分表、应用服务化
   - 分布式事务的应用场景

     支付、电商平台下单
   - 常见的分布式事务解决方案

     消息事务 + 最终一致性，所谓的消息事务就是基于消息中间件的两阶段提交，本质上是对消息中间件的一种特殊利用，它是将本地事务和发消息放在了一个分布式事务里，保证要么本地操作成功成功并且对外发消息成功，要么两者都失败1、A 系统向消息中间件发送一条预备消息 2、消息中间件保存预备消息并返回成功 3、A 执行本地事务 4、A 发送提交消息给消息中间件

2. **谈谈分布式锁（分布式锁如何设计）**

   [分布式锁](#RedLock)

3. **什么是微服务**

   微服务一种架构模式或者说是一种架构风格，它提倡应用程序单一化，每个服务运行在其独立的进程中，服务间采用轻量级通信机制（通常是基于http的restful api）就是将传统的单一应用，根据业务拆分成一个一个的服务，彻底去耦合，一个服务只做一件事，能够单独启动或销毁，拥有独立的数据库

4. **微服务优缺点**

   优点每个服务足够内聚、足够单一，代码更容易聚焦到指定的业务 微服务能够被小团队单独开发，小团队一般是由 2 到 5 人组成微服务能够使用不同语言开发微服务只是关心业务逻辑代码，不会和 html，css 或其它界面组件混合，每个微服务都有自己的存储能力，可以有单独数据库，也可以有统一数据缺点开发人员要处理分布式系统的复杂性 随着服务的增加，运维的压力也会增大，系统部署依赖程度高服务间通信也会有成本，系统需要集成测试性能的监控

5. **什么是服务熔断？什么是服务降级**

   服务熔断是应对雪崩效应的一种微服务保护机制，hystrix 会监控服务间调用情况，如果服务出现异常则会走 fallback 备选处理，熔断机制注解是 @HystrixCommand 服务降级处理是在客户端处理的，与服务端没有关系，统一在客户端接口中声明 @FeignClient-->fallbackFactory 属性指定服务出错的处理，这样就能将服务端容错出现彻底解耦出来

6. **CAP（请说下 Redis/eureka 和 zookeeper 两个的区别）**

   Redis 保证的是 AP：Redis 集群部署时，set 一条数据，首先会回复 OK，再把数据异步复制给从节点。它保证的是高可用，但牺牲了数据一致性

   Eureka 保证的是 AP：Eureka 在设计时就先保证了可用性，节点间都是平等的，节点挂掉不会影响其它节点的工作，Eureka 的客户端在向某个 Eureka 注册服务时如果失败，则会自动切换至其它节点

   Zookeeper 保证的是 CP：它是把主节点的数据同步给 slave 节点，保证所有的都同步了才返回 OK。这样 Zookeeper 的高可用和并发性就下降了

   > 当 master 节点失去联系时，剩余节点会重新进行 leader 的选举，但是 leader 的选举时间过长（一般在 30s~120s）且选举期间整个集群是不可用的，这就会导致选举期间注册服务瘫痪

   - CAP 理论：CAP 理论核心是一个分布式系统不可能同时很好满足一致性、可用性、分区容错性这三个需求

   总结：Eureka/Redis 可以很好的应对因网络故障导致的节点丢失这种情况，而 zk 则会使整个注册服务瘫痪

7. **分布式 session 如何设计**

   [见 Java WEB](#session)

### Redis 缓存相关

1. <span id='CPU'>**Redis都有哪些数据类型？分别在哪些场景下使用比较合适？**</span>

   > [Command reference – Redis](https://redis.io/commands)

   i. String：做基础的 k/v 缓存

   使用场景：

   - 商品编号、订单号可用采用 INCR 命令生成，每次 +1
   - 微信公众号：是否喜欢作者、统计阅读数（只要点击了 restful 地址，就是用 INCR key 命令使数字 +1）
     <img src="https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/image-20210726153732341.png" alt="image-20210726153732341" style="zoom:25%;" />

   ii. List：有序列表（LRANGE 命令可以做分页）

   场景：微信订阅的微信公众号发布的文章可用 List

   ![image-20210726152607272](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/image-20210726152607272.png)

   ```bash
   127.0.0.1:6379> LPUSH likeauthor:uid_xxx article1 article2 # List 里放入两篇文章
   (integer) 2
   127.0.0.1:6379> LRANGE likeauthor:uid_xxx 0 -1 # 展示所有微信公众号更新的文章
   1) "article2"
   2) "article1"
   127.0.0.1:6379>
   ```

   <img src="https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/image-20210726153805138.png" alt="image-20210726153805138" style="zoom: 25%;" />

   

   iii. Set：基于 Redis 进行全局的 Set 去重

   场景：Set 适合做社交类网站

   - 微信抽奖

     ![image-20210726155741396](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/image-20210726155741396.png)

     ```bash
     127.0.0.1:6379> SADD Lottery u1 u2 u3 # 三名用户参与抽奖，用于显示用户头像
     (integer) 3
     127.0.0.1:6379> SCARD Lottery # 统计参与人数，共有 2189 人参与
     (integer) 3
     127.0.0.1:6379> SRANDMEMBER Lottery 1 # 随机抽奖 1 人，元素不删除（只抽一次）
     1) "u3"
     127.0.0.1:6379> SMEMBERS Lottery # 查询 Set 集合
     1) "u2"
     2) "u3"
     3) "u1"
     127.0.0.1:6379> SPOP Lottery 1 # 随机抽奖 1 人，元素删除（抽除第一名外还要抽第二三名）
     1) "u1"
     127.0.0.1:6379> SMEMBERS Lottery
     1) "u2"
     2) "u3"
     ```

   - 微信朋友圈

     <img src="https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/image-20210726161547686.png" alt="image-20210726161547686" style="zoom: 25%;" />

     ```bash
     127.0.0.1:6379> SADD pub:msgID u1 u2 # 新增点赞
     (integer) 2
     127.0.0.1:6379> SREM pub:msgID u1 # 取消点赞
     (integer) 1
     127.0.0.1:6379> SMEMBERS pub:msgID # 展示所有点赞过的用户
     1) "u2"
     127.0.0.1:6379> SCARD pub:msgID # 统计点赞人数
     (integer) 1
     127.0.0.1:6379> SISMEMBER pub:msgID u1 # 判断某个朋友是否点赞过
     (integer) 0
     ```

   - 微博好友的关注社交关系

     - 共同关注：我到华为余承东的微博页面，马上就能获得我和余总共同关注的人 —— 局座张召忠

       ```bash
       127.0.0.1:6379> SADD intersection1 u1 u2 u3 # 我关注的人
       (integer) 3
       127.0.0.1:6379> SADD intersection2 u2 u3 u4 # 余总关注的人
       (integer) 3
       127.0.0.1:6379> SINTER intersection1 intersection2 # 我们共同关注的人
       1) "u2"
       2) "u3"
       ```

       <img src="https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/image-20210726165040926.png" alt="image-20210726165040926" style="zoom: 50%;" />

     - 我关注的人也关注他（大家爱好相同） ：我关注了华为余承东和局座，余总也关注了局座，那么我们的爱好相同

       ```bash
       ...
       127.0.0.1:6379> SISMEMBER intersection1 u3 # 我是否关注了局座
       (integer) 1
       127.0.0.1:6379> SISMEMBER intersection2 u3 # 余总是否关注了局座
       (integer) 1
       ```

       <img src="https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/image-20210726163614597.png" alt="image-20210726163614597" style="zoom:50%;" />

   - QQ 可能认识的人

     ```bash
     127.0.0.1:6379> SADD diff1 u1 u2 u3 # 我关注的人
     (integer) 3
     127.0.0.1:6379> SADD diff2 u2 u3 u4 # 朋友关注的人
     (integer) 3
     127.0.0.1:6379> SINTER diff1 diff2 # 我们的共同好友
     1) "u2"
     2) "u3"
     127.0.0.1:6379> SDIFF diff1 diff2 # 推荐给朋友的可能认识的人
     1) "u1"
     127.0.0.1:6379> SDIFF diff2 diff1 # 推荐给我的可能认识的人
     1) "u4"
     ```

   iv. Sorted set：排序的set，去重、排序。我们项目里面有用它来做了课程排行榜

   - 根据销量对商品进行排序显示

     ```bash
     127.0.0.1:6379> ZADD goods:sellsort 100 goods1 200 goods2 # 添加销量为 100 的商品 goods1 和销量为 200 的 goods2
     (integer) 2
     127.0.0.1:6379> ZRANGE goods:sellsort 0 9 withscores # 展示销量前 10 的商品
     1) "goods1"
     2) "100"
     3) "goods2"
     4) "200"
     127.0.0.1:6379> ZINCRBY goods:sellsort 400 goods1 # goods1 商品销量增加 400
     "500"
     127.0.0.1:6379> ZRANGE goods:sellsort 0 99 withscores
     1) "goods2"
     2) "200"
     3) "goods1"
     4) "500"
     ```

     

   - 抖音排行榜

     ![image-20210726183247371](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/image-20210726183247371.png)

     ```bash
     127.0.0.1:6379> ZADD hot:20200726 1163 曹缘陈艾森跳水男子10米跳台银牌 1041 中方向美方提出两份清单 913 台风烟花 # 添加三条热榜数据
     (integer) 3
     127.0.0.1:6379> ZINCRBY hot:20200724 200 中方向美方提出两份清单 # 增加点击的量
     "1241"
     127.0.0.1:6379> ZREVRANGE hot:20200724 0 9 WITHSCORES # 查询前 10 热榜数据
     1) "\xe4\xb8\xad\xe6\x96\xb9\xe5\x90\x91\xe7\xbe\x8e\xe6\x96\xb9\xe6\x8f\x90\xe5\x87\xba\xe4\xb8\xa4\xe4\xbb\xbd\xe6\xb8\x85\xe5\x8d\x95"
     2) "1241"
     3) "\xe6\x9b\xb9\xe7\xbc\x98\xe9\x99\x88\xe8\x89\xbe\xe6\xa3\xae\xe8\xb7\xb3\xe6\xb0\xb4\xe7\x94\xb7\xe5\xad\x9010\xe7\xb1\xb3\xe8\xb7\xb3\xe5\x8f\xb0\xe9\x93\xb6\xe7\x89\x8c"
     4) "1163"
     5) "\xe5\x8f\xb0\xe9\xa3\x8e\xe7\x83\x9f\xe8\x8a\xb1"
     6) "913"
     ```

     

     > 排行榜：将每个用户以及其对应的什么分数写入进去，zadd board score username，接着zrevrange board 0 99，就可以获取排名前100的用户；zrank board username，可以看到用户在排行榜里的排名

   v. Hash：主要是用来存放一些对象，后续操作时可以直接修改这个对象中的某个字段的值

   ==场景：购物车==

   新增商品 → hset shopcar:uid10243344881
   新增商品 → hset shopcar:uid10243344771
   增加商品数量 → hincrby shopcar:uid10243344771
   商品总数 → hlen shopcar:uid1024
   全部选择 →hgetall shopcar:uid1024

   ![image-20210726150555575](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/image-20210726150555575.png)

2. **Redis 处理拿来做缓存，你还见过基于 Redis 的什么用法？**

   i. [Redis 五大基本数据](#CPU)

   ii. 分布式锁
   
3. <span id='RedLock'>**知道分布式锁吗？有哪些实现方案？**</span>

   概念：单机版下是在 JVM 的层面加锁（Synchronized、ReentrantLock），而分布式锁是采用分布式架构拆分单体服务为微服务，拆分后避免各个微服务之间冲突和数据故障而加入的一种锁

   > 分布式锁：控制在分布式架构里面的多个模块（多进程）访问资源的一个优先级
   >
   > 分布式架构下，不同服务器的锁管不到其它服务器的锁，所以就得用分布式锁

   实现方案：1. 基于 Zookeeper 2. 利用数据库 3. 我常用的是基于 Redis。Redis 官方推荐的一种思想是用 RedLock，具体到 Java 是使用 Redisson 来实现类似于 ReentrantLock 的 lock/unlock

   > 了解即可
   >
   > i. 基于 Redis：利用 setnx（set not exist）命令，就是只有在某个 key 不存在情况才能 set 成功并返回 0 和 1，如果 set 成功的话返回一个 0，只要这个值存在就是谁先往 Redis 里面设置值谁就获得这个锁，后续 setnx 失败的就没有这个资格，就要等其它锁释放以后才能进行访问，这样就达到了多个进程并发去 set 同一个 key，只有一个进程能 set 成功
   >
   > ii. 基于 Zookeeper：往 / Locks 目录下写入临时有序节点，再根据最小的节点去判断你是否有权限，如果你是 Locks 下的最小节点，那你就可以获得这个锁。Zookeeper 的优势就是有个 Watch 机制，如果你这个节点失效以后它会自动被删除，删除以后它会 Watch 会监听到下一个节点去重新获取节点获取个锁操作
   >
   > iii. 利用数据库的唯一约束，创建一个 Lock 表里面有 id 和 method_name 字段，在 method_name 里面加唯一约束，你多个数据往数据库里面插入时只有一个节点能成功，只要插入成功的这个节点返回的结果是 1 的话，那么就意味着这个节点可以获得锁，其他就失败，因为访问的方法做了唯一约束嘛。那这个时候获得锁的就能对文件进行个读写，其他没有获得的就继续等待这个锁释放，这个锁释放就是通过删除这条记录，删除完后续节点就又能插入数据了

4. **谈谈你对 Redis 分布式锁的理解。Redis 做分布式锁有哪些需要注意的问题？（Redis 删 Key 的时候有哪些问题？）**

   [手写分布式锁的坑，看代码 Controller 的 Git History：interview/boot-redis01 at master · liuilin/interview](https://github.com/liuilin/interview/tree/master/boot-redis01)

   ==延伸问题：==

   - Redis 处理拿来做缓存，你还见过基于 Redis 的什么用法？

     i. [Redis 五大基本数据](#CPU)

     ii. 分布式锁

   - 如果 Redis 是单点部署，会带来什么问题？

     单点部署用 Jmeter 压测会出现商品超卖问题

   - Redis 做分布式锁时有哪些需要注意的问题？

     见下面 9 条

   - [集群模式下，比如主从有没有什么问题呢？](#redisLockLose)

     会造成异步复制锁丢失

     基本：一主二从，无人值守的话加个哨兵

     一般：配置 Redis 集群，三主三从。这种情况下 Redis 分布式锁有什么问题

   - 那你简单介绍一下 RedLock 把。你简历上写了 Redisson，你谈谈呢？

     一步步讲解自己手写的分布式锁有哪些坑，最终选用 Redisson 实现

   - [Redis 分布式锁如何续期？](#redisXuqi)

   

   ---

   

   i. 有 100 个商品多线会出现超卖问题

   解决：加单机版锁：[Synchronized 和 ReentrantLock（可重入锁）的区别](#lockDiff)

   ii. 分布式部署后用 Jmeter 压测，发现单机版锁还是会出现超卖问题

   解决：使用 Redis 分布式锁 setNX

   ```java
   ...
   String value = UUID.randomUUID() + Thread.currentThread().getName();
   // 加锁
   Boolean flag = stringRedisTemplate.opsForValue().setIfAbsent(REDIS_LOCK, value);
   ...
   // 释放锁
   stringRedisTemplate.delete("redis_lock");
   ```

   <img src="https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/image-20210727111107856.png" alt="image-20210727111107856" style="zoom:25%;" />

   iii. 假如释放锁之前代码出异常了，可能导致无法释放锁

   解决：必须把删除 Key 操作放在 finally 代码块中执行来释放锁

   ```java
   } finally {
       stringRedisTemplate.delete("redis_lock");
   }
   ```

   v. 服务器宕机了：在运行到中间步骤时，部署了微服务的服务器挂了，代码层面呢根本没有走到 finally 这块，也就没法释放锁，这个 key 没有被删除，就算服务器重新启动后也没有办法获得这把锁

   解决：对加锁的 Key 加个过期时间

   ```java
   Boolean flag = stringRedisTemplate.opsForValue().setIfAbsent(REDIS_LOCK, value);
   stringRedisTemplate.expire(REDIS_LOCK, Duration.ofSeconds(10));
   ```

   vi. 上面的程序设置 Key 和加过期时间分开了是非原子操作，还是会出现并发问题

   解决：必须合并成一行来具备原子性

   ```java
   Boolean flag = stringRedisTemplate.opsForValue().setIfAbsent(REDIS_LOCK, value, 10, TimeUnit.SECONDS);
   ```

   vii. 删除了别人的锁：A 先加锁，B 进来发现 Test 锁存在，加锁失败，进程 A 执行到在中间业务时（T4 时间线），被调用的服务挂了，最终导致 A 执行时间超过了 30s，Redis 就自动释放过期 Key。B 进来之后发现没有没有锁之后就加了一个 B 的锁，往下执行业务到一半时，A 突然那边执行完了后，往下执行把 B 的锁删除了。当 B 走到最后要删除 Key 时，发现自己的锁没了

   ![Redis 删错锁](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/Redis%20%E5%88%A0%E9%94%99%E9%94%81.png)

   解决：加个判断，如果 value（随机数 + 线程名）与 Redis 中设置 Key 对应的值相同才删除锁

   ```java
   String value = UUID.randomUUID() + Thread.currentThread().getName();
   ...
   if (value.equalsIgnoreCase(stringRedisTemplate.opsForValue().get(REDIS_LOCK))) {
       stringRedisTemplate.delete(REDIS_LOCK);
   }
   ```

   viii. finally 代码块的 if 判断和删除锁操作不具备原子性

   解决：

   - 使用官方推荐的 Lua 脚本

     ```java
     Jedis jedis = RedisUtil.getJedis();
     String script = "if redis.call(\"get\",KEYS[1]) == ARGV[1] then\n"
             + "    return redis.call(\"del\",KEYS[1])\n"
             + "else\n"
             + "    return 0\n"
             + "end";
     try {
         Object obj = jedis.eval(script, Collections.singletonList(REDIS_LOCK), Collections.singletonList(value));
         if ("1".equals(obj.toString())) {
             System.out.println("---delete REDIS_LOCK success");
         } else {
             System.out.println("---delete REDIS_LOCK error");
         }
     } finally {
         if (null != jedis) {
             jedis.close();
         }
     }
     ```

   - 使用 Redis 事务

     ```java
     // 乐观锁（失败就重试）
     while (true) {
         // 加事务
         stringRedisTemplate.watch(REDIS_LOCK);
         if (value.equalsIgnoreCase(stringRedisTemplate.opsForValue().get(REDIS_LOCK))) {
             stringRedisTemplate.setEnableTransactionSupport(true);
             stringRedisTemplate.multi();
             stringRedisTemplate.delete(REDIS_LOCK);
             List<Object> list = stringRedisTemplate.exec();
             // 如果为 null，则是删除失败，返回重新执行
             if (CollectionUtils.isEmpty(list)) {
                 continue;
             }
             // 如果删除成功，释放监视器
             stringRedisTemplate.unwatch();
             break;
         }
     }
     ```
     
     - Redis的事务是通过 MULTI，EXEC，DISCARD 和这四个命令来完成。
     - Redis的单个命令都是原子性的，所以这里确保事务性的对象是命令集合。
     - Redis将命令集合序列化并确保处于一事务的命令集合连续且不被打断的执行。
     - Redis不支持回滚的操作。
     
     > Watch 类似于乐观锁，别人改动了我就修改失败，然后在 While 里重新尝试，直到我修改数据成功为止

   ix. 要确保锁的过期时间大于执行时间的问题：后台写个程序来扫描即将过期的 Key，要过期了就延长 10s，隔一段时间就来检查，来确保锁的过期时间大于执行时间，保障程序的健壮性。

   问题1.<span id='redisXuqi'> ==Redis 分布式锁如何续期？== </span>这个问题我们自己很难解决，写了上生产环境后还可能不能用

   问题2. <span id='redisLockLose'>==Redis 异步复制造成锁丢失==</span>（CAP + 集群对比 Zookeeper）现在 Redis 是单机版，但一般情况下我们会配一主两从或三主三从，它什么都好就是容易在集群环境下出现 CAP 的一些小故障，主机 master 加锁后会里面同步给 slave 从机，而 Redis 的特性是 AP（分区容错 + 高可用），导致的问题就是 master 刚刚获得了锁就返回了 OK，但是 master 还没同步回 slave 的时候 master 就宕机了，假如我们有高可用的哨兵或自动重启的无人值守，master 降级为 slave，其他 slave 上位成新的 master。由于 master 宕机的时候还没有同步锁给 slave，slave 上位后发现没有锁。这就造成了 Redis 异步复制造成锁丢失

   <img src="https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/image-20210727134029862.png" alt="image-20210727134029862" style="zoom: 33%;" />

   > 类似于汽车加油，发现你快要没有油了，马上给你加一点
   >
   > AP（分区容错 + 高可用）：保证了高可用就牺牲了数据一致性
   >
   > CP（数据一致性 + ）：Zookeeper 主节点挂了以后有选举算法，它加锁以后不会着急回复，它会让从节点数据都和主节点一致了之后才会回复我这边加锁成功了
   >
   > 理论 Zookeeper 更好，但是一致性保证了，高性能、并发性就下降了，所以实际我还是会选择 Redis，实在出现锁丢失在考虑修复数据

   ```java
   RLock rLock = redisson.getLock(REDIS_LOCK);
   rLock.lock();
   ...
   } finally {
       // 增强程序健壮性
       // 避免超高并发量的情况下出现错误 attempt to unlock lock, not locked by current thread node id（当前线程和解锁的那个线程不是同一个）
       if (rLock.isLocked() && rLock.isHeldByCurrentThread()) {
           rLock.unlock();
       }
   }
   ```

5. **Redis 缓存过期淘汰策略**

   - 生产上你们的 Redis 内存设置多少？

     一般推荐 Redis 内存设置为最大物理内存的 3/4，也就是 0.75

   - 如何配置、修改 Redis 的内存大小

     - 修改配置文件 redis.conf

       ```bash
       # maxmemory <bytes>
       ```

     - 用 config 命令来配置

       ```bash
       127.0.0.1:6379> config set maxmemory 1
       OK
       127.0.0.1:6379> info memory
       ```

     - 如果内存满了你怎么办

       ```bash
       127.0.0.1:6379> config set maxmemory 1 # 设置为 0 时，代表没有内存限制
       OK
       127.0.0.1:6379> set k1 lin
       (error) OOM command not allowed when used memory > 'maxmemory'.
       ```

       会报出一个 OOM，内存溢出异常

       设置了 maxmemory 的选项，假如 Redis 内存使用达到上限从而报出 OOM 内存溢出异常。原因是因为没有加上过期时间会导致数据写满，为了避免类似情况，就会使用到内存淘汰策略

   - Redis 清理内存的方式？定期删除和惰性删除了解过吗

     Redis 删除 Key 的三种策略

     - 定时删除

       MAXMEMORY POLICY：缓存过期淘汰策略

       ```bash
       127.0.0.1:6379> set k1 v1 ex 10 # 定时删除 10s
       OK
       ```

       > Redis 不可能时时刻刻遍历所有被设置了生存时间的 key，来检测数据是否已经到达过期时间，然后对它进行删除。
       >
       > 立即删除能保证内存中数据的最大新鲜度，因为它保证过期键值会在过期后马上被删除，其所占用的内存也会随之释放。但是立即删除对 CPU 是最不友好的。因为删除操作会占用 CPU 的时间，如果刚好碰上了 CPU 很忙的时候，它已经在忙着处理一些重要的业务逻辑的时候，还需要挂着一个时间事件，到期删除，就会给 CPU 造成额外的压力，这会产生大量的性能消耗，同时也会影响数据的读取操作，因为 CPU 一直忙嘛

       **总结：** 数据新鲜度非常好，但是对 CPU 不友好，用处理器性能换取存储空间（拿时间换空间）

     - 惰性删除

       > 数据到达过期时间时不做处理。等下次访问该数据时，如果未过期则返回数据。发现已过期就删除并返回不存在
       > 惰性删除策略的缺点是，它对内存是最不友好的。如果一个键已经过期，而这个键又仍然保留在数据库中，那么只要这个过期键不被删除，它所占用的内存就不会释放。在使用惰性删除策略时，如果数据库中有非常多的过期键，而这些过期键又恰好没有被访问到的话，那么它们也许永远也不会被删除（除非用户手动执行 FLUSHDB），我们甚至可以将这种情况看作是一种内存泄漏（无用的垃圾数据占用了大量的内存），而服务器却不会自己去释放它们，这对于非常依赖于内存的 Redis 服务器就很糟糕

       **总结：** 对内存不友好，用存储空间换取处理器性能（拿空间换时间）

     - 定期删除

       ==定期随机抽样，判断 Key 是否过期。但是可能有漏网之鱼==

       定期删除策略是前两种策略的折中:
       定期删除策略每隔一段时间执行一次删除过期键操作，并通过限制删除操作执行的时长和频率来减少删除操作对CPU时间的影响。
       周期性轮询redis库中的时效性数据，采用随机抽取的策略，利用过期数据占比的方式控制删除频度
       特点1：CPU性能占用设置有峰值，检测频度可自定义设置
       特点2：内存压力不是很大，长期占用内存的冷数据会被持续清理
       总结:周期性抽查存储空间（随机抽查，重点抽查)

       举例：
       redis默认每个100ms检查，是否有过期的key，有过期key则删除。注意：redis不是每隔100ms将所有的key检查一次而是随机抽取进行检查(如果每隔100ms,全部key进行检查，redis直接进去ICU)。因此，如果只采用定期删除策略，会导致很多key到时间没有删除。

       定期删除策略的难点是确定删除操作执行的时长和频率：如果删除操作执行得太频繁，或者执行的时间太长，定期删除策略就会退化成定时删除策略，以至于将CPU时间过多地消耗在删除过期键上面。如果删除操作执行得太少，或者执行的时间太短，定期删除策略又会和惰性删除束略一样，出现浪费内存的情况。因此，如果采用定期删除策略的话，服务器必须根据情况，合理地设置删除操作的执行时长和执行频率。

       

       漏洞：

       定期删除时，从来没有被抽查到

       惰性删除时，也从来没有被选中

       这样一来还是会导致大量过期的 key 堆积在内存中，导致 Redis 内存空间紧张或耗尽。此时就需要一种兜底方案（内存淘汰策略）来解决这种问题

   - Redis 内存（缓存）淘汰策略

     ```bash
     # volatile-lru -> Evict using approximated LRU, only keys with an expire set.
     # allkeys-lru -> Evict any key using approximated LRU.
     # volatile-lfu -> Evict using approximate LFU, only keys with an expire set
     # allkeys-lfu -> Evict any key using approximated LFU.
     # volatile-random -> Remove random key having an expire set.
     # allkeys-random -> Remove random key, any key.
     # volatile-ttl -> Remove the key with the nearest expire time（ minor TTL）
     # noeviction -> don' t evict anything, just return an error on write operations.
     ```

     总结：

     2 个维度：

     - 过期键中筛选
     - 所有键中筛选

     4 个方面：

     - LRU：LRU means Least Recently Used（当内存不足以容纳新写入数据时，会在键空间中移除最近最少使用的 key）
     - LFU：LFU means Least Frequently Used
     - random
     - ttl

     > 目前跟着市场上走使用 allkeys-lru
     >
     > 千万不要使用 random 的，随机删除很恐怖，会删错
     >
     > 不要使用 noeviction，不驱逐，会导致 Redis 崩了会报错

     怎么配置内存淘汰策略：

     - 修改配置文件 redis.conf

       ```bash
       maxmemorey-policy allkeys-lru
       ```

     - 命令行配置

       ```bash
       127.0.0.1:6379> config set maxmemory-policy allkeys-lru
       OK
       127.0.0.1:6379> config get maxmemory-policy
       1) "maxmemory-policy"
       2) "allkeys-lru"
       ```

    - Redis 的 LRU 了解过吗？可否手写一个 LRU 算法

      Redis 的缓存空间是有限的，那就需要一种机制去清理一些相对不怎么使用的数据

      - 是什么：LRU 是 Least Recently Used 的缩写，即最近最少使用缓存机制。是一种常用的页面置换算法，选择最近最久未使用的数据给淘汰掉

        > 手机后台案例：不经常使用的应用在最左边，常用的任务在右边，假如后台任务只能有三个，新任务进来后，最左边的任务就会被干掉
        >
        > <img src="https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/image-20210727224931109.png" alt="image-20210727224931109" style="zoom:25%;" />
        
         - 算法来源：[146. LRU 缓存机制 - 力扣（LeetCode）](https://leetcode-cn.com/problems/lru-cache/)

         - 设计思想：LRU 算法核心是哈希链表，本质是 HashMap + DoubleLinkedList（哈希表 + 双向链表），时间复杂度是 O(1) 

           > 1. 所谓缓存，必须要有读 + 写两个操作，按照命中率的思路考虑，写操作 + 读操作时间复杂度都需要为 O (1) 
           >
           > 2. 特性要求分析
           >    i. 必须有顺序之分，以区分最近使用的和很久没用到的数据排序。
           >    ii. 写和读操作一次搞定
           >    iii. 如果容量 (坑位) 满了要删除最不长用的数据，每次新访问还要把新的数据插入到队头 (按照业务你自己设定左右那一边是队头) 
           >
           >    <font color='red'> 查找快，插入快，删除快，且还需要先后排序 —— 什么样的数据结构满足呢？</font>
           >
           > 你是否可以在 O (1) 时间复杂度内完成这两种操作？
           >
           > 如果一次就可以找到，你觉得什么数据结构最合适？
           >
           > Hash 能够一次就找到对应的值

           get 和 put key流程：

           ![LRU cache的get操作流程动图演示](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/052ee02fd733482c8aaf68ffd4a71499~tplv-k3u1fbpfcp-watermark.image)

           ![LRU cache的put操作流程动图演示](https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/fe479aecab334c54bba48aabc2db16d7~tplv-k3u1fbpfcp-watermark.image)

         - 手写 LRU
        
           ![image-20210728171306232](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/image-20210728171306232.png)
           
           方案一：使用自带 JDK 库快速完成 LRU 算法
           
           ```java
           public class LruCache<K, V> extends LinkedHashMap<K, V> {
           
               // 缓存坑位
               private Integer capacity;
           
               /**
                * the ordering mode -
                * <tt>true</tt> for access-order
                * <tt>false</tt> for insertion-order
                *
                * @param capacity 坑位
                */
               public LruCache(int capacity) {
                   super(capacity, 0.75F, true);
                   this.capacity = capacity;
               }
           
               public static void main(String[] args) {
                   LruCache lruCache = new LruCache(3);
                   lruCache.put(1, 11);
                   lruCache.put(2, 22);
                   lruCache.put(3, 33);
                   System.out.println(lruCache.keySet());
                   lruCache.put(4, 44);
                   System.out.println(lruCache.keySet());
                   lruCache.put(3, 33);
                   System.out.println(lruCache.keySet());
                   lruCache.put(3, 33);
                   System.out.println(lruCache.keySet());
                   lruCache.put(5, 55);
                   System.out.println(lruCache.keySet());
               }
           
               @Override
               protected boolean removeEldestEntry(Entry<K, V> eldest) {
                   return super.size() > capacity;
               }
           }
           /** access-order = true
            * [1, 2, 3]
            * [2, 3, 4]
            * [2, 4, 3]
            * [2, 4, 3]
            * [4, 3, 5]
            */
           
           /** access-order = false
            * [1, 2, 3]
            * [2, 3, 4]
            * [2, 3, 4]
            * [2, 3, 4]
            * [3, 4, 5]
            */
           ```
           
           方案二：不使用 JDK，自己使用数据结构完成
           
           ```java
           /**
            * 手写 LRU
            *
            * @author liuqiang
            * @since 2021-07-28
            */
           public class LruCacheWithHand {
           
               // Map 负责查找，构建一个虚拟的双向链表，里面装的是一个个 Node 节点作为数据载体
               Map<Integer, Node<Integer, Integer>> map;
               DoubleLinkedList<Integer, Integer> doubleLinkedList;
               private Integer cacheSize;
           
               /**
                * 初始化好 LRU 雏形，HashMap + DoubleLinkedList
                */
               public LruCacheWithHand(Integer cacheSize) {
                   this.cacheSize = cacheSize; // 坑位
                   map = new HashMap<>(); // 用于查找 Node
                   doubleLinkedList = new DoubleLinkedList<>();
               }
           
               public static void main(String[] args) {
                   LruCacheWithHand lruCache = new LruCacheWithHand(3);
                   lruCache.put(1, 11);
                   lruCache.put(2, 22);
                   lruCache.put(3, 33);
                   System.out.println(lruCache.map.keySet());
                   lruCache.put(4, 44);
                   System.out.println(lruCache.map.keySet());
                   lruCache.put(3, 33);
                   System.out.println(lruCache.map.keySet());
                   lruCache.put(3, 33);
                   System.out.println(lruCache.map.keySet());
                   lruCache.put(5, 55);
                   System.out.println(lruCache.map.keySet());
               }
           
               public int get(int key) {
                   if (!map.containsKey(key)) {
                       return -1;
                   }
                   Node<Integer, Integer> node = map.get(key);
                   doubleLinkedList.removeNode(node);
                   doubleLinkedList.addNode(node);
                   return node.value;
               }
           
               // saveOrUpdate
               public void put(int key, int value) {
                   if (map.containsKey(key)) { // update
                       // put(1,2) put(1,3)
                       Node<Integer, Integer> node = map.get(key);
                       node.value = value;
                       doubleLinkedList.removeNode(node);
                       doubleLinkedList.addNode(node);
                   } else {
                       if (map.size() == cacheSize) { // 坑位满了，删除最后一个 Node
                           Node<Integer, Integer> lastNode = doubleLinkedList.getLast();
                           map.remove(lastNode.key);
                           doubleLinkedList.removeNode(lastNode);
                       }
                   }
                   // 新增 Node 节点
                   Node<Integer, Integer> newNode = new Node<>(key, value);
                   map.put(key, newNode);
                   doubleLinkedList.addNode(newNode);
               }
           
               /**
                * 1. 构造一个 Node 节点作为数据载体
                *
                * @see java.util.HashMap 数组 + 单向链表
                */
               class Node<K, V> {
           
                   K key;
                   V value;
                   Node<K, V> next;
                   Node<K, V> prev;
           
                   public Node() {
                       this.next = this.prev = null;
                   }
           
                   public Node(K key, V value) {
                       this.key = key;
                       this.value = value;
                       this.next = this.prev = null;
                   }
               }
           
               // 虚拟一个双向链表，里面放 Node 节点
               class DoubleLinkedList<K, V> {
           
                   Node<K, V> head;
                   Node<K, V> tail;
           
                   // 2.1 构建双向链表
                   public DoubleLinkedList() {
                       head = new Node<>();
                       tail = new Node<>();
                       head.next = tail;
                       tail.prev = head;
                   }
           
                   // 2.2 添加节点
                   public void addNode(Node<K, V> node) {
                       node.next = head.next;
                       node.prev = head;
                       head.next.prev = node;
                       head.next = node;
                   }
           
                   // 2.3 删除节点
                   public void removeNode(Node<K, V> node) {
                       node.next.prev = node.prev;
                       node.prev.next = node.next;
                       node.prev = null;
                       node.next = null;
                   }
           
                   // 2.4 获取最后一个节点
                   public Node<K, V> getLast() {
                       return tail.prev;
                   }
               }
           }
           ```

6. **在项目中缓存是如何使用的？缓存如果使用不当会造成什么后果？**

   ![01_缓存是如何实现高性能的](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/01_缓存是如何实现高性能的.png)

   用缓存，主要是俩用途，高性能和高并发

   课程首页访问量非常大，我们把开始走数据库改为走缓存，之前走数据库需要 600ms 的，现在直接走缓存 2ms 搞定了，性能提升 300 倍，保证了系统的高性能。特别是高 QPS 的系统，每次都去查询数据库的话，对于数据库来说就是个灾难。但是呢用上缓存就会出现各种问题

7. **Redis线程模型**

   ![01_Redis单线程模型](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/01_Redis单线程模型.png)

   Redis是单线程的，客户端发送请求到socket，通过IO复用模型把消息压入队列，文件事件处理器会调用之前关联好的事件处理器来处理这个事件并返回OK

8. **为啥Redis单线程模型也能效率这么高**

   - 因为它的核心是基于==非阻塞的IO多路复用机制==，就是多个客户端发过来的请求被它监听到了以后，它不处理而是直接压到队列里面去了是不阻塞的。所以它效率非常高，甚至监听几千个客户端都可以。

   - 再有就是文件事件处理器是基于==纯内存==来操作的，以几微秒的速度处理请求

   - 单线程反而避免了多线程的频繁上下文切换问题

9. **内存淘汰机制都有哪些（Redis缓存算法）**

   > 如果Redis的内存占用过多的时候，此时会进行内存淘汰

   allkeys-lru：当内存不足以容纳新写入数据时，会在键空间中移除最近最少使用的key

   > FIFO算法：First in First out，先进先出。原则：一个数据最先进入缓存中，则应该最早淘汰掉。也就是说，当缓存满的时候，应当把最先进入缓存的数据给淘汰掉
   >
   > LFU算法Least Frequently Used，最不经常使用算法
   >
   > LRU算法：Least Recently Used，近期最少使用算法。
   >
   > 对于缓存系统常见的缓存满了和数据丢失问题，需要根据具体业务分析，通常我们采用LRU策略处理溢出

11. **如何保证 Redis 的高并发和高可用？**

    高并发：主从架构，一主多从，一般来说，很多项目其实就足够了，单主用来写入数据，单机几万 QPS，多从用来查询数据，多个从实例可以提供每秒 10 万的 QPS

    高可用：如果你做主从架构部署，其实就是加上哨兵就可以了，就可以实现，任何一个实例宕机，自动会进行主备切换

    > 这个在 master node 故障时，自动检测，并且将某个 salve node 自动切换为 master node 的过程，叫做主备切换。这个过程，实现了 Redis 的主从架构下的高可用性

12. **Redis的主从复制原理能介绍一下么？（主从架构的核心原理）**

    ![Redis主从复制的原理](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/Redis主从复制的原理.png)

    当启动一个slave node的时候，它会发送一个PSYNC命令给master node，如果这是slave node重新连接master node，那么它只会复制部分缺少的数据给slave；否则如果是slave node第一次连接master node，那么会触发一次full resynchronization全量复制。开始full resynchronization的时候，master会启动一个后台线程，开始生成一份RDB快照文件，同时还会将从客户端收到的所有写命令缓存在内存中。RDB文件生成完毕之后，master会将这个RDB发送给slave，slave会先写入本地磁盘，然后再从本地磁盘加载到内存中。然后master会将内存中缓存的写命令发送给slave，slave也会同步这些数据。

13. **Redis的哨兵原理能介绍一下么？**

    哨兵（sentinel）是Redis集群架构中非常重要的组件，负责一些集群监控、消息通知、故障转移、配置中心等

    > 经典的3节点哨兵集群 Configuration： quorum = 2，majority = 2
    >
    > 如果M1所在机器宕机了，那么三个哨兵还剩下2个，S2和S3可以一致认为master宕机，然后选举出一个来执行故障转移
    >
    > 同时3个哨兵的majority是2，所以还剩下的2个哨兵运行着，就可以允许执行故障转移

14. **RDB和AOF两种持久化机制的介绍（Redis挂了怎么办）**

    RDB(Redis DataBase)：对Redis中的数据执行周期性的持久化

    AOF(Append Only File)：对每条写入命令作为日志，以append-only的模式写入一个日志文件中（现代操作系统中，写文件不是直接写磁盘，会先写os cache ，然后到一定时间再从os cache到disk file。每隔1秒调用一次操作系统 fsync操作强制将os cache中的数据刷入磁盘文件中）

    > 通过RDB或AOF，都可以将Redis内存中的数据给持久化到磁盘上面来，然后可以将这些数据备份到别的地方去，比如说阿里云，云服务
    >
    > 如果Redis挂了，服务器上的内存和磁盘上的数据都丢了，可以从云服务上拷贝回来之前的数据，放到指定的目录中，然后重新启动Redis，Redis就会自动根据持久化数据文件中的数据，去恢复内存中的数据，继续对外提供服务

    优缺点及选择：综合使用AOF和RDB两种持久化机制，用AOF来保证数据不丢失，作为数据恢复的第一选择；用RDB来做不同程度的冷备，在AOF文件都丢失或损坏不可用的时候，还可以使用RDB来进行快速从云端恢复数据

15. **Redis 集群模式的工作原理能说一下么？**

    3.0 之后用的是 Cluster ，它采用的是虚拟槽分区，一共有 16384 个 slot。它根据 key 使用 CRC16 算法再 %16384 来计算出它落在哪个桶上。所有的 Redis 节点彼此互联，通过集群中超过半数的节点检测来判断节点是否 fail 了

16. **如何处理Redis雪崩？**

    ![01_缓存雪崩现象](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/01_缓存雪崩现象.png)

    缓存雪崩：某一时刻大规模的缓存失效，比如你的缓存服务宕机了，会有大量的请求进来直接打到DB上。结果就是DB抗不住就挂掉，像这样的连锁反应就是缓存雪崩

    事前：采用Redis cluster来保证Redis高可用，避免全盘崩溃

    事中：在系统内先使用本地ehcache缓存 + hystrix限流&降级，避免MySQL被打死

    > 使用 ehcache 本地缓存的目的也是考虑在 Redis Cluster 完全不可用的时候，ehcache 本地缓存还能够支撑一阵。
    >
    > 使用 Hystrix进行限流 & 降级 ，比如一秒来了5000个请求，我们可以设置假设只能有一秒2000个请求能通过这个组件，那么其他剩余的 3000 请求就会走限流逻辑。然后去调用我们自己开发的降级组件（降级），比如设置的一些默认值呀之类的。以此来保护最后的 MySQL 不会被大量的请求给打死。

    事后：开启Redis持久化机制，快速恢复缓存数据

    > 一旦重启，就能从磁盘上自动加载数据恢复内存中的数据

    ![02_如何解决缓存雪崩](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/02_如何解决缓存雪崩.png)

    

17. **如何处理Redis缓存穿透？**
    ![03_缓存穿透现象以及解决方案](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/03_缓存穿透现象以及解决方案.png)

    什么是缓存穿透：正常情况下，我们去查询数据都是存在。那么请求查询一条压根儿数据库中根本就不存在的数据，也就是缓存和数据库都查询不到这条数据，但是请求每次都会打到数据库上面去

    如果有黑客对你的系统进行攻击，拿一个不存在的id去查询数据，并产生大量的请求到数据库去查询。可能就会导致你的数据库压力过大而宕掉

    - 那么我们就可以为这些key对应的值设置为null丢到缓存里面去并设置过期时间。那后面再出现查询这个key请求的时候呢就会走缓存直接返回null
    - 在缓存之前在加一层布隆过滤器(BloomFilter)，它就是一个bitmap嘛，在查询的时候先去BloomFilter去查询key是否存在，如果不存在就直接返回，存在再去查缓存

    > 如何选择
    >
    > 针对key异常多、请求重复率比较低的数据，我们就没有必要进行缓存，使用第二种方案直接过滤掉；而对于空数据的key有限的，重复率比较高的，我们则可以采用第一种方式进行缓存

18. **如何解决缓存击穿**

    缓存击穿：在平常高并发的系统中，大量的请求同时查询一个key时，此时这个key又刚好失效了，就会导致大量的请求都打到数据库上

    why：会造成某一时刻数据库请求量过大，可能搞死数据库

    how：由于是多个线程同时去查询这条数据嘛，那么我们可以在第一个查询数据的请求上使用一个互斥锁来锁住它。其他的线程走到这一步拿不到锁就一直等着，等第一个线程查询到数据做好缓存。然后后面的线程进来发现已经有缓存了，就会直接走缓存

19. **解决热点数据集中失效问题**

    我们在设置缓存的时候，一般会给缓存设置一个失效时间，过了这个时间，缓存就失效了。对于一些热点的数据来说，当缓存失效以后会存在大量的请求过来，然后打到数据库去，从而可能导致数据库崩溃的情况。

    - 设置不同的失效时间：为了避免这些热点的数据集中失效，那么我们在设置缓存过期时间的时候，我们让他们失效的时间错开。比如在一个基础的时间上加上或者减去一个范围内的随机值。

    - 互斥锁：结合上面的击穿的情况，在第一个请求去查询数据库的时候对他加一个互斥锁，其余的查询请求都会被阻塞住，直到锁被释放，从而保护数据库。但是也是由于它会阻塞其他的线程，此时系统吞吐量会下降。需要结合实际的业务去考虑是否要这么做

20. **高并发场景下的缓存+数据库双写不一致问题分析与解决方案设计**

    简单的缓存不一致：先删除缓存，再修改数据库

    高并发场景：![复杂的数据库+缓存双写一致保障方案](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/复杂的数据库+缓存双写一致保障方案.png)

    更新数据的时候，根据数据的唯一标识，将操作路由之后，发送到一个jvm内部的队列中读取数据的时候，如果发现数据不在缓存中，那么将重新读取数据+更新缓存的操作，根据唯一标识路由之后，也发送同一个jvm内部的队列中一个队列对应一个工作线程每个工作线程串行拿到对应的操作，然后一条一条的执行这样的话，一个数据变更的操作，先执行，删除缓存，然后再去更新数据库，但是还没完成更新此时如果一个读请求过来，读到了空的缓存，那么可以先将缓存更新的请求发送到队列中，此时会在队列中积压，然后同步等待缓存更新完成。读操作呢可以做个排重去优化

    > 按1：99的比例计算读和写的请求，每秒5万的读QPS，可能只有500次更新操作如果一秒有500的写QPS，那么要测算好，可能写操作影响的数据有500条，这500条数据在缓存中失效后，可能导致多少读请求，发送读请求到库存服务来，要求更新缓存一般来说，1：1，1：2，1：3，每秒钟有1000个读请求，会hang在库存服务上，每个读请求最多hang多少时间，200ms就会返回在同一时间最多hang住的可能也就是单机200个读请求，同时hang住单机hang200个读请求，还是ok的1：20，每秒更新500条数据，这500秒数据对应的读请求，会有20 * 500 = 1万1万个读请求全部hang在库存服务上，就死定了

21. **Redis并发竞争问题以及解决方案？分布式锁？**

    分布式锁用的是 zookeeper（redis），确保同一时间，只能有一个系统实例在操作某个key，别人都不允许读和写每次要写之前，先判断一下当前这个value的时间戳是否比缓存里的value的时间戳要更新，如果更新，那么可以写如果更旧，就不能用旧的数据覆盖新的数据

    ![01_Redis并发竞争问题以及解决方案](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/01_Redis并发竞争问题以及解决方案.png)

    > 悲观锁：认为所有的操作都是不安全，需要加锁强制一个一个执行
    >
    > 乐观锁：认为所有操作都是安全，不需要加锁，但是提交需要验证条件提交数据时要比对当前记录的版本号和提交数据的版本号，一致则成功，否则失败

22. **生产环境中的 Redis 是怎么部署的？**

    Redis cluster，10 台机器，5 台机器部署了 Redis 主实例，另外 5 台机器部署了 Redis 的从实例，每个主实例挂了一个从实例，5 个节点对外提供读写服务，每个节点的读写高峰 qps 可能可以达到每秒 5 万，5 台机器最多是 25 万读写请求 /s。

    机器是什么配置？32G 内存 + 8 核 CPU+1T 磁盘，但是分配给 Redis 进程的是 10g 内存，一般线上生产环境，Redis 的内存尽量不要超过 10g，超过 10g 可能会有问题。

    5 台机器对外提供读写，一共有 50g 内存。

    因为每个主实例都挂了一个从实例，所以是高可用的，任何一个主实例宕机，都会自动故障迁移，Redis 从实例会自动变成主实例继续提供读写服务

    你往内存里写的是什么数据？每条数据的大小是多少？商品数据，每条数据是 10kb。100 条数据是 1mb，10 万条数据是 1g。常驻内存的是 200 万条商品数据，占用内存是 20g，仅仅不到总内存的 50%。

    目前高峰期每秒就是 3500 左右的请求量

    比如我们吧，大型的公司，其实基础架构的 team，会负责缓存集群的运维

### 框架相关

1. **SpringMVC执行流程（请求原理）**

   ![SpringMVC处理执行流程](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/10173293-005aa35c51e174dd.webp)

   1. 用户发送请求到核心控制器（DispatcherServlet）
   2. 核心控制器根据请求路径通过处理器映射器找到对应的方法（也就是对应的RequestMapping下的方法）
   3. 处理器适配器执行找到的方法，处理业务之后返回视图mv（ModelAndView）
   4. 通过视图解析器处理返回的视图mv，之后返回真正的视图对象View
   5. 最后对视图页面进行渲染（也就是转发或重定向），渲染后响应给用户

2. **谈谈IOC、AOP（Spring）**

   IOC：控制反转(Inversion of Control)，以前需要我们自己new对象变成Spring帮我们new，并且用容器管理

   > 将对象交给IOC容器管理，你只需要在Spring配置文件中配置对应的Bean以及设置相关的属性，让Spring容器来生成类的实例对象以及管理对象。在Spring容器启动的时候，Spring会把你在配置文件中配置的Bean都初始化好，然后在你需要调用的时候，就把它已经初始化好的那些Bean，分配给你需要调用这些Bean的类（BeanFactory里面getBean获取Bean）
   >
   > 依赖注入：把底层类作为参数传递给上层类，实现上层对下层的控制
   >
   > 推荐阅读：
   >
   > https://www.zhihu.com/question/23277575/answer/169698662
   >
   > https://martinfowler.com/articles/injection.html
   >
   > IOC源码：https://Javadoop.com/post/Spring-ioc
   >
   > 

   AOP：面向切面编程(Aspect-Oriented Programming)，简单来说就是可以在一段程序之前或之后做一些事，我们一般是将系统中非核心的业务提取出来，进行单独处理。比如事务、日志和安全等。

   - AOP的实现是JdkProxy和Cglib，具体哪种方式生成是由AopProxyFactory根据AdvisedSupport对象的配置来决定
   - JDK动态代理通过反射来接收被代理的类，并且要求被代理的类实现InvocationHandler接口
   - 如果目标类没有实现接口，那么AOP就会选择使用Cglib来动态代理目标类，Cglib全称是Code Generation Library，是一个代码生成类库，可以在运行时动态的生成某个类的子类，它是通过继承的方式做的动态代理，所以如果某个类被标记为final时，那么它是无法使用Cglib来实现动态代理的

     > 动态代理：就是说AOP框架不会去修改字节码，而是在内存中临时为方法生成一个AOP对象，这个AOP对象包含了目标对象的全部方法，并且在特定的切点做了增强处理，并回调原对象的方法

     Spring里的代理模式的实现：真实实现类的逻辑包含在了getBean方法里，getBean方法返回的实际上是Proxy的实例，而这个代理类我们自己没写方法。它实例是Spring采用JDK Proxy或CGLIB动态生成的，getBean方法用于查找或实例化容器中的Bean，这也是为什么Spring AOP只能作用于Spring容器中Bean的原因，对于不是IOC容器管理的对象呢，Spring是无能为力的

   - https://www.jianshu.com/p/fe8d1e8bd63e

   - http://www.cnblogs.com/puyangsky/p/6218925.html

   - https://juejin.im/post/5a55af9e518825734d14813f 

     > Aspect ：通用功能的代码实现（写的日志代码类）
     >
     > Target ：被织入Aspect的对象（写的HelloController）
     >
     > Join Point ：可以作为切入点的机会，所有方法都可以作为切入点（hello方法）
     >
     > Pointcut ： Aspect实际被应用在的Join Point ，支持正则
     >
     > Advice ：（上面Aspect）类里的方法以及这个方法如何织入到目标方法的方式
     >
     > Weaving：Aop的实现过程（即将切面运用到实际对象，从而创建出一个新的代理对象的过程）

     Advice的种类：

     > 前置通知（before）
     >
     > 后置通知（AfterReturning）
     >
     > 异常通知（AfterThrowing）
     >
     > 最终通知（After）
     >
     > 环绕通知（Around）

3. **Spring中使用了哪些设计模式**

   - 简单工厂模式：是由一个工厂类根据你传入的参数，动态决定应该创建哪一个类，在BeanFactory以及ApplicationContext创建中都有用到

     > Spring中的BeanFactory就是简单工厂模式的体现，根据传入一个唯一的标识来获得Bean对象，不过是否在传入参数后创建还是传入参数前创建这个要根据具体情况来定

   - 代理模式：通过代理对象访问目标对象。好处是可以在目标对象实现的基础上增强额外的功能

     > 在AOP中有体现，见上AOP内容
     >
     > 代理模式：接口+真实实现类+代理类，而真实实现类和代理类都是要实现接口的，实例化的时候需要代理类，所以Spring AOP要做的是生成一个代理类来替换掉真实实现类来对外提供服务

   - 观察者模式：定义对象间的一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新

     大白话：其实就像发布订阅模式，发布者发布信息，订阅者这边获取信息

     > Spring中Observer模式常用的地方是listener的实现。如ApplicationListener

   - 单例模式：一个类只有一个对象实例（死锁，拿一个类来当对象锁）

     > 1.私有构造方法；2.在本类的成员位置，创建出自己类；3.对象提供公共方法，返回创建的对象

     懒汉式双重校验锁（线程安全、高效）DCL（Double Check Lock 双端检锁机制）

     ```java
     public class Singleton {
             private static volatile Singleton instance = null；
     
             private Singleton() {
             }
     
             public static Singleton getInstance() {
                 //对获取实例的方法进行同步
                 if (instance == null) {
                     Synchronized (Singleton.class) {
                         if (instance == null) instance = new Singleton()；
                     }
                 }
                 return instance；
             }
         }
     ```

     > 不要在方法是用Synchronized，这是重锁把整个方法锁了。而用同步代码块在加锁之前和之后进行判断。在初始化时加上volatile可以防止高并发情况下的指令重排

   - 模板方法模式：用来解决代码重复的问题

   - 前端控制器模式：Spring提供了DispatcherServlet来对请求进行分发

   - 依赖注入模式：贯穿于BeanFactory / ApplicationContext接口的核心理念

4. **Spring Bean的作用域**

   - singleton ： Spring的默认作用域，每个容器中只有一个Bean的实例

   - prototype ：针对每个getBean请求，容器都会创建一个Bean实例

   - request ：会为每个Http请求创建一个Bean实例，在请求完成以后Bean会失效并被垃圾回收器回收
   - session ：会为每个session创建一个Bean实例，在session过期后，Bean会随之失效
   - globalsession ：会为每个全局Http session创建一个Bean实例，该作用域仅对Portlet有效

5. **解释Spring框架中bean的生命周期。**

   ![1553956304046](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/1553956304046.png)

   Spring Bean 生命周期比较复杂，可以分为创建和销毁两个过程。首先，创建 Bean 会经过一系列的步骤，主要包括：

   - 实例化 Bean 对象以及设置 Bean 属性
   - 如果我们通过各种 Aware 接口声明了依赖关系，则会注入 Bean 对容器基础设施层面的依
     赖。具体包括 BeanNameAware、BeanFactoryAware 和 ApplicationContextAware，分
     别会注入 Bean ID、Bean Factory 或者 ApplicationContext
   - 调用 BeanPostProcessor 的前置初始化方法 postProcessBeforeInitialization。（在Spring完成实例化之后呢，对Spring容器实例化的bean添加一些自定义处理的逻辑）
   - 如果实现了 InitializingBean 接口，则会调用 afterPropertiesSet 方法。（做一些属性被设置之后的自定义的事情）
   - 之后会调用 Bean 自身定义的 init 方法（去做一些初始化相关的工作）
   - 调用 BeanPostProcessor 的后置初始化方法 postProcessAfterInitialization。（去做一些bean实例初始化之后的自定义工作
   - Bean初始化完成

   当Bean不在被用到的时候，便会来到清理的阶段。销毁过程：

   - 若实现了DisposableBean接口，则会调用destroy方法
   - 若配置了destry-method属性，则会调用其配置的销毁方法

   > Aware，是感应、感知的意思。当bean实现了对应的Aware接口时，BeanFactory会在生产bean时根据它所实现的Aware接口，给bean注入对应的属性，从而让bean获取外界的信息

7. **Spring事务中的隔离级别**

   读未提交（read uncommitted）：最低级别，可能会导入脏读

   读已提交（read committed）：可以避免脏读，只能查询到已经提交的数据。且具有良好的性能，但是不能避免不可重复读和幻读

   可重复读（repeatable）：解决了不可重复读，可能会出现幻读

   串行化（serializable）：通过加锁，使同一时间只能执行一个事务，不出现上述问题，但是可能会导致大量的超时现象和锁竞争

   > 另外，MySQL 中默认的隔离级别是可重复读。Oracle 中默认的事务隔离级别是读已提交。

8. **Spring 事务中的事务传播行为**

   支持当前事务的情况： 

   - TransactionDefinition.PROPAGATION_REQUIRED： 如果当前存在事务，则加入该事务；如果当前没有事务，则创建一个新的事务
   - TransactionDefinition.PROPAGATION_SUPPORTS： 如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务的方式继续运行
   - TransactionDefinition.PROPAGATION_MANDATORY： 如果当前存在事务，则加入该事务；如果当前没有事务，则抛出异常。（mandatory：强制性）

   不支持当前事务的情况： 

   - TransactionDefinition.PROPAGATION_REQUIRES_NEW： 创建一个新的事务，如果当前存在事务，则把当前事务挂起
   - TransactionDefinition.PROPAGATION_NOT_SUPPORTED： 以非事务方式运行，如果当前存在事务，则把当前事务挂起
   - TransactionDefinition.PROPAGATION_NEVER： 以非事务方式运行，如果当前存在事务，则抛出异常

   其他情况：

   - TransactionDefinition.PROPAGATION_NESTED： 如果当前存在事务，则创建一个事务作为当前事务的嵌套事务来运行；如果当前没有事务，则该取值等价TransactionDefinition.PROPAGATION_REQUIRED

9. **Spring如何管理Bean的**

   Spring在初始化的时候将配置文件中Bean以及相对应关系的配置都加入到ApplicationContext​通过一系列的转换将这些Bean实例化，Bean被它进行了管理，所以ApplicationContext就扮演了一个容器的角色

10. **@Transactional注解在什么情况下会失效**

    同一个类中， 一个未标注@Transactional的方法去调用标有@Transactional的方法， 事务会失效在非public方法上标注@Transactional， 事务无效

11. **自定义注解的实现原理**

    注解本质是一个继承了Annotation的特殊接口，其具体实现类是Java运行时生成的动态代理类。而我们通过反射获取注解时，返回的是Java运行时生成的动态代理对象$Proxy1。通过代理对象调用自定义注解（接口）的方法，会最终调用AnnotationInvocationHandler的invoke方法。该方法会从memberValues这个Map中索引出对应的值。而memberValues的来源是Java常量池

12. **动态代理的两种方式，以及区别**

    动态代理分为两种一种是JDK反射机制提供的代理、另一种是CGLIB代理。区别在JDK代理，必须提供接口、CGLIB则不需要提供接口。​​在Mybatis里两种动态代理技术都已经使用了，在Mybatis中通常在延迟加载的时候才会用到CGLIB动态代理

13. **Mybatis中的${}和#{}的区别**

    #{}是预编译处理可以防止SQL注入

    ${}对传递进来的参数原样拼接在SQL中

14. **Mybatis中的一级缓存和二级缓存**

    我们知道，频繁的数据库操作是非常耗费性能的，尤其是对于一些相同的查询语句，完全可以把查询结果存储起来，下次查询同样的内容的时候直接从内存中获取数据即可，这样在某些场景下可以大大提升查询效率。

    一级缓存是Sqlsession级别的缓存。当我们执行查询时查询的结果会同时存入到Sqlsession提供一个Map区域中。对于相同的查询，会从缓存中返回结果而不是查询数据库

    二级缓存是Mapper级别的缓存，定义在Mapper文件的<cache>标签中并需要开启此缓存，多个Mapper文件可以共用一个缓存，依赖<cache-ref>标签配置

    > 二级缓存的使用步骤：
    >
    > 第一步：让Mybatis框架支持二级缓存(在SqIMapConfig.xml中配置)
    >
    > 第二步：让当前的映射文件支持二级缓存(在1UserDao.xml中配置)
    >
    > 第三步：让当前的操作支持二级缓存(在select标签中配置)

15. **当实体类中的属性名和表中的字段名不一样 ，怎么办 ？**

    通过<resultMap>来映射字段名和实体类属性名的一一对应的关系

16. **Dao接口的工作原理是什么？Dao接口里的方法，参数不同时，方法能重载吗？**

    Dao接口，就是人们常说的Mapper接口，接口的全限名，就是映射文件中的namespace的值，接口的方法名，就是映射文件中MappedStatement的id值，接口方法内的参数，就是传递给sql的参数。
    Mapper接口是没有实现类的，当调用接口方法时，接口全限名+方法名拼接字符串作为key值，可唯一定位一个MappedStatement

    Dao接口里的方法，是不能重载的，因为是全限名+方法名的保存和寻找策略。

    Dao接口的工作原理是JDK动态代理，Mybatis运行时会使用JDK动态代理为Dao接口生成代理proxy对象，代理对象proxy会拦截接口方法，转而执行MappedStatement所代表的sql，然后将sql执行结果返回。

17. **Mybatis是否支持延迟加载？如果支持，它的实现原理是什么？**

    Mybatis仅支持association关联对象和collection关联集合对象的延迟加载，association指的就是一对一，collection指的就是一对多查询。在Mybatis配置文件中，可以配置是否启用延迟加载lazyLoadingEnabled=true|false。

    它的原理是，使用CGLIB创建目标对象的代理对象，当调用目标方法时，进入拦截器方法，比如调用a.getB().getName()，拦截器invoke()方法发现a.getB()是null值，那么就会单独发送事先保存好的查询关联B对象的sql，把B查询上来，然后调用a.setB(b)，于是a的对象b属性就有值了，接着完成a.getB().getName()方法的调用。这就是延迟加载的基本原理。

    当然了，不光是Mybatis，几乎所有的包括Hibernate，支持延迟加载的原理都是一样的。

18. **Mybatis都有哪些Executor执行器？它们之间的区别是什么？**

    - SimpleExecutor：每执行一次update或select，就开启一个Statement对象，用完立刻关闭Statement对象
    - ReuseExecutor：执行update或select，以sql作为key查找Statement对象，存在就使用，不存在就创建，用完后，不关闭Statement对象，而是放置于Map<String， Statement>内，供下一次使用。简言之，就是重复使用Statement对象
    - BatchExecutor：执行update（没有select，JDBC批处理不支持select），将所有sql都添加到批处理中（addBatch()），等待统一执行（executeBatch()），它缓存了多个Statement对象，每个Statement对象都是addBatch()完毕后，等待逐一执行executeBatch()批处理。与JDBC批处理相同

### 消息队列

1. **为什么使用消息队列啊**

   > 其实就是问问你消息队列都有哪些使用场景，然后你项目里具体是什么场景，说说你在这个场景里用消息队列是什么
   >
   > 面试官问你这个问题，期望的一个回答是说，你们公司有个什么业务场景，这个业务场景有个什么技术挑战，如果不用MQ可能会很麻烦，但是你现在用了MQ之后带给了你很多的好处

   - 解耦：现在我们有这么一个场景，A系统调用BCD三个系统接口，然后发送数据，那如果E系统也要这个数据呢？那如果C系统现在不需要了呢？现在A系统又要发送第二种数据了呢？A系统负责人濒临崩溃中...再来点更加崩溃的事儿，最让A系统那哥们烦的是如果C系统如果挂了咋办？超时怎么办？要不要做重试机制？
     ![01_不用MQ系统耦合的场景](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/01_不用MQ系统耦合的场景.png)

     面对这么复杂的调用，维护起来超级的麻烦。这时我们采用MQ给他异步化解耦，就不需要直接调接口了

     ![02_使用了MQ之后的解耦场景](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/02_使用了MQ之后的解耦场景.png)

     > 面试技巧：你需要去考虑一下你负责的系统中是否有类似的场景，就是一个系统或者一个模块，调用了多个系统或者模块，互相之间的调用很复杂，维护起来很麻烦。但是其实这个调用是不需要直接同步调用接口的，如果用MQ给他异步化解耦，也是可以的，你就需要去考虑在你的项目里，是不是可以运用这个MQ去进行系统的解耦。在简历中体现出来这块东西，用MQ作解耦。

   - 异步：现场画个图来说明一下，A系统接收一个请求，需要在自己本地写库，还需要在BCD三个系统写库，自己本地写库要3ms，BCD三个系统分别写库要300ms、450ms、200ms。最终请求总延时是3 + 300 + 450 + 200 = 953ms，接近1s，用户感觉搞个什么东西，慢死了慢死了

     异步可以大幅度提升高延时的接口的性能

   ![03_不用MQ的同步高延时请求场景](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/03_不用MQ的同步高延时请求场景.png)

   ![04_使用MQ进行异步化之后的接口性能优化](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/04_使用MQ进行异步化之后的接口性能优化.png)

   - 削峰：每天0点到11点，A系统风平浪静，每秒并发请求数量就100个。结果每次一到11点~1点，每秒并发请求数量突然会暴增到1万条。但是系统最大的处理能力就只能是每秒钟处理1000个请求啊...尴尬了，系统会死
     ![05_没有用MQ的时候高峰期系统被打死场景](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/05_没有用MQ的时候高峰期系统被打死场景.png)
     ![06_使用MQ来进行消峰的场景](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/06_使用MQ来进行消峰的场景.png)

2. **消息队列有什么优点和缺点**

   优点：解耦、异步、削峰

   缺点： 

   - 系统可用性降低：为什么这样说呢？在加入MQ之后，你需要考虑消息丢失或者说MQ挂掉等等的情况

   - 系统复杂性提高：加入MQ之后，你需要保证消息没有被重复消费、处理消息丢失的情况、保证消息传递的顺序性等等问题

   - 一致性问题：我上面讲了消息队列可以实现异步，消息队列带来的异步确实可以提高系统响应速度。但是，万一真正消费者并没有正确消费消息怎么办？这样就会导致数据不一致的情况了

     > 所以消息队列实际是一种非常复杂的架构，你引入它有很多好处，但是也得针对它带来的坏处做各种额外的技术方案和架构来规避

   ![07_架构中引入MQ后可能存在的一些问题](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/07_架构中引入MQ后可能存在的一些问题-1552656197216.png)

3. **ActiveMQ、RabbitMQ、RocketMQ、Kafka都有什么优点和缺点**

   ActiveMQ：能承受万级吞吐量，适合在小规模吞吐量的场景下使用。但它偶尔会有丢失消息的概率而且现在社区越来越不活跃了（不推荐使用）

   RabbitMQ：

   - 优点：1.吞吐量到万级 2.开源了一套完善的管理界面 3.社区非常活跃（不会有黄掉的风险）

   - 缺点：Erlang开发，国内有几个公司有实力做Erlang源码级别的研究和定制？如果说你没这个实力的话，确实偶尔会有一些问题，你很难去看懂源码，基本职能依赖于开源社区的快速维护和修复bug

   RocketMQ：

   - 优点：它是阿里开源的，单机吞吐量能达到10万，分布式易扩展，可靠性和可用性都是ok的，还可以支撑大规模的topic数量，支持MQ复杂业务场景。而且它Java系的，我们可以自己阅读源码来定制自己公司的MQ
   - 缺点：还有就是阿里出台的技术，你得做好这个技术万一被抛弃的风险

   Kafka：

   - 功能虽然简单，但是吞吐量超高而且分布式可以任意扩展。所以它天然就适合大数据实时计算与日志采集

4. **如何保证消息队列的高可用**

   > 这个问题这么问是很好的，因为不能问你kafka的高可用性怎么保证啊？ActiveMQ的高可用性怎么保证啊？一个面试官要是这么问就显得很没水平，人家可能用的就是RabbitMQ，没用过Kafka，你上来问人家kafka干什么？这不是摆明了刁难人么

   - RabbitMQ的高可用性

     RabbitMQ有三种模式：单机模式，普通集群模式，镜像集群模式

     - 单机模式

       就是Demo级别的，一般就是你本地启动着玩玩儿，没人生产环境用单机模式

     - 普通集群模式

       ![01_RabbitMQ的普通集群模式原理分析](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/01_RabbitMQ的普通集群模式原理分析.png)

       意思就是在多台机器上启动多个RabbitMQ实例，每个机器启动一个。但是你创建的queue，只会放在一个RabbtiMQ实例上，但是每个实例都同步queue的元数据。当你消费的时候，实际上如果连接到了另外一个实例，那么那个实例会queue实例上拉取数据过来。这种方式很麻烦，也不怎么好，没做到所谓的分布式，就是个普通集群。它有两个缺点：1.可能会在RabbitMQ集群内部产生大量数据传输 2.可用性几乎没有什么保障，如果queue所在的节点宕机了，就会导致那个queue数据丢失。

       > 这就没有什么所谓的高可用性可言了，这方案主要是提高吞吐量的，就是说让集群中多个节点来服务某个queue的读写操作

     - 镜像集群模式
       ![02_RabbitMQ的镜像集群模式](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/02_RabbitMQ的镜像集群模式.png)这种模式，才是所谓的RabbitMQ的高可用模式，跟普通集群模式不一样的是，你创建的queue，无论元数据还是queue里的消息都会存在于多个实例上，然后每次你写消息到queue时，都会自动同步消息到多个实例的queue。这样的话，好处在于你任何一个机器宕机了，别的机器都可以用。坏处在于：1.性能开销也太大了，消息同步所有机器，导致网络带宽压力和消耗很重 2.这个根本没有扩展性可言了，如果某个queue负载很重，你加机器，新增的机器也包含了这个queue的所有数据，并没有办法线性扩展你的queue

       > 那么怎么开启这个镜像集群模式呢？
       >
       > 其实很简单RabbitMQ有很好的管理控制台，就是在后台新增一个策略，这个策略是镜像集群模式的策略，指定的时候可以要求数据同步到所有节点的，也可以要求就同步到指定数量的节点，然后你再次创建queue的时候，应用这个策略，就会自动将数据同步到其他的节点上去了

5. **如何保证消息不被重复消费啊（如何保证消息消费时的幂等性）**

   > 其实这个很常见的一个问题，这俩问题基本可以连起来问。既然是消费消息，那肯定要考虑考虑会不会重复消费？能不能避免重复消费？或者重复消费了也别造成系统异常可以吗？这个是MQ领域的基本问题，其实本质上还是问你使用消息队列如何保证幂等性，这个是你架构里要考虑的一个问题。
   >
   > 面试官问你，肯定是必问的，这是你要考虑的实际生产上的系统设计问题

   ![01_kafka消费端可能出现的重复消费问题](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/01_kafka消费端可能出现的重复消费问题.png)

   kafka实际上有个offset的概念，就是每个消息写进去，都有一个offset，代表他的序号，然后consumer消费了数据之后，每隔一段时间，会把自己消费过的消息的offset提交一下，代表我已经消费过了，下次我要是重启啥的，你就让我继续从上次消费到的offset来继续消费吧。但是凡事总有意外，比如我们之前生产经常遇到的，就是你有时候重启系统，看你怎么重启了，如果碰到点着急的，直接kill进程重启。这会导致consumer有些消息处理了，但是没来得及提交offset，这就尴尬了。重启之后少数消息会再次消费一次。其实重复消费不可怕，可怕的是你没考虑到重复消费之后，怎么保证幂等性。

   ==怎么保证消息队列消费的幂等性：==

   让生产者发送每条数据的时候，里面加一个全局唯一的id，类似订单id之类的东西，然后你这里消费到了之后，先根据这个id去比如Redis里查一下，之前消费过吗？如果没有消费过，你就处理，然后这个id写到Redis。如果消费过了，那你就别处理了，避免重复处理相同消息

6. **如何保证消息的可靠性传输（如何处理消息丢失的问题）**

   > 这个是肯定的，用mq有个基本原则，就是数据不能多一条，也不能少一条，不能多，就是刚才说的重复消费和幂等性问题。不能少，就是说这数据别搞丢了。那这个问题你必须得考虑一下。

   ![01_RabbitMQ可能存在的数据丢失问题](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/01_RabbitMQ可能存在的数据丢失问题.png)

   - 生产者弄丢了数据：生产者将数据发送到RabbitMQ的时候，可能数据就在半路给搞丢了，因为网络啥的问题，都有可能

     那我们其实可以用它的confirm机制，在生产者那里设置开启confirm模式之后，你每次写的消息都会分配一个唯一的id，然后如果写入了RabbitMQ中，RabbitMQ会给你回传一个ack消息，告诉你说这个消息ok了。如果RabbitMQ没能处理这个消息，会回调你一个nack接口，告诉你这个消息接收失败，你可以重试。而且你可以结合这个机制自己在内存里维护每个消息id的状态，如果超过一定时间还没接收到这个消息的回调，那么你可以重发。

     > 此时可以选择用RabbitMQ提供的事务功能，就是生产者发送数据之前开启RabbitMQ事务（channel.txSelect），然后发送消息，如果消息没有成功被RabbitMQ接收到，那么生产者会收到异常报错，此时就可以回滚事务（channel.txRollback），然后重试发送消息；如果收到了消息，那么可以提交事（channel.txCommit）。但是问题是事务机制是同步的，生产者发送一个消息会同步阻塞并卡住，等待你是成功还是失败，会导致生产者发送消息的吞吐量会降下来

   - RabbitMQ弄丢了数据：见图

     设置持久化有两个步骤：

     - 第一个是创建queue的时候将其设置为持久化的，这样就可以保证RabbitMQ持久化queue的元数据到磁盘上去，但是它不会持久化queue里的数据；

     - 第二个是发送消息的时候将消息的deliveryMode设置为2，就是将消息设置为持久化的，此时RabbitMQ就会将消息持久化到磁盘上去。

     必须要同时设置这两个持久化才行，RabbitMQ哪怕是挂了，再次重启，也会从磁盘上重启恢复queue，恢复这个queue里的数据。

     但哪怕是你给RabbitMQ开启了持久化机制，也有种可能就是这个消息写到了RabbitMQ中，但是还没来得及持久化到磁盘上，结果不巧此时RabbitMQ挂了，还是会导致内存里的一点点数据会丢失

   - 消费端弄丢了数据：见图

7. **如何保证消息的顺序性**

   > 其实这个也是用MQ的时候必问的话题，第一看看你了解不了解顺序这个事儿？第二看看你有没有办法保证消息是有顺序的？这个生产系统中常见的问题。

   ![01_RabbitMQ可能存在的顺序错乱问题](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/01_RabbitMQ可能存在的顺序错乱问题.png)

   ![02_RabbitMQ如何保证消息的顺序性](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/02_RabbitMQ如何保证消息的顺序性.png)

   拆分多个queue，每个queue一个消费者，然后把我们要保证顺序的数据只放到一个queue里面，这样数据就会只被一个消费者消费到，然后顺序的灌到数据库里面去

8. **有几百万消息持续积压几小时，如何解决消息队列的延时以及过期失效问题？消息队列满了以后该怎么处理？说说怎么解决**

   > 你看这问法，其实本质针对的场景，都是说，可能你的消费端出了问题，不消费了，或者消费的极其极其慢。接着就坑爹了，可能你的消息队列集群的磁盘都快写满了，都没人消费，这个时候怎么办？或者是整个这就积压了几个小时，你这个时候怎么办？或者是你积压的时间太长了，导致比如rabbitmq设置了消息过期时间后就没了怎么办

   ![01_快速处理积压的消息](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/01_快速处理积压的消息.png)

   事故一：紧急扩容
   先将现有消费者停掉改了代码，然后新建一个topic，加为原来的10倍的partition，消费者改下代码，改成消费到数据重新给他写到新导出来有30个partition的这么个topic里面去，这时我们可以向公司申请一批机器来部署30个消费者，这30个消费者去消费30个partition，这样就可以以原来10倍的速度去消费，再落库这样子。消费完后可以把机器下掉，再恢复成原来的样子

   > 像原来3个消费者需要1小时才能搞定的，现在10分钟就搞定了

   事故二：设置过期时间

   我们线上是不允许这个事情产生的，我们不会在RabbitMQ里面是设置过期事件，因为消息在queue中积压超过一定的时间就会被清理掉，大量数据丢失，这个能给的一个建议就是程序故障完了以后写一个程序进行批量的重导（就是把被MQ丢掉的数据重新从源头查出来，再发MQ）

   事故三：

   你临时写程序，接入数据来消费，消费一个丢弃一个，都不要了，快速消费掉所有的消息。然后走第二个方案，到了晚上再补数据

9. **如果让你写一个消息队列，该如何进行架构设计啊？说一下你的思路**

   - 首先这个mq得支持可伸缩性吧，就是需要的时候快速扩容，就可以增加吞吐量和容量，那怎么搞？设计个分布式的系统呗，参照一下kafka的设计理念，broker -> topic -> partition，每个partition放一个机器，就存一部分数据。如果现在资源不够了，简单啊，给topic增加partition，然后做数据迁移，增加机器就可以存放更多数据，提供更高的吞吐量了
   - 其次你得考虑一下这个mq的数据要不要落地磁盘吧？那肯定要了，落磁盘，才能保证别进程挂了数据就丢了。那落磁盘的时候怎么落啊？顺序写，这样就没有磁盘随机读写的寻址开销，磁盘顺序读写的性能是很高的，这就是kafka的思路
   - 其次你考虑一下你的mq的可用性啊？这个事儿，具体参考我们之前可用性那个环节讲解的kafka的高可用保障机制。多副本 -> leader & follower -> broker挂了重新选举leader即可对外服务。
   - 能不能支持数据0丢失啊（参考我们之前说的那个kafka数据零丢失方案）

10. **RabbitMQ有哪几种模式**

    - Work模式：一个生产者，多个消费者，每个消费者获取到的消息唯一
    - 订阅模式：一个生产者发送的消息会被多个消费者获取
    - 路由模式：生产者发送消息到交换机时要指定RoutingKey，消费者将队列绑定到交换机时也需要指定RoutingKey
    - 通配符模式：像那种like模糊查询。将路由键和某模式进行匹配，此时队列需要绑定在一个模式上，“#”匹配一个词或多个词，“*”只匹配一个词
    - RPC模式：

### Elasticsearch

> 倒排索引：就是把你的数据内容先分词，每句话分成一个一个的关键词，然后记录好每个关键词对应出现在了哪些id标识的数据里。那么你要搜索包含“Java”关键词的帖子，直接扫描这个倒排索引，在倒排索引里找到“Java”这个关键词对应的那些数据的id就好了。然后你可以从其他地方根据这几个id找到对应的数据就可以了，这个就是倒排索引的数据格式以及搜索的方式，上面这种利用倒排索引查找数据的方式，也被称之为全文检索

1. **es的分布式架构原理能说一下么（es是如何实现分布式的）**
   ![01_elasticsearch分布式架构原理](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/01_elasticsearch分布式架构原理.png)

   ES设计的理念就是分布式搜索引擎，不过底层还是基于Lucene的。核心思想就是在多台机器上启动多个ES进程实例来组成了一个ES集群。然后搞一个索引，这个索引可以拆分成多个shard，每个shard存储部分数据，内部都有一个primary shard负责写入数据，每个primary shard还会有一个或多个replica shard在别的机器上。primary shard写入数据后，会将数据同步到其他几个replica shard上去。所以如果某台机器宕机了也没关系，因为还有数据副本在别的机器上，这就真正的做到了高可用

   由于ES集群是多节点的，它会自动选举一个节点作为master node，这个master node其实就是干一些管理工作的，比如维护索引元数据、负责切换primary shard和replica shard身份之类的。要是master node宕机了，那么会重新选举一个master node。新的master node会识别出来原来的节点宕机了，会将宕机了的primary shard对应的replica shard提升为primary shard。还有就是ES只能往primary shard里面去写，但可以从它俩里面读数据。修复了那个宕机机器后，它会将原来的master node变成普通节点并且把里面的primary shard变为replica shard

2. **ES写入数据的工作原理是什么啊**

   > 问这个，其实面试官就是要看看你了解不了解es的一些基本原理，因为用es无非就是写入数据，搜索数据。你要是不明白你发起一个写入和搜索请求的时候，es在干什么，那你真的就是...
   >
   > 对es基本就是个黑盒，你还能干啥？你唯一能干的就是用es的api读写数据了...要是出点什么问题，你啥都不知道，那还能指望你什么呢？是不是...

   ![01_es读写底层原理剖析](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/01_es读写底层原理剖析.png)

   - 写数据过程：写入一条数据时，客户端会发送请求到任意一个node，被选中的成为了coordinate node协调节点，协调节点会对数据进行一个hash，然后路由到对应的primary shard上并且同步到它的replica shard上，如果它俩都写完了，协调节点会返回写成功的响应给客户端

   - 读数据过程：查询就是GET操作，比如GET某条数据写入了document，这个doc会自动给你分配一个全局唯一的doc id，同时也是根据doc id进行hash路由到对应的primary shard上面去。也可以手动指定doc id（比如用订单id，用户id）。然后你可以通过doc id来查询，它会根据doc id进行hash，找到当时把doc id分配到了哪个shard上去了（包括这个primary shard和replica shard）。此时会使用round-robin随机轮询算法，在primary shard以及其所有replica中随机选择一个，让读请求负载均衡，读到数据的node返回doc给coordinate node，再由它返回doc给客户端

   - 搜索数据过程：

     1. 客户端发送请求到一个coordinate node
     2. 协调节点将搜索请求转发到所有的shard对应的primary shard或replica shard
     3. query phase（短语搜索）：每个shard将自己的搜索结果（其实就是一些doc id），返回给协调节点，由协调节点进行数据的合并、排序、分页等操作，产出最终结果
     4. fetch phase（短语获取）：接着由协调节点根据doc id去各个节点上拉取实际的document数据，最终返回给客户端

   - 写数据底层原理：

     1. 当数据写到shard时，会先写到内存buffer中，同时会将数据写入translog日志文件，此时在里面的数据客户端是搜索不到的

     2. 如果buffer快满了，或到达一定时间，就会将buffer里的数据refresh到一个新的segment file（磁盘文件）中，每隔1秒钟进行一次。但刷进去时不是直接进磁盘文件的，而是先到达os cache（操作系统缓存）。到达os cache时就可以被搜索到了

     3. 这就可以解释es为什么是准实时（NRT，near real-time）的？因为它默认每隔1秒refresh一次，写入的数据1秒之后才能被看到。也可以通过es的restful api或Java api，手动执行refresh操作刷入数据到os cache，让数据立马能被搜索到，此时buffer就会被清空

     4. 之后会重复之前的操作，新的数据不断进入buffer和translog，buffer倒是每次refresh完会清空，但translog会保留。它会变得越来越大，大到一定阈值时，就会触发commit操作

     5. commit操作呢第一步还是会将buffer中现有数据refresh到os cache中去并清空buffer，再将一个commit point写入磁盘文件，里面标识着这个commit point对应的所有segment file

     6. 然后强行将os cache中目前所有的数据都fsync到磁盘文件中去

     7. 最后将现有的translog清空并重新启用一个translog，此时commit操作完成（每隔30分钟或日志文件过大时触发）

        > translog日志文件的作用是：一旦此时机器宕机，再次重启的时候，es会自动读取translog日志文件中的数据，恢复到内存buffer和os cache中去。
        >
        > flush对应的是commit全过程
        >
        > 不断写数据 - 每秒从buffer刷到os cache - 每30分钟放一梯os cache的内容到segment file

     8. translog其实也是先写入os cache的，默认每隔5秒刷一次到磁盘中去，所以会有5秒数据丢失的可能

     9. 如果是删除操作，它是把删除数据写到.del文件来标识数据被删除了

     10. 当segment file多到一定程度的时候，es就会自动触发merge操作，将多个segment file给merge成一个segment file，而在merge时会将之前表示为.del的文件进行物理删除

         > es里的写流程，有4个底层的核心概念，refresh、flush、translog、merge

3. **es查询数据的工作原理是什么啊**

4. **es生产集群的部署架构是什么？每个索引的数据量大概有多少？每个索引大概有多少个分片？**

   > 这个问题，包括后面的Redis什么的，谈到es、Redis、MySQL分库分表等等技术，面试必问！就是你生产环境咋部署的？说白了，这个问题没啥技术含量，就是看你有没有在真正的生产环境里干过这事儿！
   >
   > 其实这个问题没啥，如果你确实干过es，那你肯定了解你们生产es集群的实际情况，部署了几台机器？有多少个索引？每个索引有多大数据量？每个索引给了多少个分片？

   - es生产集群我们部署了5台机器，每台机器是6核64G的，集群总内存是320G
   - 我们es集群的日增量数据大概是2000万条，每天日增量数据大概是500MB，每月增量数据大概是6亿，15G。目前系统已经运行了几个月，现在es集群里数据总量大概是100G左右。
   - 目前线上有5个索引（这个结合你们自己业务来，看看自己有哪些数据可以放es的），每个索引的数据量大概是20G，所以这个数据量之内，我们每个索引分配的是8个shard，比默认的5个shard多了3个shard

### 微服务

1. **什么是微服务**

   一系列微小的服务共同组成，跑在自己的进程里，每个服务为独立的业务开发，可以独立部署且分布式的管理为什么使用微服务：因为它们是一个个独立的小系统，可以独立部署并对外提供服务（提高服务的可重用性）比如双 11 来了我们可以给订单服务的节点部署的多一些，用户管理的节点部署的少一些，方便系统的可扩展性和维护性。而且可以针对 PC 和 H5 只开发一套系统提供服务

2. **SpringCloud**

   - Eureka：各个服务启动时，Eureka Client都会将服务注册到Eureka Server，并且Eureka Client还可以反过来从Eureka Server拉取注册表，从而知道其他服务在哪里

   - Ribbon：负载均衡客户端，需要结合RestTemplate进行服务的调用服务器启动时，先从Eureka server获取服务列表，然后再请求微服务时，通过RestTemplate进行http调用

   - Feign：Feign默认集成了Ribbon，可以通过@FeignClient 注解标识一个接口，通过该接口生成一个代理类来进行远程的微服务调用

   - Hystrix ： 熔断限流的组件

     - 为了防止微服务直接调用时，由于某一个微服务宕机导致整个无法雪崩，这里采用Hystrix来阻断对存在宕机，异常情况的请求，直接本地返回

     - 1）Ribbon集成，首先引入相关的依赖，接着开启@EnableHystrix
       接着在调用微服务方法上添加 @HystrixCommand(fallbackMethod = "hiError")指定服务异常的之后本地执行的方法

       2）Feign集成，在微服务绑定的接口@FeignClient(value = "service-hi"，fallback = SchedualServiceHiHystric.class)中指定异常时调用本地接口实现

     - 判定失败：Hystrix会在某个服务连续调用N次不响应的情况下，立即通知调用端调用失败，避免调用端持续等待而影响了整体服务，执行本地业务

     - 恢复服务：Hystrix间隔时间会再次检查此服务，如果服务恢复将继续提供服务。Hystrix间隔几秒会让其中一个请求去调用远程微服务，如果调用成功，就表示服务正常，后面就重新链接

   - Zuul：网关它的作用就是路由转发、请求过滤等。如果前端、移动端要调用后端系统，统一从Zuul网关进入，由Zuul网关转发请求给对应的服务

     前端请求到Nginx，Nginx请求到Zuul，Zuul来拦截请求来进行路由转发和请求过滤。可以去网关中做认证授权，并根据请求转发到微服务

     > 认证：无论是app，小程序，PC都需要使用用户名和密码进行认证，也就是登陆。登陆时请求网关，网关就会转发该登陆请求到登陆的微服务并且将用户名和密码传递过去，在用户登陆的微服务中比对数据库，如果成功则返回用户信息给网关，接着网关调用令牌申请的微服务得到令牌，接着网关将令牌返回给调用方。
     > 授权：当前用户发起请求的时候有网关拦截请求，并在网关的过滤器中获取当前请求头中是否携带令牌，如果没有就返回无权访问信息，否则网关调用令牌微服务的校验接口判断当前令牌是否合法，如果不合法则返回错误信息，否则转发到指定微服务
     >
     > 所有的请求都要经过Zuul，所以生成环境中我们都需要部署多台Zuul，以避免单点故障，把配置传到GitHub上以实现动态路由

   - SpringCloud config server（为什么使用统一配置中心）

     集中管理配置文件，可以将配置文件存在本地或者Git仓库，这样实现不重启服务器来自动刷新配置

     没使用统一配置中心之前的配置是有非常大的弊端的

     - 不方便维护：多个人协作开发时，我在开发一个功能时去修改了配置，或者新增了一些配置项，这个时候我把代码给push上去了，那另外一个人来改的时候可能要测的还是之前的一些功能，这个时候配置文件都被我改的面目全非了，他可能就要骂人了
     - 配置内容安全与权限：这个是针对线上的配置来说，公司里面线上的配置一般不会对开发公开的，特别是==数据库的账号和密码==，比较敏感的内容这些只有运维知道。不能直接放在项目里面，这样每个开发人员都能够看见了。最终需要把配置文件进行隔离
     - 我觉得最大的缺点是每次更新配置都要重启项目，多多少少都要等好一会（更新文案之类）

   - Zpkin：进行服务的追踪

3. **Spring Cloud你们在项目中如何使用？**

   项目中基础的Spring Cloud架构是有架构师搭建好的，我们主要按照代码规范开发微服务，并且把微服务注册到Eurake 注册中心，然后在需要调用微服务的客户端使用Feign的注解@FeignClient绑定接口来调用，同时在Zuul网关项目中配置自己编写的服务地址

   永远不要先考虑性能。优先考虑的是文档/社区/可维护性

   > Spring Cloud微服务架构下，微服务之间使用的是HTTP restful风格，restful风格本身轻量、易用，适用性强。可以很容易的跨语言、跨平台或者与已有的系统交互
   >
   > Spring Cloud中服务间有两种restful调用方式：1.RestTemplate 2. Feign

4. **为什么要用Spring Boot？**

   独立运行；简化配置；自动配置；无代码生成和XML配置

5. **Spring BootBoot自动配置的原理**  

   在Spring程序main方法中 添加@SpringBootApplication或者@EnableAutoConfiguration会自动去maven中读取每个starter中的Spring.factories文件  该文件里配置了所有需要被创建Spring容器中的Bean

6. **Spring Cloud和Dubbo的区别**

   Spring Cloud抛弃了Dubbo 的RPC通信，采用的是基于HTTP的REST方式。Dubbo目前也已经支持REST风格的服务，但是在项目中使用Dubbo还有很多问题需要解决，比如熔断机制，集中配置等需要自行使用其他技术，但是Spring Cloud提供一套微服务架构比较完善的解决方案。所以目前更多的企业使用Spring Cloud

7. **如何拆数据**

   依据服务特点选择不同结构的数据库类型：比如有些前置服务使用node开发的，主要是展示类型的数据，类型很丰富，对事务要求不高，那就可以考虑使用nosql的MongoDB。如果是专门做搜索类型，那优先考虑使用ES，对事务要求高的订单服务之类，优先考虑支持事务的关系型数据库

### 项目

怎么讲好自己的模块：是什么 what，先将文档上的需求分析 why，怎么实现的 how

自我介绍：面试官您好！我叫刘强。做开发两年多了。熟悉市场上比较主流的框架像 SpringMVC、Spring、Mybatis，以及 Spring boot 这些，数据库话比较了解像 MySQL 这样的关系型数据库以及 Redis、MongoDB 这样的非关系型数据库。平时呢喜欢上一些像掘金、Stack overflow、GitHub 等技术性网站。然后我来介绍一下我做过的项目吧

1. **项目介绍**

   印象最深的这个学汇网它是一个在线学习平台，项目采用前后端分离的技术架构，前端采用的是 Vue.js，后端采用 SpringBoot 和 SpringCloud 全家桶来构建微服务，用户可以通过 PC、手机等客户端来访问系统进行在线学习，那我主要负责的是页面管理模块、课程搜索模块、微信支付模块

   > 业务流程：
   > 1. 用户可以通过 pc、手机等客户端访问系统进行在线学习
   > 2. 系统应用 CDN 技术，对一些图片、CSS、视频等资源从 CDN 调度访问
   > 3. 所有的请求全部经过负载均衡器
   > 4. 对于 PC、H5 等客户端请求，首先请求 UI 层，渲染用户界面
   > 5. 客户端 UI 请求服务层获取进行具体的业务操作
   > 6. 服务层将数据持久化到数据库

2. **CMS页面管理模块**

   ![1552897686356](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/1552897686356.png)

   CMS 是由我们系统管理员进行操作模块，主要管理着各个用户子系统的页面静态。包含了教学中心，门户，用户中心等子系统的页面。主要维护模板数据、页面信息这些，然后我们会利用 freemarker 技术将页面信息静态化，并且提供预览功能，确认无误的后就可以发布页面了。

   页面发布的流程：前端点击某个页面的发布按钮，此时会将 pageId 传递给 cms 后台来获取当前页面信息，并且拿出 dataUrl（远程数据接口）来获取当前页面的数据模型。接着通过页面信息的模板 id 来得到 GridFS 中的模板内容，此时就可以利用 Freemarker 技术将模板和数据结合生成静态化的内容。接着将内容存入 GridFS，会得到一个文件 id，并且将 id 更新到当前的页面信息中的 htmlfileid 这个字段里，然后利用 RabbmitMQ 的 routing 模式将当前页面 id 发送给多个 cms 消费者，这里可能会有多个消费者，每一个消费者监听的 routingkey 是站点 id，所以在发送消息的时候通过 routingkey 需要动态指定为当前的页面所对应的站点 id，最后利用 pageId 获取静态的内容，并写入指定的 Nginx 所代理的目录

   > 页面发布代码：传入 pageId 执行静态化，将页面静态化文件存到 GridFS 中，然后向 MQ 发送消息到 CMS Client，CMS Client 就开始从 GridFS 下载文件到所在服务器

3. **课程搜索模块**

   查看文档的 `需求分析` `技术方案`

   课程搜索它包括两部分，一部分是索引一部分是搜索。

   是先有了索引，用户才能去搜索。我们想的是把课程信息索引到 ES 索引库中，

   首先我们部署一个专门的服务器叫 Logstash，它是官方提供用于提供数据采集的程序，用它就可把 MySQL 数据库中课程信息内容采集到 ES 索引库，但它这个只负责课程有添加、有更新的时候才采集，若是出现课程删除的情况？这就需要我们单独写一个删除的定时任务，然后根据删除日志来把索引库的数据删除

   这时索引库的信息已经保证和 MySQL 的信息同步之后，那么前端就可以搜索了，它是通过课程搜索前端发送 http get 请求搜索的服务端，搜索服务是我们写的 Java 程序，它要通过 Http 的 Restful 请求部署的 ES 服务。最终完成从索引库的全文检索，然后把信息给课程服务，再由课程服务把数据再返回给前端

   > 课程的搜索主要是用到了 ElasticSearch，流程大致分为两部分，用户进行搜索的前提是要在 ES 里面创建了索引，就是教师端每一个老师会对课程进行发布我们这边就会对课程信息进行聚合，改变课程表里面的状态，把课程相关的基本信息表、营销数据表、课程计划表以及图片信息同步到索引库。
   >
   > 同步表其实他也是一个表专门用来同步索引的这个表创建好后有一个字段叫 timestamp，这个时间戳比较重要，后面我们用到了 Logstash 来执行一个脚本来把 MySQL 里面索引表的数据采集到我们的 ES 索引库，他每一次同步会记录一个时间，如果 MySQL 中查出时间戳大于上一次采集的时间他就会把数据更新到索引库中。索引创建好之后就是我们 API 的创建与调用。用户进行搜索的时候，我们会有 SpringBoot 整合 ES 调用他的 API 来实现我们的高亮、分页、关键字以及过滤条件来进行搜索。

4. **微信支付**

   我们把课程添加到购物车之后，会生成一个订单的支付日志。当我们点击支付的时候，会跳转到支付页面，我们要根据当前的一个订单号去把它查出来计算出金额，然后请求我们微信统一下单的接口。完成请求之后呢，它会返回给我们支付的一个地址、订单号以及总金额，我们再把这些东西返回给我们的页面，页面在初始化的时候就有 URL、总金额和订单号。这个时候就会利用我们的 qrious 插件生成一个二维码显示到页面上。这个时候我们就可以使用微信客户端进行扫描二维码支付。我们这个生成完页面后端会循环的发送 Ajax 请求，判断是否支付。会循环 5 分钟，它会每 3 秒去查看一下我们的支付状态，他会拿当前订单去查询，如果说当这个订单已经查到了支付完成了，就会把表里的订单状态改为已支付，这时用户就有权限观看视频了。而超过了 5 分钟没有支付，我们就会通知页面重新生成一个二维码。而重新生成了二维码，但页面关闭了，过了 5 分钟还没有支付，就不再查询订单状态了，只有他点击我的订单时才有个待支付，再次跳转到支付页面时才会去查询订单状态

   ```java
   统一下单请求参数(必填)
   private String appid;			    //应用ID(公众账号ID)
   private String mch_id;		 		//商户号
   private String nonce_str;	 	    //随机字符串
   private String body; 		 	  	//商品描述
   private String out_trade_no;	    //商户订单号
   private String total_fee; 		    //总金额
   //private String spbill_create_ip;		//终端IP
   private String notify_url; 		  	//通知地址
   //private String trade_type; 			//交易类型(JSAPI公众号支付、NATIVE原生扫码支付、APPapp支付)
   private String trade_type; 			//签名
   ```

   > sign 签名每次都不一样，怎么保证的？
   >
   > 有个生成随机字符串（必填项）的方法，用它和商户号、秘钥等等参与运算。通过加密算法生成一个签名来做校验，来证明你的请求是合法的
   >
   > 我们主要会用到微信支付 SDK 的以下功能：
   >
   > （1）获取随机字符串
   >
   >   WXPayUtil.*generateNonceStr*()  
   >
   > （2）MAP 转换为 XML 字符串（自动添加签名）
   >
   >    WXPayUtil.*generateSignedXml*(param, partnerkey)  
   >
   > （3）XML 字符串转换为 MAP
   >
   >   WXPayUtil.*xmlToMap*(result)

6. **GirdFS是什么？工作原理是什么？如何使用？**

   GridFS 是 MongoDB 提供的用于持久化存储文件的模块，它可以作为分布式文件系统使用，CMS 子系统将页面文件、模板文件存储到 GridFS 中

   原理：GridFS 存储文件是将文件分块存储，文件会按照 256KB 的大小分割成多个块进行存储，它是使用两个集合来（collection）存储文件，一个集合是 chunks， 用于存储文件的二进制数据；一个集合是 files，用于存储文件的元数据信息（文件名称、块大小、上传时间等信息）
   
6. **项目开发流程**

   [https://search.bilibili.com/all?keyword=%E9%A1%B9%E7%9B%AE%E5%BC%80%E5%8F%91%E6%B5%81%E7%A8%8B&from_source=nav_search_new](https://search.bilibili.com/all?keyword=项目开发流程&from_source=nav_search_new)

   1. 需求调研 - 需求文档
   2. 开发文档 - 包含业务和页面原型 --  页面代码  --- 交给美工作图，前端开发根据图纸完成页面
   3. (前后端分离的方式) 项目经理会根据业务，编写一个接口文档
   4. 安排任务 - excel 文档标注你要完成哪些功能，每一个功能所选要时间
   5. 熟悉公司的开发流程
      - 提前熟悉需求  -- 简单的功能做什么，数据表有哪些，细节处理
      - (刚刚进公司) 公司代码规范和开发流程
        - 提前熟悉项目 -- 上级都会给你一个项目
        - 需要问一下有没有需求文档或者接口或者功能说明文档
        - 该项目运行需要哪些环境 -- (需要发布 tomcat？ 需要安装哪些东西)
        - 如果能够运行 -- 试图自己运行起来，如果运行不起来，如果启动报错
          ，自己先百度是什么问题，如果不解决，那么可以问一下旁边的同事
        - 开发流程 (最好能够向上级申请一下希望能够找一个前辈帮自己快速熟悉公司的代码规范和开发流程，找一个同事帮梳理一遍某一个增删改查功能开发过程) 如果能够运行或者有接口文档 -> 获得请求的 url -> 全局搜索查找匹配该 url 的 controller-> 找到该 url 对应的请求方法 (分析调用了本地哪些 Java 文件，debug) 如果没有接口文档也不能运行，自己尝试把所有的包去看看，有没有自己熟悉，查看有没有 web，controller，service，mapper，reporties，dao，utils，filter (分析调用了本地哪些 Java 文件，debug)
      - 根据公司架构提供集成架构上进行业务功能开发
        - 从 git 或者 svn 将基础代码拉取下来
        - 按照公司开发规范编写代码 api 接口 (controller)  ---> 根据业务分析接口所需要的参数和返回值
          controller 实现类 service 具体业务 --> dao 业务的细节： 做一些数据验证，判断是否登陆才能操作之类
      - 每天下班的时候记得把完成功能 (可运行的代码) 提交 svn git

7. **事务是怎么控制的？用到分布式事务控制了吗？如何做的？**

   i. 在微服务中使用 Spring 声明式事务控制方式进行控制，在 Service 方法上添加 @Transctional 注解即可实现事务控制，它控制的是 MySQL 的本地事务

   ii. 项目中大量存在分布式事务控制，比如下单支付、课程发布等地址都用到了分布式事务来实现最终数据一致性，做法是：![1553048376228](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/1553048376228.png)
   

场景：当用户去选课，选了一门课支付成功后呢需要自动将课程在学习系统中添加成功，然后用户就可以在线学习了

在这呢我们用到的就是事务的最终一致性，落地方案采用的是消息队列，首先支付成功后我们会在订单数据库的消息表中进行记录，那订单支付表和消息表在同一个数据库中就能保证事务了，所以订单支付成功之后会更新支付状态为成功并向消息表写一个消息，内容就是向学习系统添加一门课。这时候呢在订单系统中有个定时任务去扫描消息表，当一旦有消息就发给 MQ，MQ 就通知学习系统进行添加选课。添加成功后呢会返回选课成功消息给 MQ，MQ 会告诉订单你刚才的消息已经结束，订单系统就会把那条消息删掉。这样前边就不会再次发送这条消息了。最终也就完成了只要向订单支付成功那么学习系统的选课表就添加成功这么个同步的事务

8. **项目人员**

   项目经理：1个	项目组长：1个	前端：2个	开发：4个	测试：2个	运维：1个

9. **接口定义规范（接口是怎么定义的？采用什么数据格式？如何实现？）**

   项目架构设立接口层，接口层使用 swagger 注解描述接口的内容，接口定义规范如下:

   - 接口定义

     使用 SpringMVC 定义接口，在类上定义了根路径，在每个方法上边我们用 GetMapping、PutMapping、PostMapping、DeleteMapping 等注解定义 URL

   - 数据格式

     - Get 请求时，采用 key/value 格式请求，SpringMVC 可采用基本数据类型接收，查询对象条件等呢可以使用自定义类型对象来接收

     - Post 请求时，可以提交 Form 表单数据（application/x-www-form-urlencoded）或 Json 数据 (ContentType=application/json) 以及文件等多部件类型数据（multipart/form-data），对于 Json 数据 SpringMVC 使用 @RequestBody 注解解析请求的 json 数据

   - 响应：统一响应 json 格式

     - 响应结果信息统一包括：是否成功、操作代码、提示信息以及自定义数据（比如查询结果用的就是 QueryResponseResult 来接收）

     - 响应结果格式呢统一为 json 数据

       > 服务端都是暴露的 rest 接口，统一用 json 展示数据

     实现：json 格式数据 SpringMVC 采用 FastJson 解析为对象。非 json 格式数据 SpringMVC 提供参数绑定的方法，将 key/value 或 Form-Data 数据转换为对象或基本数据类型的变量

10. **API 定义约束**

    Api 定义是使用 SpringMVC 来完成，由于接口后期将作为微服务远程调用使用，在定义接口时使用
    @PathVariable 和 @RequestParam 统一指定参数名称，必须在注解的括号中指明参数，如：@PathVariable ("id") @RequestParam（"id"） 

    > 为什么把 api 接口单独定义在一个服务中？
    >
    > 1）方便统一的管理，不然微服务特别多就会分散在各个位置
    >
    > 2）微服务与微服务之间得远程调用技术就是基于接口调用的，如果接口分散在不同的位置，服务 A 调用服务 B，那么 A 就依赖于 B，但现在统一定义在 api 服务中，那么所有服务依赖于 api 就可以轻易拿到任意微服务接口了
    >
    > 3）当有一天我们想要换用别的 web 框架了，那么 api 服务是不用动的，只用改实现类就可以了，增强了系统的可扩展性

11. **前后端开发时具体流程是什么？**

    > 前后端分离开发模式在互联网公司最常见，特别是一些大型的互联网公司，但是一些传统的软件开发企业仍然是采用传统开发模式，此问题被问及是考察你有没有真正体会前端开发的好处
    >
    > 好处：它是统一对外提供服务嘛，方便了系统的扩展性和可维护性，比如说现在要开发一个安卓客户端，那么现在只需要单独做个客户端就可以了，不管什么样的客户端来请求业务，服务层都统一提供服务。
    >
    > 还有就是说如果双十一要来了，下单的用户比较多，就可以把订单的节点服务部署的多一点，用户管理的部署少一些，这就是一些好处，方便系统的扩展性和可维护性
    >
    > 用户层：面向哪些用户、CDN 作为缓存、负载均衡把用户的请求分担到不同的节点、微服务层统一为前端提供服务

- 前端与后端开发人员讨论确定接口接口讨论通过，形成接口文档。本项目专门设立一个 api 工程，在此工程定义接口，Spring Boot 集成 Swagger，生成 Swagger 接口，前后端开发人员通过 html 查看接口文档的内容

- 前端与后端开发人员按照接口文档进行开发。开发过程中各自进行单元测试。前端人员怎么进行单元测试？前端人员可以通过一些工具生成一些模拟数据，比如：EasyMock

  > 项目是基于前后端分离的架构进行开发，前后端分离架构总体上包括前端和服务端，通常是多人协作并行开发，开发步骤如下：
  > 1、需求分析
  > 梳理用户的需求，分析业务流程
  > 2、接口定义
  > 根据需求分析定义接口
  > 3、服务端和前端并行开发
  > 依据接口进行服务端接口开发。
  > 前端开发用户操作界面，并请求服务端接口完成业务处理。
  > 4、前后端集成测试
  > 最终前端调用服务端接口完成业务。

11. **你在开发中遇到什么问题？是怎么解决的？**

    例子：在处理订单时要用到定时任务，当时采用的是 Spring Task 来完成，由于一个订单服务会部署多个，多个订单服务同时去处理任务会造成任务被重复处理的情况，如何解决任务的重复处理

    解决：采用乐观锁解决，在任务表中设置一个 version 字段记录版本号，取出任务记录同时拿到任务的版本号，执行前对任务进行锁定，具体的做法是执行 update 根据当前版本号将版本号加 1，update 成功表示锁定任务成功，即可开始执行任务

    OutOfMemoryError（见 JVM 部分）、StackOverflowError（方法调用死循环）

12. **如何设计一个高并发系统？**

![01_高并发系统的架构组成](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/01_高并发系统的架构组成.png)

13. **前后端如何联调**

    就是我们把后端代码写好后，用 jenkins 进行发布一个版本，同时给它注册到 Eureka 上，前端就可以来调你地址来进行联调啦，如果有问题再修改后端代码

14. **项目使用Spring了吗?用了它的哪些东西?**

    项目是基于 Spring 进行构建的：

    i. 所有的微服务开发采用 Spring Boot 开发
    ii. 数据层使用 Spring Data JPA， Spring Data MongoDB， Spring Data Redis
    iii. 业务层使用 Spring 来控制本地事务，还使用了 Spring Task 任务调度框架 Spring AMQP 组件等
    iv. 控制使用 SpringMVC， Sprnig Security Oauth2
    v. 微服务管理使用 Spring Cloud 的 Eureka 注册中心，微服务之间调用使用 Ribbon 和 Feign Client 完成
    vi. 使用 Zuul 网关完成微服务安全验证

15. **什么是雪崩，如何解决？**

    微服务的雪崩效应表现在服务与服务之间调用,当其中一个服务无法提供服务可能导致其它服务也死掉了

16. **学成在线的技术架构**

    ![1555770911092](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/1555770911092.png)

    - 门户是整个平台的入口
    - 学习中心是为用户提供在线学习服务
    - 教学中心是为教育机构或个人讲师提供教学管理功能
    - 系统管理中心是提供CMS、分类管理、数据字典、系统参数配置等
    
17. **Vue**

    Vue.js是一个MVVM的框架

    - MVVM拆分解释为：
      - Model:负责数据存储
      - View:负责页面展示
      - View Model:负责业务逻辑处理（比如Ajax请求等），对数据进行加工后交给视图展示
    - 用图解的形式分析Ajax请求回来数据后直接操作Dom来达到视图的更新的缺点，以及使用MVVM模式是如何来解决这个缺点的
    - Vue中的 MVVM，VM(ViewModel)可以把view视图和Model模型解耦合
      ![image-20200423105638701](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/image-20200423105638701.png)

    > MVVM要解决的问题是将业务逻辑代码与视图代码进行完全分离，使各自的职责更加清晰，后期代码维护更 加简单

18. **为什么使用Vue**

    1. 体积小：压缩后33K
    2. 更高的运行效率：基于虚拟dom一种可以预先通过JavaScript进行各种计算，把最终的DOM操作计算出来并优化的技术，由于这个DOM操作属于预处理操作，并没有真实的操作DOM，所以叫做虚拟DOM
    3. 双向数据绑定：让开发者不用再去操作dom对象，把更多的精力投入到业务逻辑上
    4. 生态丰富、学习成本低：市场上拥有大量成熟、稳定的基于 vue. JS的UI框架、常用组件！拿来即用实现快速开发对初学者友好、入门容易、学习资料多

19. **前后端请求响应流程**

    ![image-20200423162408539](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/image-20200423162408539.png)

    > 1. 在浏览器输入前端url
    > 2. 前端框架vue.js根据url解析路由，根据路由找到page_list.vue页面
    > 3. 首先执行page_list.vue中的钩子方法
    > 4. 在钩子方法中调用query方法
    > 5. 在query方法中调用cms.js中的page_list方法
    > 6. cms.js中的page_list方法通过axios请求服务端接口
    > 7. 采用proxyTable解决跨域问题，node.js将请求转发到服务端(http://localhost:31001/cms/page/list)
    > 8. 服务端处理，将查询结果响应给前端
    > 9. 成功响应后调用then方法，在then方法中处理响应结果，将查询结果赋值给数据模型的total和list
    > 10. vue.js通过双向数据绑定将list数据渲染输出

20. **异常处理**

    ```java
    //添加页面
    public CmsPageResult add(CmsPage cmsPage) {
        //校验页面是否存在，根据页面名称、站点Id、页面webpath查询
        CmsPage cmsPage1 = cmsPageRepository.findByPageNameAndSiteIdAndPageWebPath(cmsPage.getPageName(), cmsPage.getSiteId(), cmsPage.getPageWebPath());
        if (cmsPage1 == null) {
            cmsPage.setPageId(null);//添加页面主键由Spring data 自动生成
            cmsPageRepository.save(cmsPage);
            //返回结果
            CmsPageResult cmsPageResult = new CmsPageResult(CommonCode.SUCCESS, cmsPage);
            return cmsPageResult;
        }
        return new CmsPageResult(CommonCode.FAIL, null);
    }
    ```

    问题：

    1. 上边的代码只要操作不成功仅向用户返回“错误代码：11111，失败信息：操作失败”，无法区别具体的错误信息
    2. service方法在执行过程出现异常在哪捕获？在service中需要都加try/catch，如果在controller也需要添加
       try/catch，代码冗余严重且不易维护

    解决方案：

    1. 在Service方法中的编码顺序是先校验判断，有问题则抛出具体的异常信息，最后执行具体的业务操作，返回成功信息
    2. 在统一异常处理类中去捕获异常，无需controller捕获异常，向用户返回统一规范的响应信息

    异常处理流程：

    1. 自定义异常类型。

    2. 自定义错误代码及错误信息。

    3. 对于可预知的异常由程序员在代码中主动抛出，由SpringMVC统一捕获

       可预知异常是程序员在代码中手动抛出本系统定义的特定异常类型，由于是程序员抛出的异常，通常异常信息比较齐全，程序员在抛出时会指定错误代码及错误信息，获取异常信息也比较方便

    4. 对于不可预知的异常（运行时异常）由SpringMVC统一捕获Exception类型的异常。
       不可预知异常通常是由于系统出现bug、或一些不要抗拒的错误（比如网络中断、服务器宕机等），异常类型为RuntimeException类型（运行时异常）

    5. 可预知的异常及不可预知的运行时异常最终会采用统一的信息格式（错误代码+错误信息）来表示，最终也会随请求响应给客户端

    ![image-20200423180918464](https://cdn.jsdelivr.net/gh/liuilin/interview@latest/interview_note/img/image-20200423180918464.png)

    > 1、在controller、service、dao中程序员抛出自定义异常；springMVC框架抛出框架异常类型
    > 2、统一由异常捕获类捕获异常，并进行处理
    > 3、捕获到自定义异常则直接取出错误代码及错误信息，响应给用户
    > 4、捕获到非自定义异常类型首先从Map中找该异常类型是否对应具体的错误代码，如果有则取出错误代码和错误信息并响应给用户，如果从Map中找不到异常类型所对应的错误代码则统一为99999错误代码并响应给用户
    > 5、将错误代码及错误信息以Json格式响应给用户

21. **为什么既使用SpringDataJPA又使用Mybatis？**

    因为 SpringDataJPA 是面向对象的项目中不需要写实现类，方便快速开发。而 mybatis 是面向 SQL 开发，适合做 SQL 优化，自定义一些 SQL 比较灵活。

### 面试问题集锦

1. **项目里面遇到过什么难点问题，怎么解决的?**

   项目需求的版本变更时，需要将旧版数据库同步到新版数据库，但又不能使用 sql 脚本直接同步，因为数据库的字典不一致，改动呢比较大！我们呢是采用写代码的方式来进行同步，同时呢用了多线程来提高效率，要同步多少个表的数据就开启多少个线程

2. **项目中代码怎么优化？**

   - 字符串拼接的优化，对于日志字符串的拼接我们都是采用 StringBuffer（因为用到了多线程）来进行优化
   - 对于循环，我们是需要判断是否已经达到循环的目的，然后直接 break
   - 遵循公司的开发规范
   - sql 优化

3. **工作中遇到过哪些异常？**

   Java.util.ConcurrentModificationExceptior

   [OutOfMemoryErrorWithNativeThread](#OutOfMemoryErrorWithNativeThread)

4. **你的个人规划？**

   我目前就是想在一家公司稳定的待着，因为在这边买了房子

5. **你们项目中用到了多线程了吗**

   - 消息堆积问题，以及如何处理
   - 后台违约订单处理：利用定时任务扫描商品已经下架，但是没有支付的订单进行处理
   
6. **对于 git，svn 代码冲突怎么处理？**

   多个人都在操作同一个文件，然后直接都在提交

   - 谁先提交，谁就不用管
   - 这个时候，就让别人再次更新他的代码，然后我先更新，更新之后再他的基础上进行修改
   - 直接采用 IDEA 工具来当前你要修改的文件和目前更新的文件有哪些地方不一样

   拉下来看，如果修改是同一个文件，并不是同一处，那么可以通过工具合并，再提交。

   如果修改的是同一处，那么我这边当前修改的内容比较少，我就让同事提交他的代码，然后我更新之后再修改，最后再提交

2. **关于项目上线的问题？ 比如：并发多少，集群环境，搭建了多少台服务器**

   集群环境是否负责： 生产环境我作为开发并没有涉及，主要负责的事开发环境和测试环境。

3. **当面试官问你还有什么问题问我时，回答模式？**

   人事：

   - 五险一金如何购买，买在哪里
   - 公司还有其他福利

   技术：

   - 贵公司开发用什么技术什么框架，或者利用什么公司
   - 贵公司版本管理工具用的是什么
   - 贵公司的开发模式，是前后端分离还是后台人员需要开发 js 交互
   - 贵公司的开发业务方向
   - 加班如何
   
9. **SpringBoot 注解：**

   装配一个 Bean 时，会用到 @Configuration、@Bean 这两个注解。这种装配方法虽然简单粗暴，但是多了都用 @Bean 方式注入会很痛苦，那就可以使用 SpringBoot 的方式装配 Bean，使用的就是 @Component（标明哪个类被扫描，在类里面使用 @Value 指定值）和 @ComponentScan，当然 @SpringBootApplication 里面已经包含了 @ComponentScan。

   @Autowired：根据属性类型找到对应的 Bean 进行注入

   @ComponentScan 组件扫描，可自动发现和装配一些 Bean

   @RestController 相当于 @Controller 和 @ResponseBody

   @PathVariable 获取参数

   @SpringBootApplication：包含了 @ComponentScan、@Configuration 和 @EnableAutoConfiguration 注解

   > 其中 @ComponentScan 让 Spring Boot 扫描到 Configuration 类并把它加入到程序上下文

10. **开闭原则：对拓展开放、对修改关闭**

    里氏替换原则：任何子类都能替换父类

11. **如何用 MySQL 实现 cas 模式的数据安全**

    可以采用的乐观锁机制，在数据库里面加一个 version 的字段，判断当前的 version 和数据库里的是否一致，一致就可以进行修改，不一致就会不断重试

12. **IOC 的优点是什么？**

    IOC 或 依赖注入把应用的代码量降到最低。它使应用容易测试，单元测试不再需要单例和 JNDI 查找机制。最小的代价和最小的侵入性使松散耦合得以实现。IOC 容器支持加载服务时的饿汉式初始化和懒加载。

13. **@Qualifier** 

    注解当有多个相同类型的 bean 却只有一个需要自动装配时，将 @Qualifier 注解和 @Autowire 注解结合使用以消除这种混淆，指定需要装配的确切的 bean

14. **查看进程命令**

    ps 命令（Process Status）ps aux | grep Redis

15. **Servlet执行过程**

    当服务器端通过 HTTP 协议接收到客户请求后，会将其转化为 HttpServletRequest 对象传递给 Servlet。
    Servlet 通过这些类理解客户的请求，并将其处理后的内容通过 HttpServletResponse 回复到服务器端。
    Web 容器进行整理后用 HTTP 协议向客户端传送响应。

12. **Servlet生命周期**

    Servlet 实例装载有以下三种方式：

    当第一次调用 Servlet 时，就会创建一个 Servelt 实例，这个实例会长期驻留内存中。

    > 在 Web.xml 文件中的 <Servlet></Servlet> 之间添加如下代码：<loadon-startup>1</loadon-startup>，Servelt 容器启动时会自动装载这个 Servlet，数字越小表示优先级别越高。
    > Servlet 类文件被更新后，会重新装载 Servlet

    - init () 方法初始化阶段

      只调用一次 ，第一次创建 Servlet 时被调用。init () 方法简单地创建或加载一些数据，这些数据将被用于 Servlet 的整个生命周期

    - service () 方法处理客户端请求阶段

      处理客户端的请求，并把格式化的响应写回给客户端。每次服务器接收到一个 Servlet 请求时，服务器会产生一个新的线程并调用服务，它会根据来自客户端的请求类型来重载 doGet () 或 doPost () 

    - destroy () 方法终止阶段

      只会被调用一次，在 Servlet 生命周期结束时被调用。destroy () 方法可以让 Servlet 关闭数据库连接、停止后台线程、把 Cookie 列表或点击计数器写入到磁盘等

18. **后台系统如何防止重复提交（微信支付）**

    可以使用 token 令牌机制，在进去表单页面的时候发送请求到后台。后台生成一个不重复的 ID 返回。并把 ID 存在 Redis 中。表单提交时带上这个 ID 去做判断就好了

    > 消息的不丢失。开启消息的持久化，包括生产者开启事务。交换机持久化，队列持久化。自动应答改为手动确认消费者端的自动消息确认，改为操作成功后手动提交

19. **拦截器和过滤器**

20. **各行业特点**

    传统行业：项目业务

    金融：事务的隔离级别、SSM

    互联网行业：技术新、微服务

21. **日志怎么贯穿你们 service 服务层了**

    使用 Zpkin 来查看你的服务调用链日志

17. **两个项目之间如何通信的**

    应用间通信： RPC（Dubbo）vs HTTP（Spring Cloud）

    Dubbo 本身定位就是一个 RPC 框架，它在服务治理集成上非常完善不仅提供了服务注册发现、负载均衡、路由等面向分布式基础的能力，还提供了面向测试的 mock、泛化调用等机制，同时提供了服务治理、监控等可视化平台。所以在 SpringCloud 没出来之前，Dubbo 在国内应用的相当之广泛

    Dubbo 的定位始终是 RPC 框架，而 SpringCloud 的目标是微服务下的一站式解决方案

    Spring Cloud 微服务架构下，微服务之间使用的是 HTTP restful 风格，restful 风格本身轻量、易用，适用性强。可以很容易的跨语言、跨平台或者与已有的系统交互

    Spring Cloud 中服务间有两种 restful 调用方式：1.RestTemplate 2.Feign

    两个 Java 项目，他们之间进行信息的通信
    前提：必须知道要通信的 Java 项目（接收请求方）的服务器的 IP 地址和访问路径。
    其实两个 Java 项目之间的通信还是使用 HTTP 的请求。主要有两种方式：
    :one: 使用 Apache 的 HttpClient 方式
    :two: 使用 JDK 自带的 Java.net 包下的 HttpURLConnection 方式

    HttpURLConnection 方式：HttpURLConnection 传递请求常用的有两种方式：POST 和 GET 方式。使用 setRequestMethod () 方法设置传递的方式

    

    直接通过远程过程调用来访问别的 service：REST

    > 优点：
    >
    > - 简单，常见
    > - 因为没有中间件代理，系统更简单
    >
    > 缺点：
    >
    > - 只支持请求 / 响应的模式，不支持别的，比如通知、请求 / 异步响应、发布 / 订阅、发布 / 异步响应
    > - 降低了可用性，因为客户端和服务端在请求过程中必须都是可用的

    使用 RabbitMQ 的异步消息来做服务间通信

    > 优点:
    >
    > - 把客户端和服务端解耦，更松耦合
    > - 提高可用性，因为消息中间件缓存了消息，直到消费者可以消费
    > - 支持很多通信机制比如通知、请求 / 异步响应、发布 / 订阅、发布 / 异步响应
    >
    > 缺点:
    >
    > - 消息中间件有额外的复杂性

18. **为什么用两个不同的数据库？**

    根据服务的特点来选择不同结构的数据库：

    - 比如有些前置服务使用 node 开发的，主要是展示类型的数据，类型很丰富，对事务要求不高，那我们就考虑使用 nosql 的 MongoDB
    - 如果是专门做搜索类型，考虑使用 ES
    - 像订单服务啊这种对事务要求高的，还是优先考虑用支持事务的关系型数据库

19. **Lock 锁抛出异常了怎么办 **

    Lock 必须要在 finally 代码块中 unlock() 手动释放锁，否则容易造成线程死锁

20. **用 JQuery 写一段伪代码，实现页面端通过 Ajax 调用服务端请求**

    ```javascript
    $.ajax({
        		type: "GET"，   						//请求方式
                url: "http://www.microsoft.com"，    //请求的url地址  
                dataType: "json"，   				//返回格式为json  
                async: true，	//请求是否异步，默认为异步，这也是ajax重要特性  
                data: {"id": "value"}，    			//参数值  
                success: function (req) {
                    //请求成功时处理  
                }，
                error: function () {
                    //请求出错处理  
                }
            });
    ```

21. **数据库视图与表的区别？**

    视图是按照条件查出来的结果集，只能进行 select 操作

    表是真实存在的，增删改查都可以

22. **分布式 ID 的特性**

    - 唯一性：确保生成的 ID 是全网唯一的。
    - 有序递增性：确保生成的 ID 是对于某个用户或者业务是按一定的数字有序递增的。
    - 高可用性：确保任何时候都能正确的生成 ID。
    - 带时间：ID 里面包含时间，一眼扫过去就知道是哪天交易的

23. **如何选择合适的分布式主键方案**

    - UUID

      > 算法的核心思想是结合机器的网卡、当地时间、一个随记数来生成 UUID

    - 数据库自增 ID

      > 使用数据库的 id 自增策略，如 MySQL 的 auto_increment。并且可以使用两台数据库分别设置不同步长，生成不重复 ID 的策略来实现高可用

    - Redis 生成 ID

      > Redis 的所有命令操作都是单线程的，本身提供像 incr 和 increby 这样的自增原子命令，所以能保证生成的 ID 肯定是唯一有序的
      >
      > 另外，比较适合使用 Redis 来生成每天从 0 开始的流水号。比如订单号 = 日期 + 当日自增长号。可以每天在 Redis 中生成一个 Key ，使用 incr 进行累加

    - 推特雪花算法（Twitter 的 snowflake 算法）

      > Twitter 利用 zookeeper 实现了一个全局 ID 生成的服务 Snowflake

24. **小伙子，你是我最近面试的程序员中基础知识最扎实的一个**

    没有没有，还是您引导的好，正好问到的是我之前复习到、有用到的，如果您再问深点估计我就挂了

### GitHub

GitHub快捷键：https://help.github.com/en/articles/using-keyboard-shortcuts

GitHub指南：https://sspai.com/post/46061

Git Flow工作流：https://github.com/xirong/my-git/blob/master/git-workflow-tutorial.md

https://www.ruanyifeng.com/blog/2015/12/git-workflow.html

[https://www.funtl.com/zh/git/GitFlow%E5%B7%A5%E4%BD%9C%E6%B5%81.html](https://www.funtl.com/zh/git/GitFlow工作流.html)

https://www.cnblogs.com/iBrand2018/p/8708740.html

BOSS 让做一个支付接口 / 秒杀

上 GitHub 借鉴优秀框架，阅读源码

1. Git：每个开发者可以有属于自己的整个工程的本地拷贝。隔离的环境让各个开发者的工作和项目的其他部分修改独立开来 —— 即自由地提交到自己的本地仓库，先完全忽略上游的开发，直到方便的时候再把修改反馈上去

2. in关键词限制搜索范围：xxx关键词 in:name，description，readme 项目名、描述、readme中包含关键字的

3. SpringBoot stars/forks:>=5000

   springboot forks: 100.. 200 stars:80.. 100

4. awesome Redis

5. 给别人指出关键代码的行号  地址+#L13（-L23）

6. 项目内源代码搜索：t

7. 搜索某地区内的大佬

   - 公式：
     - location：地区
     - language：语言
   - 地区成都的Java方向的用户：location:chengdu language:Java
   
   > 1.按照文件搜索
   > android in:file
   > 2.按照路径检索
   > andrioid in:path
   > 3.按照语言检索
   > android language:Java
   > 4.按照文件大小
   > android size:>100
   > 5.按照后缀名检索
   > android extention:css
   > 6.按照是否被fork过
   > android fork:true
   > 7.按照地域检索
   > android location:beijing

### 简历

https://www.ruanyifeng.com/blog/2020/01/technical-resume.html